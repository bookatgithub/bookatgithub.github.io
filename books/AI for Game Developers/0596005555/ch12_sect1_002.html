<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>12.2 What is Probability?</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body >
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch12_sect1_001.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch12_sect1_003.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch12_sect1_002"></A>
<H3 class="docSection1Title" id="">12.2 What is Probability?</H3>
<P class="docText">The question posed here—what is probability?—is deceptively simple to answer in that there's no single definition of probability. One can interpret probability in several different ways, depending on the situation being considered and who's doing the considering. In the following sections, we consider three common interpretations of probability, all of which have a place in games in some form or another. We keep these discussions general in nature to keep them easy to understand.</P>
<A NAME="ch12_sect2_006"></A>
<H4 class="docSection2Title">12.2.6 Classical Probability</H4>
<P class="docText"><span class="docEmphasis">Classical probability</span> is an interpretation of probability that refers to events and possibilities, or possible outcomes. Given an event, <span class="docEmphasis">E</span>, which can occur in <span class="docEmphasis">n</span> ways out of a total of <span class="docEmphasis">N</span> possible outcomes, the probability, <span class="docEmphasis">p</span>, of occurrence of the event is:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq01.jpg" ALT="figs/ch12_ueq01.jpg">
<P class="docText">Here, <span class="docEmphasis">P(E)</span> is the probability of event <span class="docEmphasis">E</span>, which is equal to the number of ways <span class="docEmphasis">E</span> occurs out of <span class="docEmphasis">N</span> possible ways. <span class="docEmphasis">P(E)</span> usually is called the <span class="docEmphasis">probability of success</span> of the event. The <span class="docEmphasis">probability of failure</span> of the event is <span class="docEmphasis">1-P(E)</span>. In summary:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq02.jpg" ALT="figs/ch12_ueq02.jpg">
<P class="docText">Note that probabilities range in value from 0 to 1 and the sum of the probabilities of success and failure, <span class="docEmphasis">p</span><SUB>s</SUB> + <span class="docEmphasis">p</span><SUB>f</SUB>, must equal 1.</P>
<P class="docText">Let's consider a simple example. Say you roll a six-sided die; the probability that a four will show up is 1/6 because there's only one way in which a four can show up out of six possible outcomes in a single roll. In this example, the event, <span class="docEmphasis">E</span>, is the event that a four will show up. For the roll of a single die, a four can show up in only one way; therefore, <span class="docEmphasis">n</span> = 1. The total number of possible outcomes, <span class="docEmphasis">N</span>, is six in this case; therefore, <span class="docEmphasis">P(E = 4)</span> = 1/6. Clearly, in this case the probability of any given number showing up is 1/6 because each number can show up in only one possible way out of six ways.</P>
<P class="docText">Now, consider two six-sided dice, both rolled at the same time. What is the probability that the sum of the numbers that show up is equal to, say, five? Here, the event we're interested in is a sum of five being rolled. In this case, there are four possible ways in which the sum of five can result. These are illustrated in <A class="docLink" HREF="#ch12_fig02">Figure 12-2</A>.</P>
<A NAME="ch12_fig02"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 12-2. Sums of five in roll of two dice</H5>
<IMG BORDER="0" id="" SRC="images/0596005555/figs/ch12_fig02.jpg" ALT="figs/ch12_fig02.jpg">
</CENTER></p><br>
<P class="docText">Note that the outcome of the first die showing a two and the second showing a three is distinctly different from the outcome of the first die showing a three and the second showing a two. In this case, <span class="docEmphasis">N</span> = 36—that is, there are 36 possible outcomes of the roll of two dice. The probability, then, that the sum of five will appear is four divided by 36, with 36 being the total number of possible outcomes for two six-sided dice. This results in a probability of 4/36 or 1/9.</P>
<P class="docText">You can find the probability that any sum can show up in a similar manner. For example, the possible ways in which the sum of seven can occur are summarized in <A class="docLink" HREF="#ch12_tab02">Table 12-2</A>.</P>
<A NAME="ch12_tab02"></A><P><TABLE CELLSPACING="0" FRAME="hsides" RULES="all" CELLPADDING="4" WIDTH="100%"><CAPTION><h5 class="docTableTitle">Table 12.2. Sums of seven in roll of two dice</h5></CAPTION><COLGROUP><COL><COL></COLGROUP><THEAD><TR><TH class="thead" align="center"><P class="docText">Die 1</P></TH><TH class="thead"><P class="docText">Die 2</P></TH></TR></THEAD><TR><TD class="docTableCell"><P class="docText">1</P></TD><TD class="docTableCell"><P class="docText">6</P></TD></TR><TR><TD class="docTableCell"><P class="docText">6</P></TD><TD class="docTableCell"><P class="docText">1</P></TD></TR><TR><TD class="docTableCell"><P class="docText">2</P></TD><TD class="docTableCell"><P class="docText">5</P></TD></TR><TR><TD class="docTableCell"><P class="docText">5</P></TD><TD class="docTableCell"><P class="docText">2</P></TD></TR><TR><TD class="docTableCell"><P class="docText">3</P></TD><TD class="docTableCell"><P class="docText">4</P></TD></TR><TR><TD class="docTableCell"><P class="docText">4</P></TD><TD class="docTableCell"><P class="docText">3</P></TD></TR></TABLE></P><br>
<P class="docText">In this case, the probability of a sum of seven is 6/36 or 1/6. Stated another way, the probability of a sum of seven is 16.7%. We can express probability as percentages by taking the probability value, which will be between 0 and 1, and multiplying it by 100.</P>

<A NAME="ch12_sect2_007"></A>
<H4 class="docSection2Title">12.2.7 Frequency Interpretation</H4>
<P class="docText">The <span class="docEmphasis">frequency interpretation</span> of probability, also known as <span class="docEmphasis">relative frequency</span> or <span class="docEmphasis">objective probability</span>, considers events and samples or <span class="docEmphasis">experiments</span>. If an experiment is conducted <span class="docEmphasis">N</span> times and some event, <span class="docEmphasis">E</span>, occurs <span class="docEmphasis">n</span> times, the probability of <span class="docEmphasis">E</span> occurring is:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq03.jpg" ALT="figs/ch12_ueq03.jpg">
<P class="docText">Note here the caveat that <span class="docEmphasis">P(E)</span> is <span class="docEmphasis">n/N</span> as the number of experiments conducted gets very large. For a finite number of experiments, the resulting probability will be approximate, or empirical, because it is derived statistically. Empirical probability can be slightly different from theoretical probability if it can, indeed, be calculated for a given event. Additionally, we're assuming the experiments are independent—that is, the outcome of one experiment does not affect the outcome of any other experiment.</P>
<P class="docText">Consider a simple experiment in which a coin is tossed 1000 times. The results of this experiment show that heads came up 510 times. Therefore, the probability of getting heads is 510/1000, which yields:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq04.jpg" ALT="figs/ch12_ueq04.jpg">
<P class="docText">Of course, in this example we know that <span class="docEmphasis">P(heads)</span> is 0.5 or 50% and were we to continue with these experiments for a larger number of tosses we would expect our empirically derived <span class="docEmphasis">P(heads)</span> to approach 0.5.</P>

<A NAME="ch12_sect2_008"></A>
<H4 class="docSection2Title">12.2.8 Subjective Interpretation</H4>
<P class="docText"><span class="docEmphasis">Subjective probability</span> is a measure, on a scale from zero to one, of a person's degree of belief that a particular event will occur given their knowledge, experience, or judgment. This interpretation is useful when the event, or experiment, in question is not repeatable—that is, we can't use a frequency measure to calculate a probability.</P>
<P class="docText">Subjective probabilities are found everywhere—we can say "it probably will rain tomorrow" or "I have a good chance of passing this test" or "the Saints probably will win tomorrow." In each case, we base our belief in the outcome of these events on our knowledge of the events, whether it is complete or incomplete knowledge, and on our judgment considering a potential variety of relevant factors. For example, the fact that it is raining today might lead us to believe that it probably will rain tomorrow. We believe the Saints might win tomorrow's football game with a better-than-usual probability because we know the other team's star quarterback is suffering from an injury.</P>
<P class="docText">Consider this example: let's assume you're up for the lead game designer promotion in your company. You might say, "I have a 50% chance of getting the promotion," knowing that someone else in your group with identical qualifications also is being considered for the job. One the other hand, you might say, "I have about a 75% chance of getting the promotion," knowing that you've been with this company longer than your colleague who also is being considered. If in this case you also learn that the other candidate has notoriously missed milestone deadlines on various game projects, you might be inclined to revise your belief that you'll get the promotion to something like a 90% chance. Formally, Bayesian analysis enables us to update our belief of some event given such new information. We discuss this in much greater detail in the next chapter.</P>
<P class="docText">Subjective probabilities very often are difficult to pin down, even when one has a fairly good intuitive feeling about a particular event. For example, if you say you probably will pass that test, what would you say is the actual probability: 60%, 80%, or 90%? You can employ some techniques to help pin down subjective probabilities, and we go over two of them shortly. Before we do that, however, we need to cover two other fundamental topics: odds and expectation.</P>
<A NAME="ch12_sect3_001"></A>
<H5 class="docSection3Title">12.2.1 Odds</H5>
<P class="docText">Odds show up commonly in betting scenarios. For example, Sunflower Petals might be the long shot to win next week's horse race, and the odds against her winning are 20 to 1; a football fan might take 3 to 1 odds on a bet in favor of the Giants winning Sunday's game; and so on. For many, it's easier or more intuitive to think of probabilities in terms of odds rather than in terms of some number between 0 and 1, or in terms of percentages. Odds reflect probabilities, and you can convert between them using a few simple relations.</P>
<P class="docText">If we say the odds in favor of the success of some event, <span class="docEmphasis">E</span>, are <span class="docEmphasis">a</span> to <span class="docEmphasis">b</span>, the probability of success of that event, <span class="docEmphasis">P(E)</span>, is:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq05.jpg" ALT="figs/ch12_ueq05.jpg">
<P class="docText">We can work in the other direction from probability to odds too. If you are given the probability of success of some event, <span class="docEmphasis">P(E)</span>, the odds in favor of the event succeeding are <span class="docEmphasis">P(E)</span> to <span class="docEmphasis">(1-P(E))</span>. For example, if the odds are 9 to 1 that you'll pass a test, the probability that you'll pass is 0.9 or 90%. If, however, the probability you'll pass is only 0.6, or 60%, because you didn't study as much as you would have liked, the odds in favor of you passing are 60 to 40 or 1.5 to 1.</P>

<A NAME="ch12_sect3_002"></A>
<H5 class="docSection3Title">12.2.2 Expectation</H5>
<P class="docText">Often it is useful in probability problems to think in terms of expectation. <span class="docEmphasis">Mathematical expectation</span> is the expected value of some discrete random variable, <span class="docEmphasis">X</span>, that can take on any values, <span class="docEmphasis">x</span><SUB>0</SUB>, <span class="docEmphasis">x</span><SUB>1</SUB>, <span class="docEmphasis">x</span><SUB>2</SUB>, &#8230;, <span class="docEmphasis">x</span><SUB>n</SUB>, with corresponding probabilities, <span class="docEmphasis">p</span><SUB>0</SUB>, <span class="docEmphasis">p</span><SUB>1</SUB>, <span class="docEmphasis">p</span><SUB>2</SUB>, &#8230;, <span class="docEmphasis">p</span><SUB>n</SUB>. You calculate the expectation for such a distribution of outcomes as follows:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq06.jpg" ALT="figs/ch12_ueq06.jpg">
<P class="docText">For distributions such as this, you can think of the expectation as an average value. Statisticians think of expectation as a measure of central tendency. Decision theorists think of expectation as some measure of payoff.</P>
<P class="docText">As a very simple example, if you stand to win $100 with a probability of 0.12, your expectation is $12—that is, $100 times 0.12.</P>
<P class="docText">As another example, say you have a perpetual online role-playing game in which you monitor the number of players who gather at the local tavern each evening. Let's assume from this monitoring you establish the probabilities shown in <A class="docLink" HREF="#ch12_tab03">Table 12-3</A> for the number of players in the tavern each evening. Let's further assume that the samples you used to calculate these frequency-based probabilities were all taken at about the same time of day; for example, you might have a spy casing the tavern every night collecting intelligence for an upcoming invasion.</P>
<A NAME="ch12_tab03"></A><P><TABLE CELLSPACING="0" FRAME="hsides" RULES="all" CELLPADDING="4" WIDTH="100%"><CAPTION><h5 class="docTableTitle">Table 12.3. Probabilities of number of players in tavern each evening</h5></CAPTION><COLGROUP><COL><COL></COLGROUP><THEAD><TR><TH class="thead" align="center"><P class="docText"># Players</P></TH><TH class="thead"><P class="docText">Probability</P></TH></TR></THEAD><TR><TD class="docTableCell"><P class="docText">0</P></TD><TD class="docTableCell"><P class="docText">0.02</P></TD></TR><TR><TD class="docTableCell"><P class="docText">2</P></TD><TD class="docTableCell"><P class="docText">0.08</P></TD></TR><TR><TD class="docTableCell"><P class="docText">4</P></TD><TD class="docTableCell"><P class="docText">0.20</P></TD></TR><TR><TD class="docTableCell"><P class="docText">6</P></TD><TD class="docTableCell"><P class="docText">0.24</P></TD></TR><TR><TD class="docTableCell"><P class="docText">8</P></TD><TD class="docTableCell"><P class="docText">0.17</P></TD></TR><TR><TD class="docTableCell"><P class="docText">10</P></TD><TD class="docTableCell"><P class="docText">0.13</P></TD></TR><TR><TD class="docTableCell"><P class="docText">12</P></TD><TD class="docTableCell"><P class="docText">0.10</P></TD></TR><TR><TD class="docTableCell"><P class="docText">14</P></TD><TD class="docTableCell"><P class="docText">0.05</P></TD></TR><TR><TD class="docTableCell"><P class="docText">16</P></TD><TD class="docTableCell"><P class="docText">0.01</P></TD></TR></TABLE></P><br>
<P class="docText">Note that this distribution forms a mutually exclusive, exhaustive set. That is, there can't be, say, zero and eight players there at the same time—it has to be one or the other—and the sum of probabilities for all these outcomes must be equal to 1. In this case, the expectation, the expected number of players in the tavern in the evening, is equal to 7.1. You can calculate this by taking the sum of the products of each pair of numbers appearing in each row of the table. Therefore, in any given evening, one can expect to find about seven players in the tavern, on average. Note that using this kind of analysis, an invading force could estimate how many units to send toward the tavern to take control of it.</P>

<A NAME="ch12_sect3_003"></A>
<H5 class="docSection3Title">12.2.3 Techniques for Assigning Subjective Probability</H5>
<P class="docText">As we stated earlier, it is often very difficult to pin subjective probabilities to a specific number. Although you might have a good feel for the probability of some event, you might find it difficult to actually assign a single number to the probability of that event. To help in this regard, several commonly used metaphors are available to assist you in assigning numbers to subjective probabilities. We briefly discuss two of them here.</P>
<P class="docText">The first technique we can use to assign subjective probabilities is a betting metaphor. Let's return to the promotion example we discussed earlier. Let's say that another co-worker asked if you're willing to make a wager on whether you'll get the promotion. If the co-worker takes the side that you won't get the promotion and is willing to put up $1 on the bet, but then asks for 9 to 1 odds, you'll have to pay $9 if you lose and you'll gain $1 if you win. Would you accept this bet? If you would, you consider this a fair bet and you essentially are saying you believe you'll get the promotion with a probability of 90%. You can calculate this by considering the odds to which you agreed and using the relationship between odds and probability we discussed earlier. If you rejected these odds but instead offered 4 to 1 odds in favor of you getting the promotion, you essentially are saying you believe the probability that you'll get the promotion is 4/5 or 80%.</P>
<P class="docText">Underlying this approach is the premise that you believe that the agreed-upon odds constitute a fair bet. Subjectively, a fair bet is one in which the expected gain is 0 and it does not matter to you which side of the bet you choose. Let's say you took the 9 to 1 odds and you thought this was a fair bet. In this case, you expect to win ($1)(0.9) or 90 cents. This is simply the amount you will win times the probability that you will win. At the same time you expect to lose ($9)(0.1) or 90 cents—the amount you are wagering times the probability that you will lose. Therefore, the net gain you expect is your expected winnings minus your expected loss, which is clearly 0. Now, if you took this bet with 9 to 1 odds, but you really felt that your probability of successfully getting the promotion was only 80% as compared to 90%, your expected gain would be:</P>
<IMG BORDER="0" id="" ALIGN="center" SRC="images/0596005555/figs/ch12_ueq07.jpg" ALT="figs/ch12_ueq07.jpg">
<P class="docText">In this case you'd expect to lose $1, which indicates that this would not be a fair bet.</P>
<P class="docText">The betting metaphor we described here is the so-called <span class="docEmphasis">put up or shut up</span> approach in which you're required to really think about the probability in terms of what you'd be willing to wager on the outcome. The idea is that you should get a pretty good sense of your true belief about a particular outcome.</P>
<P class="docText">There's a problem with this approach, however, that is due to individual tolerances for risk. When we're talking about $1 versus $9, the idea of losing $9 might not be that significant to you and you might have a greater propensity to take these odds. However, what if the bets were $100 and $900, or perhaps even $1000 and $9000? Certainly, most rational people who don't own a money tree would think a little harder about their belief in some outcome occurring when larger sums of money are at stake. In some cases, the risk of losing so much money would override their belief in a certain outcome occurring, even if their subjective probability were well founded. And therein lies the problem in using this technique when perceived risk becomes significant: a person's subjective probability could be biased by the risk they perceive.</P>
<P class="docText">An alternative to the betting metaphor is the so-called <span class="docEmphasis">fair price</span> metaphor whereby instead of betting on the outcome of an event, you ask yourself to put a fair price on some event. For example, let's consider an author of a book who stands to earn $30,000 in royalties if the book he wrote is successful. Further, suppose that he will get nothing if the book fails. Now suppose the author is given the option by his publisher of taking an upfront, guaranteed payment of $10,000, but if he accepts he forfeits any further royalty rights. The question now is, what is the author's subjective probability, his belief, that the book will be successful?</P>
<P class="docText">If the author accepts the deal, we can infer that $10,000 is greater than his expectation—that is, <span class="docEmphasis">$10,000 <img src=images/ent/U2265.GIF border=0> ($30,000)(p)</span>, where <span class="docEmphasis">p</span> is his assigned subjective probability of the book's success. Therefore, in this case his belief that the book will be successful as expressed by <span class="docEmphasis">p</span> is less than 0.33 or 33%. To get this we simply solve for <span class="docEmphasis">p</span>—that is, <span class="docEmphasis">p <img src=images/ent/U2265.GIF border=0> $10,000/$30,000</span>. If the author rejects the deal, he evidently feels the book has greater than a 33% chance of success—that is, his expectation is greater than $10,000.</P>
<P class="docText">To narrow down what the author feels the probability of success of the book actually is, we can simply ask him what he would take up front—we ask him what he thinks is a fair price for the rights to the book. From his reply we can calculate the subjective probability that he has assigned for the book's success using the formula for expectation as before. If <span class="docEmphasis">U</span> is the amount he would accept up front, the subjective probability of the book's success, <span class="docEmphasis">p</span>, is simply <span class="docEmphasis">U/$30,000</span>.</P>
<P class="docText">You can come up with various versions of this fair-price metaphor yourself depending on for what it is you're trying to estimate a subjective probability. The idea here is to eliminate any bias that might be introduced when considering scenarios in which your own money is at risk, as in the betting technique.</P>



<ul></ul></td></tr></table>
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch12_sect1_001.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch12_sect1_003.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
</body>
</html>
