<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>14.1 Dissecting Neural Networks</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body >
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch14_sect1_000.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch14_sect1_002.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch14_sect1_001"></A>
<H3 class="docSection1Title">14.1 Dissecting Neural Networks</H3>
<P class="docText">In this section we're going to dissect a three-layer feed-forward neural network, looking at each of its components to see what they do, why they are important, and how they work. The aim here is to clearly and concisely take the mystery out of neural networks. We'll take a rather practical approach to this task and leave some of the more academic aspects to other books on the subject. We will give references to several such books throughout this chapter.</P>
<A NAME="ch14_sect2_004"></A>
<H4 class="docSection2Title">14.2.4 Structure</H4>
<P class="docText">We focus on three-layer feed-forward networks in this chapter. <A class="docLink" HREF="#ch14_fig05">Figure 14-5</A> illustrates the basic structure of such a network.</P>
<A NAME="ch14_fig05"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-5. Three-layer feed-forward neural network</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig05.jpg" ALT="figs/ch14_fig05.jpg">
</CENTER></p><br>
<P class="docText">A three-layer network consists of one <span class="docEmphasis">input layer</span>, one <span class="docEmphasis">hidden layer</span>, and one <span class="docEmphasis">output layer</span>. There's no restriction on the number of neurons within each layer. Every neuron from the input layer is connected to every neuron in the hidden layer. Further, every neuron in the hidden layer is connected to every neuron in the output layer. Also, every neuron, with the exception of the input layer, has an additional input called the <span class="docEmphasis">bias</span>. The numbers shown in <A class="docLink" HREF="#ch14_fig05">Figure 14-5</A> serve to identify each node in the three layers. We'll use this numbering system later when we write the formulas for calculating the value of each neuron.</P>
<P class="docText">Calculating the output value(s) for a network starts with some input provided to each input neuron. Then these inputs are weighted and passed along to the hidden-layer neurons. This process repeats, going from the hidden layer to the output layer, where the output of the hidden-layer neurons serves as input to the output layer. This process of going from input to hidden to output layer is the feed-forward process. We'll look at each component of this type of network in more detail in the following sections.</P>

<A NAME="ch14_sect2_005"></A>
<H4 class="docSection2Title">14.2.5 Input</H4>
<P class="docText">Inputs to a neural network obviously are very important; without them there's nothing for the neural network to process. Clearly we need them, but what should you choose as inputs? How many do you need? And what form should they take?</P>
<A NAME="ch14_sect3_001"></A>
<H5 class="docSection3Title">14.2.1 Input: What and How Many?</H5>
<P class="docText">The question of what to choose as input is very problem-specific. You have to look at the problem you're trying to solve and select what game parameters, data, and environment characteristics are important to the task at hand. For example, say you're designing a neural network to classify player characters in a role-playing game so that the computer-controlled creatures can decide whether they want to engage the player. Some inputs you might consider include some indication of the player's attire, his drawn weapon if present, and perhaps any witnessed actions—for example, whether his just cast a spell.</P>
<P class="docText">Your job of training the neural network, which we'll discuss later, will be easier if you keep the number of input neurons to a minimum. However, in some situations the inputs to select won't always be obvious to you. In such cases, the general rule is to include what inputs you think might be important and let the neural network sort out for itself which ones are important. Neural networks excel at sorting out the relative importance of inputs to the desired output. Keep in mind, however, that the more inputs you throw in, the more data you're going to have to prepare to train the network, and the more computations you'll have to make in the game.</P>
<P class="docText">Often you can reduce the number of inputs by combining or transforming important information into some other, more compact form. As a simple example, let's say you're trying to use a neural network to control a spacecraft landing on a planet in your game. The mass of the spacecraft, which could be variable, and the acceleration due to gravity on the planet clearly are important factors, among others, that you should provide as input to the neural network. You could, in fact, create one input neuron for each parameter—one for the mass and another for the acceleration due to gravity. However, this approach forces the neural network to perform extra work in figuring out a relationship between the spacecraft's mass and the acceleration due to gravity. A better input capturing these two important parameters is a single neuron that takes the weight of the spacecraft—the product of its mass times the acceleration due to gravity—as an input to a single neuron. There would, of course, be other input neurons besides this one, for example, you probably would have altitude and speed inputs as well.</P> 
<A NAME="ch14_sect3_002"></A>
<H5 class="docSection3Title">14.2.2 Input: What Form?</H5>
<P class="docText">You can use a variety of forms of data as inputs to a neural network. In games, such input generally consists of three types: boolean, enumerated, and continuous types. Neural networks work with real numbers, so whatever the type of data you have, it must be converted to a suitable real number for use as input.</P>
<P class="docText">Consider the example shown in <A class="docLink" HREF="ch14_sect1_000.html#ch14_fig04">Figure 14-4</A>. The "enemy engaged" input is clearly a boolean type—<span class="docEmphasis">true</span> if the enemy is engaged and <span class="docEmphasis">false</span> otherwise. However, we can't pass <span class="docEmphasis">true</span> or <span class="docEmphasis">false</span> to a neural network input node. Instead, we input a 1.0 for <span class="docEmphasis">true</span> and a 0.0 for <span class="docEmphasis">false</span>.</P>
<P class="docText">Sometimes your input data might be enumerated. For example, say you have a network designed to classify an enemy, and one consideration is the kind of weapon he is wielding. The choices might be something such as dagger, bastard sword, long sword, katana, crossbow, short bow, or longbow. The order does not matter here, and we assume that these possibilities are mutually exclusive. Typically you handle such data in neural networks using the so-called <span class="docEmphasis">one-of-n</span> encoding method. Basically, you create an input for each possibility and set the input value to 1.0 or 0.0 corresponding to whether each specific possibility is <span class="docEmphasis">true</span>. If, for example, the enemy was wielding a katana, the input vector would be {0, 0, 0, 1, 0, 0, 0} where the 1 is set for the katana input node and the <span class="docEmphasis">0</span>s are set for all other possibilities.</P>
<P class="docText">Very often your data will, in fact, be a floating-point number or an integer. In either case this type of data generally can take on any number of values between some practical upper and lower bounds. You simply can input these values directly into the neural network (which game developers often do).</P>
<P class="docText">This can cause some problems, however. If you have input values that vary widely in terms of order of magnitude, the neural network might give more weight to the larger-magnitude input. For example, if one input ranges from 0 to 20 while another ranges from 0 to 20,000, the latter likely will swamp out the influence of the former. Thus, in these cases it is important to scale such input data to ranges that are comparable in terms of order of magnitude. Commonly, you can scale such data in terms of percentage values ranging from 0 to 100, or to values ranging from 0 to 1. Scaling in this way levels the playing field for the various inputs. You must be careful how you scale, however. You need to make sure the data used to train your network is scaled in the exact same way as the data the network will see in the field. For example, if you scale a distance input value by the screen width for your training data, you must use the same screen width to scale your input data when the network is functioning in your game.</P> 

<A NAME="ch14_sect2_006"></A>
<H4 class="docSection2Title">14.2.6 Weights</H4>
<P class="docText"><span class="docEmphasis">Weights</span> in a neural network are analogous to the synaptic connection in a biological neural network. The weights affect the strength of a given input and can be either inhibitory or excitatory. It is the weights that truly define the behavior of a neural network. Further, the task of determining the value of these weights is the subject of <span class="docEmphasis">training</span> or <span class="docEmphasis">evolving</span> a neural network.</P>
<P class="docText">Every connection from one neuron to another has an associated weight. This is illustrated in <A class="docLink" HREF="#ch14_fig05">Figure 14-5</A>. The input to a neuron is then the sum of the products of each input's weight connecting that neuron times its input value plus a bias term, which we'll discuss later. The net result is called the <span class="docEmphasis">net input</span> to a neuron. The following equation shows how the net input to a given neuron, neuron <span class="docEmphasis">j</span>, is calculated from a set of input, <span class="docEmphasis">i</span>, neurons.</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq01.jpg" ALT="figs/ch14_ueq01.jpg">
<P class="docText">Referring to <A class="docLink" HREF="#ch14_fig05">Figure 14-5</A>, you can see that every input to a neuron is multiplied by the weight of the connection between those two neurons plus the bias. Let's look at a simple example (we'll take a look at source code for these calculations later).</P>
<P class="docText">Let's say we want to calculate the net input to the 0<SUP>th</SUP> neuron in the hidden layer shown in <A class="docLink" HREF="#ch14_fig05">Figure 14-5</A>. Applying the previous equation, we get the following formula for the net input to the 0<SUP>th</SUP> neuron in the hidden layer:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq02.jpg" ALT="figs/ch14_ueq02.jpg">
<P class="docText">In this formula the <span class="docEmphasis">n</span>s represents the value of the neuron. In the case of the input neurons, these are the input values. In the case of the hidden neurons, they are the net input values. The superscripts <span class="docEmphasis">h</span> and <span class="docEmphasis">i</span> represent to which layer the neuron belongs—<span class="docEmphasis">h</span> for the hidden layer and <span class="docEmphasis">i</span> for the input layer. The subscripts indicate the node within each layer.</P>
<P class="docText">Notice here that the net input to a given neuron is simply a linear combination of weighted inputs from other neurons. If this is so, how does a neural network approximate highly nonlinear functions such as those we mentioned earlier? The key lies in how the net input is transformed to an output value for a neuron. Specifically, <span class="docEmphasis">activation functions</span> map the net input to a corresponding output in a nonlinear way.</P>

<A NAME="ch14_sect2_007"></A>
<H4 class="docSection2Title">14.2.7 Activation Functions</H4>
<P class="docText">An activation function takes the net input to a neuron and operates on it to produce an output for the neuron. Activation functions should be nonlinear (except in one case, which we'll discuss shortly). If they are not, the neural network is reduced to a linear combination of linear functions and is rendered incapable of approximating nonlinear functions and relationships.</P>
<P class="docText">The most commonly used activation function is the <span class="docEmphasis">logistic</span> function or <span class="docEmphasis">sigmoid</span> function. <A class="docLink" HREF="#ch14_fig06">Figure 14-6</A> illustrates this S-shaped function.</P>
<A NAME="ch14_fig06"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-6. Logistic activation function</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig06.jpg" ALT="figs/ch14_fig06.jpg">
</CENTER></p><br>
<P class="docText">The formula for the logistic function is as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq03.jpg" ALT="figs/ch14_ueq03.jpg">
<P class="docText">Sometimes this functions is written in thes form:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq04.jpg" ALT="figs/ch14_ueq04.jpg">
<P class="docText">In this case, the <span class="docEmphasis">c</span> term is used to alter the shape of the function—that is, either stretching or compressing the function along the horizontal axis.</P>
<P class="docText">Note that the input lies along the horizontal axis and the output from this function ranges from 0 to 1 for all values of <span class="docEmphasis">x</span>. In practice the working range is more like 0.1 to 0.9, where a value of around 0.1 implies the neuron is unactivated and a value of around 0.9 implies the neuron is activated. It is important to note that no matter how large (positive or negative) <span class="docEmphasis">x</span> gets, the logistic function will never actually reach 1.0 or 0.0; it asymptotes to these values. You must keep this in mind when training. If you attempt to train your network so that it outputs a value of 1 for a given output neuron, you'll never get there. A more reasonable value is 0.9, and shooting for this value will speed up training immensely. The same applies if you are trying to train a network to output a value of 0. Use something such as 0.1 instead.</P>
<P class="docText">Other activation functions are at your disposal as well. <A class="docLink" HREF="#ch14_fig07">Figures 14-7</A> and <A class="docLink" HREF="#ch14_fig08">14-8</A> show two other well-known activation functions: the step function and the hyperbolic tangent function.</P>
<A NAME="ch14_fig07"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-7. Step activation function</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig07.jpg" ALT="figs/ch14_fig07.jpg">
</CENTER></p><br>
<A NAME="ch14_fig08"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-8. Hyperbolic activation tangent function</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig08.jpg" ALT="figs/ch14_fig08.jpg">
</CENTER></p><br>
<P class="docText">The formula for the step function is as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq05.jpg" ALT="figs/ch14_ueq05.jpg">
<P class="docText">Step functions were used in early neural network development, but their lack of a derivative made training tough. Note that the logistic function has an easy-to-evaluate derivative, which is needed for training the network, as we'll see shortly.</P>
<P class="docText">The formula for the hyperbolic tangent function is as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq06.jpg" ALT="figs/ch14_ueq06.jpg">
<P class="docText">The hyperbolic tangent function is sometimes used and is said to speed up training. Other activation functions are used in neural networks for various applications; however, we won't get into those here. In general, the logistic function seems to be the most widely used and is applicable to a large variety of applications.</P>
<P class="docText"><A class="docLink" HREF="#ch14_fig09">Figure 14-9</A> shows yet another activation function that sometimes is used—a linear activation function.</P>
<A NAME="ch14_fig09"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-9. Linear activation function</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig09.jpg" ALT="figs/ch14_fig09.jpg">
</CENTER></p><br>
<P class="docText">The formula for the linear activation function is simply:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq07.jpg" ALT="figs/ch14_ueq07.jpg">
<P class="docText">This means that the output of a neuron is simply the net input—that is, the sum of the weighted inputs from all connected input neurons plus the bias term.</P>
<P class="docText">Linear activation functions sometimes are used as the activation functions for output neurons. Note that nonlinear activation functions must be used for the hidden neurons if the network is not to be reduced to a linear combination of linear functions. Employing such a linear output neuron is sometimes useful when you don't want the output confined to an interval between 0 and 1. In such cases, you still can use a logistic output activation function, so long as you scale the output to the full range of values for which you're interested.</P> 
<A NAME="ch14_sect2_008"></A>
<H4 class="docSection2Title">14.2.8 Bias</H4>
<P class="docText">When we discussed how to calculate the net input to a neuron earlier, we mentioned that each neuron has a bias associated with it. This is represented as a bias value and a bias weight for each neuron and shows up in the net input formula we showed earlier and are showing again here for convenience:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq08.jpg" ALT="figs/ch14_ueq08.jpg">
<P class="docText"><span class="docEmphasis">b</span><SUB><span class="docEmphasis">j</span></SUB> is the bias value and <span class="docEmphasis">w</span><SUB><span class="docEmphasis">j</span></SUB> is the bias weight.</P>
<P class="docText">To understand what the bias does, you have to look at the activation functions used to generate output for a neuron given the net input. Basically, the bias term shifts the net input along the horizontal axis of the activation function, which effectively changes the threshold at which a neuron activates. The bias value always is set to 1 or -1 and its weight is adjusted through training, just like all other weights. This essentially allows the neural network to learn the appropriate thresholds for each neuron's activation.</P>
<P class="docText">Some practitioners always set the bias value to 1, while others always use -1. In our experience it really doesn't matter whether you use 1 or -1 because, through training, the network will adjust its bias weights to suit your choice. Weights can be either positive or negative, so if the neural network thinks the bias should be negative, it will adjust the weight to achieve that, regardless of your choice of 1 or -1. If you choose 1, it will find a suitable negative weight, whereas if you choose -1, it will find a suitable positive weight. Of course, you achieve all of this through training or evolving the network, as we'll discuss later in this chapter.</P>

<A NAME="ch14_sect2_009"></A>
<H4 class="docSection2Title">14.2.9 Output</H4>
<P class="docText">Just like input, your choice of output neurons for a given network is problem-specific. In general, it's best to keep the number of output neurons to a minimum to reduce computation and training time.</P>
<P class="docText">Consider a network in which, given certain input, you desire output that classifies that input. Perhaps you want to determine whether a given set of input falls within a certain class. In this case, you would use one output neuron. If it is activated, the result is <span class="docEmphasis">true</span>, whereas if it is not activated, the result is <span class="docEmphasis">false</span>—the input does not fall within the class under consideration. If you were using a logistic function as your output activation, an output of around 0.9 would indicate activated, or <span class="docEmphasis">true</span>, whereas an output of around 0.1 would indicate not activated, or <span class="docEmphasis">false</span>. In practice, you might not actually get output values of exactly 0.9 or 0.1; you might get 0.78 or 0.31, for example. Therefore, you have to define a threshold that will enable you to assess whether a given output value indicates activation. Generally, you simply choose an output threshold midway between the two extremes. For the logistic function, you can use 0.5. If the output is greater than 0.5, the result is activated or <span class="docEmphasis">true</span>, otherwise it's <span class="docEmphasis">false</span>.</P>
<P class="docText">When you're interested in whether certain input falls within more than a single class, you have to use more than a single output neuron. Consider the network shown in <A class="docLink" HREF="ch14_sect1_000.html#ch14_fig03">Figure 14-3</A>. Here, essentially we want to classify the threat posed by an enemy; the classes are aerial threat, ground threat, both aerial and ground threats, or no threat. We have one output neuron for each class. For this type of output we assume that high output values imply activated, while low output values imply not activated. The actual output values for each node can cover a range of values, depending on how the network was trained and on the kind of output activation function used. Given a set of input values and the resulting value at each output node, one way to figure out which output is activated is to take the neuron with the highest output value. This is the so-called <span class="docEmphasis">winner-take-all</span> approach. The neuron with highest activation indicates the resulting class. We'll see an example of this approach later in this chapter.</P>
<P class="docText">Often, you want a neural network that will generate a single value given a set of input. Time-series prediction, whereby you try to predict the next value given historical values over time, is one such situation in which you'll use a single output neuron. In this case, the value of the output neuron corresponds to the predicted value of interest. Keep in mind, however, you might have to scale the result if you're using an output activation function that generates bounded values, such as the logistic function, and if the value of the quantity you're trying to predict falls within some other range.</P>
<P class="docText">In other cases, such as that illustrated in <A class="docLink" HREF="ch14_sect1_000.html#ch14_fig02">Figure 14-2</A>, you might have more than one output neuron that's used to directly control some other system. In the case of the example shown in <A class="docLink" HREF="ch14_sect1_000.html#ch14_fig02">Figure 14-2</A>, the output values control the motion of each track for a half-track robot. In that example, it might be useful to use the hyperbolic tangent function for the output neurons so that the output value will range between -1 and +1. Then, negative values could indicate backward motion while positive values could indicate forward motion.</P>
<P class="docText">Sometimes you might require a network with as many output neurons as input neurons. Such networks commonly are used for autoassociation (pattern recognition) and data compression. Here, the aim is that the output neurons should echo the input values. For pattern recognition, such a network would be trained to output its input. The training set would consist of many sample patterns of interest. The idea here is that when presented with a pattern that's either degraded somewhat or does not exactly match a pattern that was included in the training set, the network should produce output that represents the pattern included in its training set that most closely matches the one being input.</P> 
<A NAME="ch14_sect2_010"></A>
<H4 class="docSection2Title">14.2.10 The Hidden Layer</H4>
<P class="docText">So far we've discussed input neurons, output neurons, and how to calculate net inputs for any neuron, but we've yet to discuss the hidden layer specifically. In our three-layer feed-forward network, we have one hidden layer of neurons sandwiched between the input and output layers.</P>
<P class="docText">As illustrated in <A class="docLink" HREF="#ch14_fig05">Figure 14-5</A>, every input is connected to every hidden neuron. Further, every hidden neuron sends its output to every output neuron. By the way, this isn't the only neural network structure at your disposal; there are all sorts—some with more than one hidden layer, some with feedback, and some with no hidden layer at all, among others. However, it is one of the most commonly used configurations. At any rate, the hidden layer is crucial for giving the network facility to process features in the input data. The more hidden neurons, the more features the network can handle; conversely, the fewer hidden neurons, the fewer features the network can handle.</P>
<P class="docText">So, what do we mean by features? To understand what we mean here, it's helpful to think of a neural network as a function approximator. Say you have a function that looks very noisy, as illustrated in <A class="docLink" HREF="#ch14_fig10">Figure 14-10</A>.</P>
<A NAME="ch14_fig10"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-10. Noisy function</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig10.jpg" ALT="figs/ch14_fig10.jpg">
</CENTER></p><br>
<P class="docText">If you were to train a neural network to approximate such a function using too few hidden neurons, you might get something such as that shown in <A class="docLink" HREF="#ch14_fig11">Figure 14-11</A>.</P>
<A NAME="ch14_fig11"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-11. Approximation of noisy function using too few neurons</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig11.jpg" ALT="figs/ch14_fig11.jpg">
</CENTER></p><br>
<P class="docText">Here, you can see that the approximated function captures the trend of the input data but misses the local noisy features. In some cases, such as for signal noise reduction applications, this is exactly what you want; however, you might not want this for other problems. If you go the other route and choose too many hidden neurons, the approximated function likely will pick up the local noisy features in addition to the overall trend of the function. In some cases, this might be what you want; however, in other cases, you might end up with a network that is overtrained and unable to generalize given new input data that was not part of the training set.</P>
<P class="docText">Exactly how many hidden neurons to use for a given application is hard to say with certainty. Generally, you go about it by trial and error. However, here's a rule of thumb that you might find useful. For three-layer networks in which you're not interested in autoassociation, the appropriate number of hidden neurons is approximately equal to the square root of the product of the number of input and output neurons. This is just an approximation, but it's as good a place to start as any. The thing to keep in mind, particularly for games in which CPU usage is critical, is that the larger the number of hidden neurons, the more time it will take to compute the output of the network. Therefore, it's beneficial to try to minimize the number of hidden neurons.</P>


<ul></ul></td></tr></table>
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch14_sect1_000.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch14_sect1_002.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
</body>
</html>
