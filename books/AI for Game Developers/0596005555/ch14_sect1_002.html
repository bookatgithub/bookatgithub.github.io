<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>14.2 Training</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body >
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch14_sect1_001.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch14_sect1_003.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch14_sect1_002"></A>
<H3 class="docSection1Title">14.2 Training</H3>
<P class="docText">So far, we've repeatedly mentioned training a neural network without actually giving you the details as to how to do this. We'll tackle that now in this section.</P>
<P class="docText">The aim of training is to find the values for the weights that connect all the neurons such that the input data generates the desired output values. As you might expect, there's more to training than just picking some weight values. Essentially, training a neural network is an optimization process in which you are trying to find optimal weights that will allow the network to produce the right output.</P>
<P class="docText">Training can fall under two categories: <span class="docEmphasis">supervised</span> training and <span class="docEmphasis">unsupervised</span> training. Covering all or even some of the popular training approaches is well beyond a single chapter, so we'll focus on one of the most commonly used supervised training methods: <span class="docEmphasis">back-propagation</span>.</P>
<A NAME="ch14_sect2_011"></A>
<H4 class="docSection2Title">14.2.11 Back-Propagation Training</H4>
<P class="docText">Again, the aim of training is to find the values for the weights that connect all the neurons such that the input data generates the desired output values. To do this, you need a training set, which consists of both input data and the desired output values corresponding to that input. The next step is to iteratively, using any of a number of techniques, find a set of weights for the entire network that causes the network to produce output matching the desired output for each set of data in the training set. Once you do this, you can put the network to work and present it with new data, not included in the training set, to produce output that is reasonable.</P>
<P class="docText">Because training is an optimization process, we need some measure of merit to optimize. In the case of back-propagation, we use a measure of error and try to minimize the error. Given some input and the generated output, we need to compare the generated output with the known, desired output and quantify how well the results match—i.e., calculate the error. Many error measures are available for you to use, and we'll use one of the most common ones here: the mean square error, which is simply the average of the square of the differences between the calculated output and the desired output.</P>
<P class="docText">If you've studied calculus you might recall that to minimize or maximize a function you need to be able to calculate the function's derivative. Because we're trying to optimize weights by minimizing the error measure, it's no surprise that we need to calculate a derivative somewhere. Specifically, we need the derivative of the activation function, and this is why the logistic function is so nice—we easily can determine its derivative analytically.</P>
<P class="docText">As we mentioned earlier, finding the optimum weights is an iterative process, and it goes something like this:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList">Start with a training set consisting of input data and corresponding desired outputs.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">Initialize the weights in the neural network to some small random values.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">With each set of input data, feed the network and calculate the output.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">Compare the calculated output with the desired output and compute the error.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">Adjust the weights to reduce the error, and repeat the process.</P></span></LI></OL></span>
<P class="docText">You can execute the process in two ways. One way is to calculate the error measure, adjust the weights for each set of input and desired output data, and then move on to the next set of input/output data. The other way is to calculate the cumulative error for all sets of input and desired output data in the training set, then adjust the weights, and then repeat the process. Each iteration is known as an <span class="docEmphasis">epoch</span>.</P>
<P class="docText">Steps 1 through 3 are relatively straightforward and we'll see an example implementation a little later. Now, though, let's examine steps 4 and 5 more closely.</P>
<A NAME="ch14_sect3_003"></A>
<H5 class="docSection3Title">14.2.3 Computing Error</H5>
<P class="docText">To train a neural network, you feed it a set of input, which generates some output. To compare this calculated output to the desired output for a given set of input, you need to calculate the error. This enables you to not only determine whether the calculated output is right or wrong, but also to determine the degree to which it is right or wrong. The most common error to use is the mean-square error, which is the average of the square of the difference between the desired and calculated output:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq09.jpg" ALT="figs/ch14_ueq09.jpg">
<P class="docText">In this equation, <img src=images/ent/U220A.GIF border=0> is the mean square error for the training set. <span class="docEmphasis">n</span><SUB>c</SUB> and <span class="docEmphasis">n</span><SUB>d</SUB> are the calculated and desired output values, respectively, for all output neurons, while <span class="docEmphasis">m</span> is the number of output neurons for each epoch.</P>
<P class="docText">The goal is to get this error value as small as is practical by iteratively adjusting the weight values connecting all the neurons in the network. To know how much the weights need adjusting, each iteration requires that we also calculate the error associated with each neuron in the output and hidden layers. We calculate the error for output neurons as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq10.jpg" ALT="figs/ch14_ueq10.jpg">
<P class="docText">Here, <font face="symbol">d</font><SUB>i</SUB><SUP>o</SUP> is the error for the <span class="docEmphasis">i</span><SUP>th</SUP> output neuron, <font face="symbol">D</font><span class="docEmphasis">n</span><SUB>i</SUB><SUP>o</SUP> is the difference between the calculated and desired output for the <span class="docEmphasis">i</span><SUP>th</SUP> output neuron, and <span class="docEmphasis">f'(n<SUB>ci</SUB><SUP>o</SUP>)</span> is the derivative of the activation function for the <span class="docEmphasis">i</span><SUP>th</SUP> output neuron. Earlier we told you that we'd need to calculate a derivative somewhere, and this is where to do it. This is why the logistic function is so useful; its derivative is quite simple in form, and it's easy to calculate it analytically. Rewriting this equation using the derivative of the logistic function yields the following equation for output neuron error:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq11.jpg" ALT="figs/ch14_ueq11.jpg">
<P class="docText">In this equation, <span class="docEmphasis">n</span><SUB><span class="docEmphasis">di</span></SUB><SUP>o</SUP> is the desired output value for the <span class="docEmphasis">i</span><SUP>th</SUP> neuron, and <span class="docEmphasis">n</span><SUB>ci</SUB><SUP>o</SUP> is the calculated output value for the <span class="docEmphasis">i</span><SUP>th</SUP> neuron.</P>
<P class="docText">For hidden-layer neurons, the error equation is somewhat different. In this case, the error associated with each hidden neuron is as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq12.jpg" ALT="figs/ch14_ueq12.jpg">
<P class="docText">Notice here that the error for each hidden-layer neuron is a function of the error associated with each output-layer neuron to which the hidden neuron connects times the weight for each connection. This means that to calculate the error and, subsequently, to adjust weight, you need to work backward from the output layer toward the input layer.</P>
<P class="docText">Also notice that the activation function derivative is required again. Assuming the logistic activation function yields the following:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq13.jpg" ALT="figs/ch14_ueq13.jpg">
<P class="docText">Lastly, no error is associated with input layer neurons because those neuron values are given.</P>

<A NAME="ch14_sect3_004"></A>
<H5 class="docSection3Title">14.2.4 Adjusting Weights</H5>
<P class="docText">With calculated errors in hand, you can proceed to calculate suitable adjustments for each weight in the network. The adjustment to each weight is as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq14.jpg" ALT="figs/ch14_ueq14.jpg">
<P class="docText">In this equation, <font face="symbol">r</font> is the learning rate, <font face="symbol">d</font><SUB>i</SUB> is the error associated with the neurons being considered, and <span class="docEmphasis">n</span><SUB>i</SUB> is the value of the neuron being considered. The new weight is simply the old weight plus <font face="symbol">D</font>w.</P>
<P class="docText">Keep in mind that the weight adjustments will be made for each weight and the adjustment will be different for each weight. When updating the weights connecting output to hidden-layer neurons, the errors and values for the output neurons calculate the weight adjustment. When updating the weights connecting the hidden- to-input-layer neurons, the errors and values for the hidden-layer neurons are used.</P>
<P class="docText">The learning rate is a multiplier that affects how much each weight is adjusted. It's usually set to some small value such as 0.25 or 0.5. This is one of those parameters that you'll have to tune. If you set it too high, you might overshoot the optimum weights; if you set it too low, training might take longer.</P>

<A NAME="ch14_sect3_005"></A>
<H5 class="docSection3Title">14.2.5 Momentum</H5>
<P class="docText">Many back-propagation practitioners use a slight modification to the weight adjustments we just discussed. This modified technique is called <span class="docEmphasis">adding</span> <span class="docEmphasis">momentum</span>. Before showing you how to add momentum, let's first discuss why you might want to add momentum.</P>
<P class="docText">In any general optimization process the goal is to either minimize or maximize some function. More specifically, we're interested in finding the global minimum or maximum of the given function over some range of input parameters. The trouble is that many functions exhibit what are called <span class="docEmphasis">local minima</span> or <span class="docEmphasis">maxima</span>. These are basically hollows and humps in the function, as illustrated in <A class="docLink" HREF="#ch14_fig12">Figure 14-12</A>.</P>
<A NAME="ch14_fig12"></A><p><CENTER>
<H5 class="docFigureTitle">Figure 14-12. Local extrema</H5>
<IMG BORDER="0" SRC="images/0596005555/figs/ch14_fig12.jpg" ALT="figs/ch14_fig12.jpg">
</CENTER></p><br>
<P class="docText">In this example, the function has a global minimum and maximum over the range shown; but it also has several local minima and maxima, characterized by the smaller bumps and hollows.</P>
<P class="docText">In our case, we're interested in minimizing the error of our network. Specifically we're interested in finding the optimum weights that yield the global minimum error; however, we might run into a local minimum instead of a global minimum.</P>
<P class="docText">When network training begins, we initialize the weights to some small random values. We have no idea at that point how close those values are to the optimum weights; thus, we might have initialized the network near a local minimum rather than a global minimum. Without going into calculus, the technique by which we update the weights is called a <span class="docEmphasis">gradient descent</span> type of technique, whereby we use the derivative of the function in an attempt to steer toward a minimum value, which in our case is a minimum error value. The trouble is that we don't know if we get to a global minimum or a local minimum, and typically the <span class="docEmphasis">error-space</span>, as it's called for neural networks, is full of local minima.</P>
<P class="docText">This sort of problem is common among all optimization techniques and many different methods attempt to alleviate it. The momentum technique is one such technique used for neural networks. It does not eliminate the possibility of converging on a local minimum, but it is thought to help get out of them and head toward the global minimum, which is where it derives its name. Basically, we add a small additional fraction to the weight adjustment that is a function of the previous iteration's weight adjustment. This gives the weight adjustments a little push so that if a local minimum is being approached, the algorithm will, hopefully, overshoot the local minimum and proceed on toward the global minimum.</P>
<P class="docText">So, using momentum, the new formula that calculates the weight adjustment is as follows:</P>
<IMG BORDER="0" ALIGN="center" SRC="images/0596005555/figs/ch14_ueq15.jpg" ALT="figs/ch14_ueq15.jpg">
<P class="docText">In this equation, <font face="symbol">D</font><span class="docEmphasis">w</span>' is the weight adjustment from the previous iteration, and <font face="symbol">a</font> is the momentum factor. The momentum factor is yet another factor that you'll have to tune. It typically is set to some small fractional number between 0.0 and 1.0.</P>



<ul></ul></td></tr></table>
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch14_sect1_001.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch14_sect1_003.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
</body>
</html>
