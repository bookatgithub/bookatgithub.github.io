<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>14.3 Neural Network Source Code</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body >
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch14_sect1_002.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch14_sect1_004.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch14_sect1_003"></A>
<H3 class="docSection1Title" id="">14.3 Neural Network Source Code</H3>
<P class="docText">At last it's time to look at some actual source code that implements a three-layer feed-forward neural network. The following sections present two C++ classes that implement such a network. Later in this chapter, we'll look at an example implementation of these classes. Feel free to skip to the section entitled "Chasing and Evading with Brains" if you prefer to see how the neural network is used before looking at its internal details.</P>
<P class="docText">We need to implement two classes in the three-layer feed-forward neural network. The first class represents a generic layer. You can use it for input, hidden, and output layers. The second class represents the entire neural network composed of three layers. The following sections present the complete source code for each class.</P>
<A NAME="ch14_sect2_012"></A>
<H4 class="docSection2Title">14.2.12 The Layer Class</H4>
<P class="docText">The class <span class="docEmphasis">NeuralNetworkLayer</span> implements a generic layer in a multilayer feed-forward network. It is responsible for handling the neurons contained within the layer. The tasks it performs include allocating and freeing memory to store neuron values, errors, and weights; initializing weights; calculating neuron values; and adjusting weights. <A class="docLink" HREF="#ch14exm01">Example 14-1</A> shows the header for this class.</P>
<A NAME="ch14exm01"></A>
<H5 class="docExampleTitle">Example 14-1. NeuralNetworkLayer class</H5>
<PRE>
class NeuralNetworkLayer
{
public:
     int               NumberOfNodes;
     int               NumberOfChildNodes;
     int               NumberOfParentNodes;
     double**          Weights;
     double**          WeightChanges;
     double*           NeuronValues;
     double*           DesiredValues;
     double*           Errors;
     double*           BiasWeights;
     double*           BiasValues;
     double            LearningRate;
     bool              LinearOutput;
     bool              UseMomentum;
     double            MomentumFactor;
     NeuralNetworkLayer*     ParentLayer;
     NeuralNetworkLayer*     ChildLayer;
     NeuralNetworkLayer();
     void     Initialize(int NumNodes,
                            NeuralNetworkLayer* parent,
                            NeuralNetworkLayer* child);
     void     CleanUp(void);
     void     RandomizeWeights(void);
     void     CalculateErrors(void);
     void     AdjustWeights(void);
     void     CalculateNeuronValues(void);
};
</PRE><BR>


<P class="docText">Layers are connected to each other in a parent-child relationship. For example, the input layer is the parent layer for the hidden layer, and the hidden layer is the parent layer for the output layer. Also, the output layer is a child layer to the hidden layer, and the hidden layer is a child layer to the input layer. Note that the input layer has no parent and the output layer has no child.</P>
<P class="docText">The members of this class primarily consist of arrays to store neuron weights, values, errors, and bias terms. Also, a few members store certain settings governing the behavior of the layer. The members are as follows:</P>
<DL class="docList"><br><p><DT><span class="docPubcolor"><span class="docEmphasis">NumberOfNodes</span></span></DT></p>
<DD><P class="docList">This member stores the number of neurons, or nodes, in a given instance of the layer class.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">NumberOfChildNodes</span></span></DT></p>
<DD><P class="docList">This member stores the number of neurons in the child layer connected to a given instance of the layer class.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">NumberOfParentNodes</span></span></DT></p>
<DD><P class="docList">This member stores the number of neurons in the parent layer connected to a given instance of the layer class.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">Weights</span></span></DT></p>
<DD><P class="docList">This member is a pointer to a pointer to a double value. Basically, this represents a two-dimensional array of weight values connecting nodes between parent and child layers.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">WeightChanges</span></span></DT></p>
<DD><P class="docList">This member also is a pointer to a pointer to a double value, which accesses a dynamically allocated two-dimensional array. In this case, the values stored in the array are the adjustments made to the weight values. We need these to implement momentum, as we discussed earlier.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">NeuronValues</span></span></DT></p>
<DD><P class="docList">This member is a pointer to a double value, which accesses a dynamically allocated array storing the calculated values, or activations, for the neurons in the layer.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">DesiredValues</span></span></DT></p>
<DD><P class="docList">This member is a pointer to a double value, which accesses a dynamically allocated array storing the desired, or target, values for the neurons in the layer. We use this for the output array where we calculate errors given the calculated outputs and the target outputs from the training set.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">Errors</span></span></DT></p>
<DD><P class="docList">This member is a pointer to a double value, which accesses a dynamically allocated array storing the errors associated with each neuron in the layer.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">BiasWeights</span></span></DT></p>
<DD><P class="docList">This member is a pointer to a double value, which accesses a dynamically allocated array storing the bias weights connected to each neuron in the layer.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">BiasValues</span></span></DT></p>
<DD><P class="docList">This member is a pointer to a double value, which accesses a dynamically allocated array storing the bias values connected to each neuron in the layer. Note that this member is not really required because we usually set the bias values to either +1 or -1 and leave them alone.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">LearningRate</span></span></DT></p>
<DD><P class="docList">This member stores the learning rate, which calculates weight adjustments.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">LinearOutput</span></span></DT></p>
<DD><P class="docList">This member stores a flag indicating whether to use a linear activation function for the neurons in the layer. You use this only if the layer is an output layer. If this flag is <span class="docEmphasis">false</span>, use the logistic activation function instead. The default value is <span class="docEmphasis">false</span>.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">UseMomentum</span></span></DT></p>
<DD><P class="docList">This member stores a flag indicating whether to use momentum when adjusting weights. The default value is <span class="docEmphasis">false</span>.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">MomentumFactor</span></span></DT></p>
<DD><P class="docList">This member stores the momentum factor, as we discussed earlier. Use it only if the <span class="docEmphasis">UseMomentum</span> flag is <span class="docEmphasis">true</span>.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">ParentLayer</span></span></DT></p>
<DD><P class="docList">This member stores a pointer to an instance of a <span class="docEmphasis">NeuralNetworkLayer</span> representing the parent layer connected to the given layer instance. This pointer is set to <span class="docEmphasis">NULL</span> for input layers.</P></DD><br><p><DT><span class="docPubcolor"><span class="docEmphasis">ChildLayer</span></span></DT></p>
<DD><P class="docList">This member stores a pointer to an instance of a <span class="docEmphasis">NeuralNetworkLayer</span> representing the child layer connected to the given layer instance. This pointer is set to <span class="docEmphasis">NULL</span> for output layers.</P></DD></DL>
<P class="docText">The <span class="docEmphasis">NeuralNetworkLayer</span> class contains seven methods. Let's go through each one in detail, starting with the constructor shown in <A class="docLink" HREF="#ch14exm02">Example 14-2</A>.</P>
<A NAME="ch14exm02"></A>
<H5 class="docExampleTitle">Example 14-2. NeuralNetworkLayer constructor</H5>
<PRE>
NeuralNetworkLayer::NeuralNetworkLayer()
{
     ParentLayer = NULL;
     ChildLayer = NULL;
     LinearOutput = false;
     UseMomentum = false;
     MomentumFactor = 0.9;
}
</PRE><BR>


<P class="docText">The constructor is very simple. All it does is initialize a few settings that we've already discussed. The <span class="docEmphasis">Initialize</span> method, shown in <A class="docLink" HREF="#ch14exm03">Example 14-3</A>, is somewhat more involved.</P>
<A NAME="ch14exm03"></A>
<H5 class="docExampleTitle">Example 14-3. Initialize method</H5>
<PRE>
void NeuralNetworkLayer::Initialize(int NumNodes,
                                               NeuralNetworkLayer* parent,
                                               NeuralNetworkLayer* child)
{
     int     i, j;
     // Allocate memory
     NeuronValues = (double*) malloc(sizeof(double) *
                                               NumberOfNodes);
     DesiredValues = (double*) malloc(sizeof(double) *
                                               NumberOfNodes);
     Errors = (double*) malloc(sizeof(double) * NumberOfNodes);
     if(parent != NULL)
     {
          ParentLayer = parent;
     }
     if(child != NULL)
     {
          ChildLayer = child;
          Weights = (double**) malloc(sizeof(double*) *
                                              NumberOfNodes);
          WeightChanges = (double**) malloc(sizeof(double*) *
                                                      NumberOfNodes);
          for(i = 0; i&lt;NumberOfNodes; i++)
          {
               Weights[i] = (double*) malloc(sizeof(double) *
                                                      NumberOfChildNodes);
               WeightChanges[i] = (double*) malloc(sizeof(double) *
                                                         NumberOfChildNodes);
          }
          BiasValues = (double*) malloc(sizeof(double) *
                                        NumberOfChildNodes);
          BiasWeights = (double*) malloc(sizeof(double) *
                                         NumberOfChildNodes);
     } else {
          Weights = NULL;
          BiasValues = NULL;
          BiasWeights = NULL;
          WeightChanges = NULL;
     }
     // Make sure everything contains 0s
     for(i=0; i&lt;NumberOfNodes; i++)
     {
          NeuronValues[i] = 0;
          DesiredValues[i] = 0;
          Errors[i] = 0;
          if(ChildLayer != NULL)
               for(j=0; j&lt;NumberOfChildNodes; j++)
               {
                    Weights[i][j] = 0;
                    WeightChanges[i][j] = 0;
               }
     }
     // Initialize the bias values and weights
     if(ChildLayer != NULL)
          for(j=0; j&lt;NumberOfChildNodes; j++)
          {
               BiasValues[j] = -1;
               BiasWeights[j] = 0;
          }
}
</PRE><BR>


<P class="docText">The <span class="docEmphasis">Initialize</span> method is responsible for allocating all memory for the dynamic arrays used to store weights, values, errors, and bias values and weights for the neurons in the layer. It also handles initializing all these arrays.</P>
<P class="docText">The method takes three parameters: the number of nodes, or neurons, in the layer; a pointer to the parent layer; and a pointer to the child layer. If the layer is an input layer, <span class="docEmphasis">NULL</span> should be passed in for the parent layer pointer. If the layer is an output layer, <span class="docEmphasis">NULL</span> should be passed in for the child layer pointer.</P>
<P class="docText">Upon entering the method, memory for the <span class="docEmphasis">NeuronValues</span>, <span class="docEmphasis">DesiredValues</span>, and <span class="docEmphasis">Errors</span> arrays is allocated. All of these arrays are one-dimensional, with the number of entries defined by the number of nodes in the layer.</P>
<P class="docText">Next, the parent and child layer pointers are set. If the child layer pointer is not <span class="docEmphasis">NULL</span>, we have either an input layer or a hidden layer and memory for connection weights must be allocated. Because <span class="docEmphasis">Weights</span> and <span class="docEmphasis">WeightChanges</span> are two-dimensional arrays, we need to allocate the memory in steps. The first step involves allocated memory to hold pointers to <span class="docEmphasis">double</span> arrays. The number of entries here corresponds to the number of nodes in the layer. Next, for each entry we allocate another chunk of memory to store the actual array values. The size of these additional chunks corresponds to the number of nodes in the child layer. Every neuron in an input or hidden layer connects to every neuron in the associated child layer; therefore, the total size of the weight and weight adjustment arrays is equal to the number of neurons in the layer times the number of neurons in the child layer.</P>
<P class="docText">We also go ahead and allocate memory for the bias values and weights arrays. The sizes of these arrays are equal to the number of neurons in the connected child layer.</P>
<P class="docText">After all the memory is allocated, the arrays are initialized. For the most part we want everything to contain <span class="docEmphasis">0</span>s, with the exception of the bias values, where we set all the bias value entries to -1. Note that you can set these all to +1, as we discussed earlier.</P>
<P class="docText"><A class="docLink" HREF="#ch14exm04">Example 14-4</A> shows the <span class="docEmphasis">CleanUp</span> method, which is responsible for freeing all memory allocated in the <span class="docEmphasis">Initialization</span> method.</P>
<A NAME="ch14exm04"></A>
<H5 class="docExampleTitle">Example 14-4. CleanUp method</H5>
<PRE>
void NeuralNetworkLayer::CleanUp(void)
{
     int     i;
     free(NeuronValues);
     free(DesiredValues);
     free(Errors);
     if(Weights != NULL)
     {
          for(i = 0; i&lt;NumberOfNodes; i++)
          {
               free(Weights[i]);
               free(WeightChanges[i]);
          }
          free(Weights);
          free(WeightChanges);
     }
     if(BiasValues != NULL) free(BiasValues);
     if(BiasWeights != NULL) free(BiasWeights);
}
</PRE><BR>


<P class="docText">The code here is pretty self-explanatory. It simply frees all dynamically allocated memory using <span class="docEmphasis">free</span>.</P>
<P class="docText">Earlier we mentioned that neural network weights are initialized to some small random numbers before training begins. The <span class="docEmphasis">RandomizeWeights</span> method, shown in <A class="docLink" HREF="#ch14exm05">Example 14-5</A>, handles this task for us.</P>
<A NAME="ch14exm05"></A>
<H5 class="docExampleTitle">Example 14-5. RandomizeWeights method</H5>
<PRE>
void NeuralNetworkLayer::RandomizeWeights(void)
{
     int     i,j;
     int     min = 0;
     int     max = 200;
     int     number;
     srand( (unsigned)time( NULL ) );
     for(i=0; i&lt;NumberOfNodes; i++)
     {
          for(j=0; j&lt;NumberOfChildNodes; j++)
          {
               number = (((abs(rand())%(max-min+1))+min));
               if(number&gt;max)
                    number = max;
               if(number&lt;min)
                   number = min;
               Weights[i][j] = number / 100.0f - 1;
          }
     }
     for(j=0; j&lt;NumberOfChildNodes; j++)
     {
               number = (((abs(rand())%(max-min+1))+min));
               if(number&gt;max)
                    number = max;
               if(number&lt;min)
                    number = min;
               BiasWeights[j] = number / 100.0f - 1;
     }
}
</PRE><BR>


<P class="docText">All this method does is simply calculate a random number between -1 and +1 for each weight in the <span class="docEmphasis">Weights</span> array. It does the same for the bias weights stored in the <span class="docEmphasis">BiasWeights</span> array. You should call this method at the start of training only.</P>
<P class="docText">The next method, <span class="docEmphasis">CalculateNeuronValues</span>, is responsible for calculating the activation or value of each neuron in the layer using the formulas we showed you earlier for net input to a neuron and the activation functions. <A class="docLink" HREF="#ch14exm06">Example 14-6</A> shows this method.</P>
<A NAME="ch14exm06"></A>
<H5 class="docExampleTitle">Example 14-6. CalculateNeuronValues method</H5>
<PRE>
void NeuralNetworkLayer::CalculateNeuronValues(void)
{
     int          i,j;
     double       x;
     if(ParentLayer != NULL)
     {
          for(j=0; j&lt;NumberOfNodes; j++)
          {
               x = 0;
               for(i=0; i&lt;NumberOfParentNodes; i++)
               {
                    x += ParentLayer-&gt;NeuronValues[i] *
                          ParentLayer-&gt;Weights[i][j];
               }
               x += ParentLayer-&gt;BiasValues[j] *
                     ParentLayer-&gt;BiasWeights[j];
               if((ChildLayer == NULL) &amp;&amp; LinearOutput)
                    NeuronValues[j] = x;
               else
                    NeuronValues[j] = 1.0f/(1+exp(-x));
          }
     }
}
</PRE><BR>


<P class="docText">In this method, all the weights are cycled through using the nested <span class="docEmphasis">for</span> statements. The <span class="docEmphasis">j</span> loop cycles through the layer nodes (the child layer), while the <span class="docEmphasis">i</span> loop cycles through the parent layer nodes. Within these nested loops, the net input is calculated and stored in the <span class="docEmphasis">x</span> variable. The net input for each node in the layer is the weighted sum of all connections from the parent layer (the <span class="docEmphasis">i</span> loop) feeding into each node, the <span class="docEmphasis">j</span><SUP>th</SUP> node, plus the weighted bias for the <span class="docEmphasis">j</span><SUP>th</SUP> node.</P>
<P class="docText">After you have calculated the net input for each node, you calculate the value for each neuron by applying an activation function. You use the logistic activation function for all layers, except for the output layer, in which case you use the linear activation function depending on the <span class="docEmphasis">LinearOutput</span> flag.</P>
<P class="docText">The <span class="docEmphasis">CalculateErrors</span> method shown in <A class="docLink" HREF="#ch14exm07">Example 14-7</A> is responsible for calculating the errors associated with each neuron using the formulas we discussed earlier.</P>
<A NAME="ch14exm07"></A>
<H5 class="docExampleTitle">Example 14-7. CalculateErrors method</H5>
<PRE>
void NeuralNetworkLayer::CalculateErrors(void)
{
     int          i, j;
     double     sum;
     if(ChildLayer == NULL) // output layer
     {
          for(i=0; i&lt;NumberOfNodes; i++)
          {
                 Errors[i] = (DesiredValues[i] - NeuronValues[i]) *
                               NeuronValues[i] *
                               (1.0f - NeuronValues[i]);
          }
     } else if(ParentLayer == NULL) { // input layer
          for(i=0; i&lt;NumberOfNodes; i++)
          {
               Errors[i] = 0.0f;
          }
     } else { // hidden layer
          for(i=0; i&lt;NumberOfNodes; i++)
          {
               sum = 0;
               for(j=0; j&lt;NumberOfChildNodes; j++)
               {
                    sum += ChildLayer-&gt;Errors[j] * Weights[i][j];
               }
               Errors[i] = sum * NeuronValues[i] *
                               (1.0f - NeuronValues[i]);
          }
     }
}
</PRE><BR>


<P class="docText">If the layer has no child layer, which happens only if the layer is an output layer, the formula for output layer errors is used. If the layer has no parent, which happens only if the layer is an input layer, the errors are set to 0. If the layer has both a parent layer and a child layer, it is a hidden layer and the formula for hidden-layer errors is applied.</P>
<P class="docText">The <span class="docEmphasis">AdjustWeights</span> method, shown in <A class="docLink" HREF="#ch14exm08">Example 14-8</A>, is responsible for calculating the adjustments to be made to each connection weight.</P>
<A NAME="ch14exm08"></A>
<H5 class="docExampleTitle">Example 14-8. AdjustWeights method</H5>
<PRE>
void NeuralNetworkLayer::AdjustWeights(void)
{
     int          i, j;
     double       dw;
     if(ChildLayer != NULL)
     {
          for(i=0; i&lt;NumberOfNodes; i++)
          {
               for(j=0; j&lt;NumberOfChildNodes; j++)
               {
                    dw = LearningRate * ChildLayer-&gt;Errors[j] *
                          NeuronValues[i];
                    if(UseMomentum)
                    {
                         Weights[i][j] += dw + MomentumFactor *
                                                WeightChanges[i][j];
                         WeightChanges[i][j] = dw;
                    } else {
                             Weights[i][j] += dw;
                    }
               }
          }
          for(j=0; j&lt;NumberOfChildNodes; j++)
          {
               BiasWeights[j] += LearningRate *
                                      ChildLayer-&gt;Errors[j] *
                                      BiasValues[j];
          }
     }
}
</PRE><BR>


<P class="docText">Weights are adjusted only if the layer has a child layer—that is, if the layer is an input layer or a hidden layer. Output layers have no child layer and therefore no connections and associated weights to adjust. The nested <span class="docEmphasis">for</span> loops cycle through the nodes in the layer and the nodes in the child layer. Remember that each neuron in a layer is connected to every node in a child layer. Within these nested loops, the weight adjustment is calculated using the formula shown earlier. If momentum is to be applied, the momentum factor times the previous epoch's weight changes also are added to the weight change. The weight change for this epoch is then stored in the <span class="docEmphasis">WeightChanges</span> array for the next epoch. If momentum is not used, the weight change is applied without momentum and there's no need to store the weight changes.</P>
<P class="docText">Finally, the bias weights are adjusted in a manner similar to the connection weights. For each bias connected to the child nodes, the adjustment is equal to the learning rate times the child neuron error times the bias value.</P>

<A NAME="ch14_sect2_013"></A>
<H4 class="docSection2Title">14.2.13 The Neural Network Class</H4>
<P class="docText">The <span class="docEmphasis">NeuralNetwork</span> class encapsulates three instances of the <span class="docEmphasis">NeuralNetworkLayer</span> class, one for each layer in the network: the input layer, the hidden layer, and the output layer. <A class="docLink" HREF="#ch14exm09">Example 14-9</A> shows the class header.</P>
<A NAME="ch14exm09"></A>
<H5 class="docExampleTitle">Example 14-9. NeuralNetwork class</H5>
<PRE>
class NeuralNetwork
{
public:
     NeuralNetworkLayer     InputLayer;
     NeuralNetworkLayer     HiddenLayer;
     NeuralNetworkLayer     OutputLayer;
     void     Initialize(int nNodesInput, int nNodesHidden,
                              int nNodesOutput);
     void     CleanUp();
     void     SetInput(int i, double value);
     double  GetOutput(int i);
     void     SetDesiredOutput(int i, double value);
     void     FeedForward(void);
     void     BackPropagate(void);
     int      GetMaxOutputID(void);
     double  CalculateError(void);
     void     SetLearningRate(double rate);
     void     SetLinearOutput(bool useLinear);
     void     SetMomentum(bool useMomentum, double factor);
     void     DumpData(char* filename);
};
</PRE><BR>


<P class="docText">Only three members in this class correspond to the layers comprising the class. However, this class contains 13 methods, which we'll go through next.</P>
<P class="docText"><A class="docLink" HREF="#ch14exm10">Example 14-10</A> shows the <span class="docEmphasis">Initialize</span> method.</P>
<A NAME="ch14exm10"></A>
<H5 class="docExampleTitle">Example 14-10. Initialize method</H5>
<PRE>
void NeuralNetwork::Initialize(int nNodesInput,
                                         int nNodesHidden,
                                         int nNodesOutput)
{
     InputLayer.NumberOfNodes = nNodesInput;
     InputLayer.NumberOfChildNodes = nNodesHidden;
     InputLayer.NumberOfParentNodes = 0;
     InputLayer.Initialize(nNodesInput, NULL, &amp;HiddenLayer);
     InputLayer.RandomizeWeights();
     HiddenLayer.NumberOfNodes = nNodesHidden;
     HiddenLayer.NumberOfChildNodes = nNodesOutput;
     HiddenLayer.NumberOfParentNodes = nNodesInput;
     HiddenLayer.Initialize(nNodesHidden,&amp;InputLayer,&amp;OutputLayer);
     HiddenLayer.RandomizeWeights();
     OutputLayer.NumberOfNodes = nNodesOutput;
     OutputLayer.NumberOfChildNodes = 0;
     OutputLayer.NumberOfParentNodes = nNodesHidden;
     OutputLayer.Initialize(nNodesOutput, &amp;HiddenLayer, NULL);
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">Initialize</span> takes three parameters corresponding to the number of neurons contained in each of the three layers comprising the network. These parameters initialize the instances of the layer class corresponding to the input, hidden, and output layers. <span class="docEmphasis">Initialize</span> also handles making the proper parent-child connections between layers. Further, it goes ahead and randomizes the connection weights.</P>
<P class="docText">The <span class="docEmphasis">CleanUp</span> method, shown in <A class="docLink" HREF="#ch14exm11">Example 14-11</A>, simply calls the <span class="docEmphasis">CleanUp</span> methods for each layer instance.</P>
<A NAME="ch14exm11"></A>
<H5 class="docExampleTitle">Example 14-11. CleanUp method</H5>
<PRE>
void NeuralNetwork::CleanUp()
{
     InputLayer.CleanUp();
     HiddenLayer.CleanUp();
     OutputLayer.CleanUp();
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">SetInput</span> is used to set the input value for a specific input neuron. <A class="docLink" HREF="#ch14exm12">Example 14-12</A> shows the <span class="docEmphasis">SetInput</span> method.</P>
<A NAME="ch14exm12"></A>
<H5 class="docExampleTitle">Example 14-12. SetInput method</H5>
<PRE>
void     NeuralNetwork::SetInput(int i, double value)
{
     if((i&gt;=0) &amp;&amp; (i&lt;InputLayer.NumberOfNodes))
     {
          InputLayer.NeuronValues[i] = value;
     }
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">SetInput</span> takes two parameters corresponding to the index to the neuron for which the input will be set and the input value itself. This information is then used to set the specific input. You use this method both during training to set the training set input, and during field use of the network to set the input data for which outputs will be calculated.</P>
<P class="docText">Once a network generates some output, we need a way to get at it. The <span class="docEmphasis">GetOutput</span> method is provided for that purpose. <A class="docLink" HREF="#ch14exm13">Example 14-13</A> shows the <span class="docEmphasis">GetOutput</span> method.</P>
<A NAME="ch14exm13"></A>
<H5 class="docExampleTitle">Example 14-13. GetOutput method</H5>
<PRE>
double     NeuralNetwork::GetOutput(int i)
{
     if((i&gt;=0) &amp;&amp; (i&lt;OutputLayer.NumberOfNodes))
     {
          return OutputLayer.NeuronValues[i];
     }
     return (double) INT_MAX; // to indicate an error
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">GetOutput</span> takes one parameter, the index to the output neuron for which we desire the output value. The method returns the value, or activation, for the specified output neuron. Note that if you specify an index that falls outside of the range of valid output neurons, <span class="docEmphasis">INT_MAX</span> will be returned to indicate an error.</P>
<P class="docText">During training we need to compare calculated output to desired output. The layer class facilitates the calculations along with storage of the desired output values. The <span class="docEmphasis">SetDesiredOutput</span> method, shown in <A class="docLink" HREF="#ch14exm14">Example 14-14</A>, is provided to facilitate setting the desired output to the values corresponding to a given set of input.</P>
<A NAME="ch14exm14"></A>
<H5 class="docExampleTitle">Example 14-14. SetDesiredOutput method</H5>
<PRE>
void NeuralNetwork::SetDesiredOutput(int i, double value)
{
     if((i&gt;=0) &amp;&amp; (i&lt;OutputLayer.NumberOfNodes))
     {
          OutputLayer.DesiredValues[i] = value;
     }
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">SetDesiredOutput</span> takes two parameters corresponding to the index of the output neuron for which the desired output is being set and the value of the desired output itself.</P>
<P class="docText">To actually have the network generate output given a set of input, we need to call the <span class="docEmphasis">FeedForward</span> method shown in <A class="docLink" HREF="#ch14exm15">Example 14-15</A>.</P>
<A NAME="ch14exm15"></A>
<H5 class="docExampleTitle">Example 14-15. FeedForward method</H5>
<PRE>
void NeuralNetwork::FeedForward(void)
{
     InputLayer.CalculateNeuronValues();
     HiddenLayer.CalculateNeuronValues();
     OutputLayer.CalculateNeuronValues();
}
</PRE><BR>


<P class="docText">This method simply calls the <span class="docEmphasis">CalculateNeuronValues</span> method for the input, hidden, and output layers in succession. Once these calls are complete, the output layer will contain the calculated output, which then can be inspected via calls to the <span class="docEmphasis">GetOutput</span> method.</P>
<P class="docText">During training, once output has been calculated, we need to adjust the connection weights using the back-propagation technique. The <span class="docEmphasis">BackPropagate</span> method handles this task. <A class="docLink" HREF="#ch14exm16">Example 14-16</A> shows the <span class="docEmphasis">BackPropagate</span> method.</P>
<A NAME="ch14exm16"></A>
<H5 class="docExampleTitle">Example 14-16. BackPropagate method</H5>
<PRE>
void NeuralNetwork::BackPropagate(void)
{
     OutputLayer.CalculateErrors();
     HiddenLayer.CalculateErrors();
     HiddenLayer.AdjustWeights();
     InputLayer.AdjustWeights();
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">BackPropagate</span> first calls the <span class="docEmphasis">CalculateErrors</span> method for the output and hidden layers, in that order. Then it goes on to call the <span class="docEmphasis">AdjustWeights</span> method for the hidden and input layers, in that order. The order is important here and it must be the order shown in <A class="docLink" HREF="#ch14exm16">Example 14-16</A>—that is, we work backward through the network rather than forward, as in the <span class="docEmphasis">FeedForward</span> case.</P>
<P class="docText">When using a network with multiple output neurons and the winner-takes-all approach to determine which output is activated, you need to figure out which output neuron has the highest output value. <span class="docEmphasis">GetMaxOutputID</span>, shown in <A class="docLink" HREF="#ch14exm17">Example 14-17</A>, is provided for that purpose.</P>
<A NAME="ch14exm17"></A>
<H5 class="docExampleTitle">Example 14-17. GetMaxOutputID method</H5>
<PRE>
int     NeuralNetwork::GetMaxOutputID(void)
{
     int          i, id;
     double     maxval;
     maxval = OutputLayer.NeuronValues[0];
     id = 0;
     for(i=1; i&lt;OutputLayer.NumberOfNodes; i++)
     {
          if(OutputLayer.NeuronValues[i] &gt; maxval)
          {
               maxval = OutputLayer.NeuronValues[i];
               id = i;
          }
     }
     return id;
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">GetMaxOutputID</span> simply iterates through all the output-layer neurons to determine which one has the highest output value. The index to the neuron with the highest value is returned.</P>
<P class="docText">Earlier we discussed the need to calculate the error associated with a given set of output. We need to do this for training purposes. The <span class="docEmphasis">CalculateError</span> method takes care of the error calculation for us. <A class="docLink" HREF="#ch14exm18">Example 14-18</A> shows the <span class="docEmphasis">CalculateError</span> method.</P>
<A NAME="ch14exm18"></A>
<H5 class="docExampleTitle">Example 14-18. CalculateError method</H5>
<PRE>
double NeuralNetwork::CalculateError(void)
{
     int          i;
     double     error = 0;
     for(i=0; i&lt;OutputLayer.NumberOfNodes; i++)
     {
          error += pow(OutputLayer.NeuronValues[i] --
                   OutputLayer.DesiredValues[i], 2);
     }
     error = error / OutputLayer.NumberOfNodes;
     return error;
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">CalculateError</span> returns the error value associated with the calculated output values and the given set of desired output values using the mean-square error formula we discussed earlier.</P>
<P class="docText">For convenience, we provide the <span class="docEmphasis">SetLearningRate</span> method, shown in <A class="docLink" HREF="#ch14exm19">Example 14-19</A>. You can use it to set the learning rate for each layer comprising the network.</P>
<A NAME="ch14exm19"></A>
<H5 class="docExampleTitle">Example 14-19. SetLearningRate method</H5>
<PRE>
void NeuralNetwork::SetLearningRate(double rate)
{
     InputLayer.LearningRate = rate;
     HiddenLayer.LearningRate = rate;
     OutputLayer.LearningRate = rate;
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">SetLinearOutput</span>, shown in <A class="docLink" HREF="#ch14exm20">Example 14-20</A>, is another convenience method. You can use it to set the <span class="docEmphasis">LinearOutput</span> flag for each layer in the network. Note, however, that only the output layer will use linear activations in this implementation.</P>
<A NAME="ch14exm20"></A>
<H5 class="docExampleTitle">Example 14-20. SetLinearOutput method</H5>
<PRE>
void     NeuralNetwork::SetLinearOutput(bool useLinear)
{
     InputLayer.LinearOutput = useLinear;
     HiddenLayer.LinearOutput = useLinear;
     OutputLayer.LinearOutput = useLinear;
}
</PRE><BR>


<P class="docText">You use <span class="docEmphasis">SetMomentum</span>, shown in <A class="docLink" HREF="#ch14exm21">Example 14-21</A>, to set the <span class="docEmphasis">UseMomentum</span> flag and the momentum factor for each layer in the network.</P>
<A NAME="ch14exm21"></A>
<H5 class="docExampleTitle">Example 14-21. SetMomentum method</H5>
<PRE>
void     NeuralNetwork::SetMomentum(bool useMomentum, double factor)
{
     InputLayer.UseMomentum = useMomentum;
     HiddenLayer.UseMomentum = useMomentum;
     OutputLayer.UseMomentum = useMomentum;
     InputLayer.MomentumFactor = factor;
     HiddenLayer.MomentumFactor = factor;
     OutputLayer.MomentumFactor = factor;
}
</PRE><BR>


<P class="docText"><span class="docEmphasis">DumpData</span> is a convenience method that simply streams some important data for the network to an output file. <A class="docLink" HREF="#ch14exm22">Example 14-22</A> shows the <span class="docEmphasis">DumpData</span> method.</P>
<A NAME="ch14exm22"></A>
<H5 class="docExampleTitle">Example 14-22. DumpData method</H5>
<PRE>
void NeuralNetwork::DumpData(char* filename)
{
     FILE*     f;
     int          i, j;
     f = fopen(filename, "w");
     fprintf(f, "---------------------------------------------\n");
     fprintf(f, "Input Layer\n");
     fprintf(f, "---------------------------------------------\n");
     fprintf(f, "\n");
     fprintf(f, "Node Values:\n");
     fprintf(f, "\n");
     for(i=0; i&lt;InputLayer.NumberOfNodes; i++)
          fprintf(f, "(%d) = %f\n", i, InputLayer.NeuronValues[i]);
     fprintf(f, "\n");
     fprintf(f, "Weights:\n");
     fprintf(f, "\n");
     for(i=0; i&lt;InputLayer.NumberOfNodes; i++)
          for(j=0; j&lt;InputLayer.NumberOfChildNodes; j++)
               fprintf(f, "(%d, %d) = %f\n", i, j,
                          InputLayer.Weights[i][j]);
     fprintf(f, "\n");
     fprintf(f, "Bias Weights:\n");
     fprintf(f, "\n");
     for(j=0; j&lt;InputLayer.NumberOfChildNodes; j++)
          fprintf(f, "(%d) = %f\n", j, InputLayer.BiasWeights[j]);
     fprintf(f, "\n");
     fprintf(f, "\n");
     fprintf(f, "---------------------------------------------\n");
     fprintf(f, "Hidden Layer\n");
     fprintf(f, "---------------------------------------------\n");
     fprintf(f, "\n");
     fprintf(f, "Weights:\n");
     fprintf(f, "\n");
     for(i=0; i&lt;HiddenLayer.NumberOfNodes; i++)
          for(j=0; j&lt;HiddenLayer.NumberOfChildNodes; j++)
               fprintf(f, "(%d, %d) = %f\n", i, j,
                           HiddenLayer.Weights[i][j]);
     fprintf(f, "\n");
     fprintf(f, "Bias Weights:\n");
     fprintf(f, "\n");
     for(j=0; j&lt;HiddenLayer.NumberOfChildNodes; j++)
          fprintf(f, "(%d) = %f\n", j, HiddenLayer.BiasWeights[j]);
     fprintf(f, "\n");
     fprintf(f, "\n");
     fprintf(f, "---------------------------------------------\n");
     fprintf(f, "Output Layer\n");
     fprintf(f, "---------------------------------------------\n");
     fprintf(f, "\n");
     fprintf(f, "Node Values:\n");
     fprintf(f, "\n");
     for(i=0; i&lt;OutputLayer.NumberOfNodes; i++)
          fprintf(f, "(%d) = %f\n", i, OutputLayer.NeuronValues[i]);
     fprintf(f, "\n");
     fclose(f);
}
</PRE><BR>


<P class="docText">The data that is sent to the given output file consists of weights, values, and bias weights for the layers comprising the network. This is useful when you want to examine the internals of a given network. This is helpful when debugging and in cases in which you might train a network using a utility program and want to hardcode the trained weights in an actual game instead of spending the time in-game performing initial training. For this latter purpose, you'll have to revise the <span class="docEmphasis">NeuralNetwork</span> class shown here to facilitate loading weights from an external source.</P>


<ul></ul></td></tr></table>
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="ch14_sect1_002.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="ch14_sect1_004.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
</body>
</html>
