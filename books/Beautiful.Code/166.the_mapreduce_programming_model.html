<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<link href="styles/globalstyle.css" type="text/css" rel="stylesheet"/>
<link title="medium" href="styles/two.css" type="text/css" rel="stylesheet"/>
<script src="scripts/main.js" type="text/javascript" language="javascript"></script>
<title>Section 23.2. The MapReduce Programming Model</title>
</head><body>
<DIV class=h3 style="MARGIN-TOP: 0px; PADDING-BOTTOM: 1em; WIDTH: 100%; PADDING-TOP: 0px"><SPAN>Distributed Programming with MapReduce</SPAN><SPAN> &gt; The MapReduce Programming Model</SPAN></DIV>
<DIV></DIV>
<DIV>
<DIV><A name=the_mapreduce_programming_model></A>
<H3 class=docSection1Title id=-100000>23.2. The MapReduce Programming Model</H3>
<P class=docText><A name="If you"></A>If you compare <A class=docLink href="165.a_motivating_example.html#naiumlve_nonparallel_word_count_program">Example 23-1</A> with <A class=docLink href="165.a_motivating_example.html#parallelized_word_count_program_with_partitioned_processors">Example 23-4</A><A name="simple task"></A>, you'll find that the simple task of counting words has been buried under lots of details about managing parallelism. If we can somehow separate the details of the original problem from the details of parallelization, we may be able to produce a general parallelization library or system that can be applied not just to this word-counting problem, but other large-scale processing problems. The parallelization pattern that we are using is:<A name=idx-CHP-23-1902></A><A name=idx-CHP-23-1903></A><A name=idx-CHP-23-1904></A></P>
<UL>
<LI>
<P class=docList><A name="extract a"></A>For each input record, extract a set of key/value pairs that we care about from each record.</P></LI>
<LI>
<P class=docList><A name="extracted key"></A>For each extracted key/value pair, combine it with other values that share the same key (perhaps filtering, aggregating, or transforming values in the process).</P></LI></UL>
<P class=docText><A name="to implement"></A>Let's rewrite our program to implement the application-specific logic of counting word frequencies for each document and summing these counts across documents in two functions that we'll call Map and Reduce. The result is <A class=docLink href="javascript:moveTo('division_of_word_counting_problem_into_map_and_reduce');">Example 23-5</A>.</P><A name=division_of_word_counting_problem_into_map_and_reduce></A>
<H5 class=docExampleTitle id=title-ID0EC5DK>Example 23-5. Division of word counting problem into Map and Reduce</H5>
<P>
<TABLE cellSpacing=0 cellPadding=5 width=* border=1>
<TBODY>
<TR>
<TD><PRE>void Map(string document) {
  for each word w in document {
    EmitIntermediate(w, "1");
  }
}

void Reduce(string word, list&lt;string&gt; values) {
  int count = 0;
  for each v in values {
    count += StringToInt(v);
  }
  Emit(word, IntToString(count));
}
</PRE><BR></TD></TR></TBODY></TABLE></P>
<P class=docText>A simple <A name=idx-CHP-23-1905></A><A name="task on"></A>driver program that uses these routines to accomplish the desired task on a single machine would look like <A class=docLink href="javascript:moveTo('driver_for_map_and_reduce');">Example 23-6</A>.<A name=idx-CHP-23-1906></A><A name=idx-CHP-23-1907></A><A name=I_indexterm23_tt460></A></P><A name=driver_for_map_and_reduce></A>
<H5 class=docExampleTitle id=title-ID0EK6DK>Example 23-6. Driver for Map and Reduce</H5>
<P>
<TABLE cellSpacing=0 cellPadding=5 width=* border=1>
<TBODY>
<TR>
<TD><PRE>map&lt;string, list&lt;string&gt; &gt; intermediate_data;

void EmitIntermediate(string key, string value) {
  intermediate_data[key].append(value);
}

void Emit(string key, string value) {
  ... write key/value to final data file ...
}

void Driver(MapFunction mapper, ReduceFunction reducer) {
  for each input item do {
    mapper(item)
  }
  for each key k in intermediate_data {
    reducer(k, intermediate_data[k]);
  }
}

main() {
  Driver(Map, Reduce);
}
</PRE><BR></TD></TR></TBODY></TABLE></P>
<P class=docText><A name="function is"></A>The Map function is called once for each input record. Any intermediate key/value pairs emitted by the Map function are collected together by the driver code. Then, the Reduce function is called for each unique intermediate key, together with a list of intermediate values associated with that key.</P>
<P class=docText><A name="implementation that"></A>We're now back to an implementation that runs on a single machine. However, with things separated in this manner, we can now change the implementation of the driver program to make it deal with distribution, automatic parallelization, and fault tolerance without affecting the application-specific logic in the Map and Reduce functions. Furthermore, the driver is independent of the particular application logic implemented by the Map and Reduce functions, and therefore the same driver program can be reused with other Map and Reduce functions to solve different problems. Finally, notice that the Map and Reduce functions that implement the application-specific logic are nearly as understandable as the simple sequential code shown in <A class=docLink href="165.a_motivating_example.html#naiumlve_nonparallel_word_count_program">Example 23-1</A>.</P></DIV></DIV>
<p>&nbsp;</p><p>&nbsp;</p><!-- 仁·义 -->
</body></html>
