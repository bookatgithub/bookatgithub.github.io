<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<link href="styles/globalstyle.css" type="text/css" rel="stylesheet"/>
<link title="medium" href="styles/two.css" type="text/css" rel="stylesheet"/>
<script src="scripts/main.js" type="text/javascript" language="javascript"></script>
<title>Section 28.7. Hunting the Defect</title>
</head><body>
<DIV class=h3 style="MARGIN-TOP: 0px; PADDING-BOTTOM: 1em; WIDTH: 100%; PADDING-TOP: 0px"><SPAN>Beautiful Debugging</SPAN><SPAN> &gt; Hunting the Defect</SPAN></DIV>
<DIV></DIV>
<DIV>
<DIV><A name=hunting_the_defect></A>
<H3 class=docSection1Title id=-100000>28.7. Hunting the Defect</H3>
<P class=docText><A name="In principle"></A>In principle, delta <A name=idx-CHP-28-2464></A><A name="minimize an"></A>debugging could also minimize an entire program code so as to keep only what is relevant. Suppose your web browser crashes while printing a HTML page. Applying delta debugging on the program code means that only the bare code required to reproduce the failure would remain. Doesn't this sound neat? Unfortunately, it would hardly work in practice. The reason is that the elements of program code are heavily dependent on each other. Remove one piece, and everything breaks apart. The chances of getting something meaningful by randomly removing parts are very slim. Therefore, delta debugging would almost certainly require a quadratic number of tests. Even for a 1,000-line program, this would already mean a million tests—and years and years of waiting. We never had that much time, so we never implemented that feat.<A name=idx-CHP-28-2465></A></P>
<P class=docText><A name="to hunt"></A>Nonetheless, we still wanted to hunt down failure causes not only in the input or the set of changes, but in the actual source code—in other words, we wanted to have the statements that caused the program to fail. (And, of course, we wanted to get them automatically.)</P>
<P class=docText><A name="a task"></A>Again, this was a task that turned out to be achievable by delta debugging. However, we did not get there directly. We wanted to make a detour via <A name=idx-CHP-28-2466></A><A name="of all"></A>program states—that is, the set of all program variables and their values. In this set, we wanted to determine failure causes automatically, as in "At the call to <TT>shell_sort()</TT>, variable size causes the failure." How would that work?</P>
<P class=docText><A name="done delta"></A>Let us recapitulate what we had done so far. We had done delta debugging on program versions—one that worked and one that failed—and isolated the minimal difference that caused the failure. We had done delta debugging on program inputs—again, one that worked and one that failed—and isolated minimal differences that caused the failure. If we applied delta debugging <A name=idx-CHP-28-2467></A><A name="we would"></A>on program states, we would take one program state from a working run, and one program state from a failing run, and eventually obtain the minimal difference that caused the failure.</P>
<P class=docText><A name="in here"></A>Now, there are three problems in here. Problem number one: <SPAN class=docEmphasis><A name="program state"></A>How does one obtain a program state?</SPAN><A name="I would"></A> Eventually, I would instrument the <SPAN class=docEmphasis>gdb</SPAN><A name="all named"></A> debugger to query all named variables first, and then <SPAN class=docEmphasis>unfold</SPAN><A name="I encountered"></A> all data structures. If I encountered an array or a structure, I would query its elements; if I found a pointer, I would query the variable it pointed to, and so on—until I reached a fix point, or the set of all accessible variables. This program state would be represented as a graph of variables (vertices) and references (edges), as shown in <A class=docLink href="javascript:moveTo('a_program_state_of_the_gnu_compiler');">Figure 28-2</A><A name="concrete memory"></A>, abstracting away concrete memory addresses.</P><A name=a_program_state_of_the_gnu_compiler></A>
<P>
<CENTER>
<H5 class=docFigureTitle><A name="state of"></A>Figure 28-2. A program state of the GNU compiler</H5><IMG id="" height=304 alt="" src="images/hunting_the_defect.0.png" width=500 border=0> </CENTER>
<P></P><BR>
<P class=docText>Next problem: <SPAN class=docEmphasis>How does one compare two program states?</SPAN><A name="subgraphs between"></A> This was rather easy: there are known algorithms for computing common subgraphs between two graphs—and anything that would not be part of the subgraph became a difference. With such an algorithm properly implemented, we now could actually extract and determine the difference between two program states.<A name=idx-CHP-28-2468></A></P>
<P class=docText><A name="last problem"></A>Third and last problem: <SPAN class=docEmphasis><A name="differences between"></A>How does one apply differences between states?</SPAN><A name="it involved"></A> This was a real challenge, as it involved not only observing but actually manipulating program states. To apply a difference in program state, we would have to set variables to new values, but also to replicate entire complex data structures, including allocating and deleting elements. Once this was done, we could do something quite fun; we could arbitrarily transfer program states between running processes. And not only entire program states, but also partial pro-gram states—ranging from small changes to a single variable to large changes of, say, half of a symbol table.</P>
<P class=docText><A name="This idea"></A>This idea of transferring program states while the program is executing is something that one needs time getting used to. I remember one of my first presentations at IBM where I explained the algorithm, its application on states, and came to the ultimate example: "We now have 879 differences between these two states. We now let delta <A name=idx-CHP-28-2469></A><A name="the failure"></A>debugging narrow down the failure cause. To this end, the algorithm takes half of the differences, that is, 439 state differences, and applies them. This means that in the passing run, 439 variables are now set to the values found in the failing run…."</P>
<P class=docText><A name="fellow from"></A>At this moment, a fellow from the audience stepped up and said: "But doesn't this sound like a very insane thing to do?"</P>
<P class=docText><A name="was right"></A>Of course, he was right. Nothing meaningful came out of setting 439 variables to values found in <A name=idx-CHP-28-2470></A><A name="it help"></A>another run; nor did it help setting the other 440 variables. But this is just the situation in which delta <A name=idx-CHP-28-2471></A><A name="tries "></A>debugging comes up with the idea of making smaller changes—that is, it tries 220 variables, 110, and so on. Eventually, it isolates the variable that caused the failure: "The compiler crash was caused by a loop in the abstract syntax tree." And this end, of course, justifies the means—in particular, for the people at IBM, who were all pretty busy developing (and debugging) compilers.</P>
<P class=docText><A name="that it"></A>Thus, the demonstration that it worked helped people forget it was a pretty weird approach. Still, my first publication on the topic had a hard time getting accepted. One reviewer frankly admitted he was so appalled by the weird approach, he would not even bother to read on toward the results.</P>
<P class=docText><A name="program state"></A>Nonetheless, finding failure causes in program state was only a detour toward the ultimate end. It was Holger Cleve who gave this technique the ultimate touch. Since he knew the <A name=idx-CHP-28-2472></A><A name="their values"></A>failure-causing variables, he would simply trace back their values to the statements that caused them—and presto! We would end up in the statements that caused the failure: "The statement in line 437 caused a loop, which again caused the failure." Now this was true magic—and this paper had no trouble getting published, either.</P>
<P class=docText><A name="as we"></A>So, as we had a complete automatic debugging solution on our hands, why do people today still use interactive debuggers? Why didn't we go public and become millionaires with automated debugging?</P></DIV></DIV>
<p>&nbsp;</p><p>&nbsp;</p><!-- 仁·义 -->
</body></html>
