<html>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<head>
<title>Section 20.3.&nbsp; Advanced Web Clients</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr><td><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch20lev1sec2.html><img src="images/prev.gif" width="60" height="17" border="0" align="absmiddle" alt="Previous Page"></a>
<td align="right"><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch20lev1sec4.html><img src="images/next.gif" width="60" height="17" border="0" align="absmiddle" alt="Next Page"></a>
</div></td></tr></table>
<br><table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><TD valign="top"><a name="ch20lev1sec3"></a>
<h3 id="title-IDAJACME" class="docSection1Title">20.3. Advanced Web Clients</H3>
<p class="docText">Web browsers are basic Web clients. They are used primarily for searching and downloading documents from the Web. Advanced clients of the Web are those applications that do more than download single documents from the Internet.</p>
<p class="docText">One example of an advanced Web client is a <span class="docEmphasis">crawler</span> (aka <span class="docEmphasis">spider</span>, <span class="docEmphasis">robot</span>). These are programs that explore and download pages from the Internet for different reasons, some of which include:</P>
<UL><LI><p class="docList">Indexing into a large search engine such as Google or Yahoo!</P></li><li><p class="docList">Offline browsingdownloading documents onto a local hard disk and rearranging hyperlinks to create almost a mirror image for local browsing</p></LI><li><p class="docList">Downloading and storing for historical or archival purposes, or</P></li><LI><p class="docList">Web page caching to save superfluous downloading time on Web site revisits.</p></LI></UL>
<p class="docText">The crawler we present below, <tt>crawl.py</tt>, takes a starting Web address (URL), downloads that page and all other pages whose links appear in succeeding pages, but only those that are in the same domain as the starting page. Without such limitations, you will run out of disk space! The source for <tt>crawl.py</tt> appears in <a class="docLink" href="ch20lev1sec2.html#ch20list02">Example 20.2</a>.</p>
<a name="ch20lev2sec7"></a>
<h4 id="title-IDABCCME" class="docSection2Title">Line-by-Line (Class-by-Class) Explanation</h4>
<a name="ch20lev3sec11"></a>
<h5 id="title-IDAKCCME" class="docSection3Title">Lines 111</H5>
<p class="docText">The top part of the script consists of the standard Python Unix start-up line and the importation of various module attributes that are employed in this application.</p>

<a name="ch20lev3sec12"></a>
<h5 id="title-IDAWCCME" class="docSection3Title">Lines 1349</H5>
<p class="docText">The <tt>Retriever</tt> class has the responsibility of downloading pages from the Web and parsing the links located within each document, adding them to the &quot;to-do&quot; queue if necessary. A <tt>Retriever</tt> instance object is created for each page that is downloaded from the net. <tt>Retriever</tt> consists of several methods to aid in its functionality: a constructor (<tt>__init__())</tt>, <tt>filename()</tt>, <tt>download()</tt>, and <tt>parseAndGetLinks()</tt>.</p>
<p class="docText">The <tt>filename()</tt> method takes the given URL and comes up with a safe and sane corresponding filename to store locally. Basically, it removes the &quot;<tt>http://</tt>&quot; prefix from the URL and uses the remaining part as the filename, creating any directory paths necessary. URLs without trailing file-names will be given a default filename of &quot;<tt>index.htm</tt>&quot;. (This name can be overridden in the call to <tt>filename()</tt>).</p>
<p class="docText">The constructor instantiates a <tt>Retriever</tt> object and stores both the URL string and the corresponding file name returned by <tt>filename()</tt> as local attributes.</p>
<p class="docText">The <tt>download()</tt> method, as you may imagine, actually goes out to the net to download the page with the given link. It calls <tt>urllib.urlretrieve()</tt> with the URL and saves it to the filename (the one returned by <tt>filename()</tt>). If the download was successful, the <tt>parse()</tt> method is called to parse the page just copied from the network; otherwise an error string is returned.</P>
<p class="docText">If the <tt>Crawler</tt> determines that no error has occurred, it will invoke the <tt>parseAndGetLinks()</tt> method to parse the newly downloaded page and determine the course of action for each link located on that page.</P>

<a name="ch20lev3sec13"></a>
<h5 id="title-IDAWECME" class="docSection3Title">Lines 5198</h5>
<p class="docText">The <tt>Crawler</tt> class is the &quot;star&quot; of the show, managing the entire crawling process for one Web site. If we added threading to our application, we would create separate instances for each site crawled. The <tt>Crawler</tt> consists of three items stored by the constructor during the instantiation phase, the first of which is <tt>q</tt>, a queue of links to download. Such a list will fluctuate during execution, shrinking as each page is processed and grown as new links are discovered within each downloaded page.</p>
<p class="docText">The other two data values for the <tt>Crawler</tt> include <tt>seen</tt>, a list of all the links that &quot;we have seen&quot; (downloaded) already. And finally, we store the domain name for the main link, <tt>dom</tt>, and use that value to determine whether any succeeding links are part of the same domain.</p>
<p class="docText"><tt>Crawler</tt> also has a static data item named <tt>count</tt>. The purpose of this counter is just to keep track of the number of objects we have downloaded from the net. It is incremented for every page successfully download.</p>
<p class="docText"><tt>Crawler</tt> has a pair of other methods in addition to its constructor, <tt>getPage()</tt> and <tt>go()</tt>. <tt>go()</tt> is simply the method that is used to start the <tt>Crawler</tt> and is called from the main body of code. <tt>go()</tt> consists of a loop that will continue to execute as long as there are new links in the queue that need to be downloaded. The workhorse of this class, though, is the <tt>getPage()</tt> method.</p>
<p class="docText"><tt>getPage()</tt> instantiates a <tt>Retriever</tt> object with the first link and lets it go off to the races. If the page was downloaded successfully, the counter is incremented and the link added to the &quot;already seen&quot; list. It looks recursively at all the links featured inside each downloaded page and determines whether any more links should be added to the queue. The main loop in <tt>go()</tt> will continue to process links until the queue is empty, at which time victory is declared.</p>
<p class="docText">Links that are part of another domain, have already been downloaded, are already in the queue waiting to be processed, or are &quot;<tt>mailto:</tt>&quot; links are ignored and not added to the queue.</p>

<a name="ch20lev3sec14"></a>
<h5 id="title-IDAWGCME" class="docSection3Title">Lines 100114</h5>
<p class="docText"><tt>main()</tt> is executed if this script is invoked directly and is the starting point of execution. Other modules that import <tt>crawl.py</tt> will need to invoke <tt>main()</tt> to begin processing. <tt>main()</tt> needs a URL to begin processing. If one is given on the command line (for example, when this script is invoked directly), it will just go with the one given. Otherwise, the script enters interactive mode, prompting the user for a starting URL. With a starting link in hand, the <tt>Crawler</tt> is instantiated and away we go.</p>
<p class="docText">One sample invocation of <tt>crawl.py</tt> may look like this:</p>
<div class="docText"><pre>        % crawl.py
        Enter starting URL: http://www.null.com/home/index.html

        ( 1 )
        URL: http://www.null.com/home/index.html
        FILE: www.null.com/home/index.html
        * http://www.null.com/home/overview.html ... new, added to Q
        * http://www.null.com/home/synopsis.html ... new, added to Q
        * http://www.null.com/home/order.html ... new, added to Q
        * mailto:postmaster@null.com ... discarded, mailto link
        * http://www.null.com/home/overview.html ... discarded, already in Q
        * http://www.null.com/home/synopsis.html ... discarded, already in Q
        * http://www.null.com/home/order.html ... discarded, already in Q
        * mailto:postmaster@null.com ... discarded, mailto link
        * http://bogus.com/index.html ... discarded, not in domain

        ( 2 )
        URL: http://www.null.com/home/order.html
        FILE: www.null.com/home/order.html
        * mailto:postmaster@null.com ... discarded, mailto link
        * http://www.null.com/home/index.html ... discarded, already processed
        * http://www.null.com/home/synopsis.html ... discarded, already in Q
        * http://www.null.com/home/overview.html ... discarded, already in Q

        ( 3 )
        URL: http://www.null.com/home/synopsis.html
        FILE: www.null.com/home/synopsis.html
        * http://www.null.com/home/index.html ... discarded, already processed
        * http://www.null.com/home/order.html ... discarded, already processed
        * http://www.null.com/home/overview.html ... discarded, already in Q

        ( 4 )
        URL: http://www.null.com/home/overview.html
        FILE: www.null.com/home/overview.html
        * http://www.null.com/home/synopsis.html ... discarded, already processed
        * http://www.null.com/home/index.html ... discarded, already processed
        * http://www.null.com/home/synopsis.html ... discarded, already processed
        * http://www.null.com/home/order.html ... discarded, already processed</pre></div><BR>
<p class="docText"><a name="iddle1298a"></a><a name="iddle1298"></a><a name="iddle1408"></a><a name="iddle1473"></a><a name="iddle2330"></a><a name="iddle2335"></a><a name="iddle2442"></a><a name="iddle3762"></a><a name="iddle4391"></a><a name="iddle4483"></a><a name="iddle4487"></a>After execution, a <tt><a class="docLink" target="_blank" href="http://www.null.com">www.null.com</a></tt> directory would be created in the local file system, with a <tt>home</tt> subdirectory. Within <tt>home</tt>, all the HTML files processed will be found.</p>



</TD></TR></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr><td><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch20lev1sec2.html><img src="images/prev.gif" width="60" height="17" border="0" align="absmiddle" alt="Previous Page"></a>
<td align="right"><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch20lev1sec4.html><img src="images/next.gif" width="60" height="17" border="0" align="absmiddle" alt="Next Page"></a>
</div></td></tr></table>
</body></html>