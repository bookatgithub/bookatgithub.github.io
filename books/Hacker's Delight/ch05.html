<html xmlns="http://www.w3.org/1999/xhtml">
   
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      
      <title>Chapter 5. Counting Bits</title>
      
      <link href="9780133085013.css" rel="stylesheet" type="text/css" />
      
      <link href="page-template.xpgt" rel="stylesheet" type="application/vnd.adobe-page-template+xml" />
      
      <meta content="urn:uuid:767ce45a-85bb-4273-91f5-801bab42906b" name="Adept.expected.resource" />
      
   </head>
   
   <body>
      
      <h2><a id="page_81"></a><a id="ch05"></a>Chapter 5. Counting Bits
      </h2>
      
      <h3><a id="ch05lev1"></a><strong>5–1 Counting 1-Bits</strong></h3>
      
      <p class="noindent">The IBM Stretch computer (ca. 1960) had a means of counting the number of 1-bits in
         a word, as well as the number of leading 0’s. It produced these two quantities as
         a by-product of all logical operations! The former function is sometimes called <em>population count</em> (e.g., on Stretch and the SPARCv9).
      </p>
      
      <p class="indent">For machines that don’t have this instruction, a good way to count the number of 1-bits
         is to first set each 2-bit field equal to the sum of the two single bits that were
         originally in the field, and then sum adjacent 2-bit fields, putting the results in
         each 4-bit field, and so on. A more complete discussion of this trick is in [RND].
         The method is illustrated in <a href="ch05.html#ch05fig1">Figure 5–1</a>, in which the first row shows a computer word whose 1-bits are to be summed, and
         the last row shows the result (23 decimal).
      </p>
      
      <div class="image"><a id="page_82"></a><a id="ch05fig1"></a><img alt="Image" src="graphics/05fig01.jpg" /></div>
      
      <p class="fig-caption">F<small>IGURE</small> 5–1. Counting 1-bits, “divide and conquer” strategy.
      </p>
      
      <p class="indent">This is an example of the “divide and conquer” strategy, in which the original problem
         (summing 32 bits) is divided into two problems (summing 16 bits), which are solved
         separately, and the results are combined (added, in this case). The strategy is applied
         recursively, breaking the 16-bit fields into 8-bit fields, and so on.
      </p>
      
      <p class="indent">In the case at hand, the ultimate small problems (summing adjacent bits) can all be
         done in parallel, and combining adjacent sums can also be done in parallel in a fixed
         number of steps at each stage. The result is an algorithm that can be executed in
         log<sub>2</sub>(32) = 5 steps.
      </p>
      
      <p class="indent">Other examples of divide and conquer are the well-known techniques of binary search,
         a sorting method known as quicksort, and a method for reversing the bits of a word,
         discussed on page <a href="ch07.html#page_129">129</a>.
      </p>
      
      <p class="indent">The method illustrated in <a href="ch05.html#ch05fig1">Figure 5–1</a> can be committed to C code as
      </p>
      
      <p class="codelink"><a href="images4.html#p081equ01" id="p081equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = (x &amp; 0x55555555) + ((x &gt;&gt; 1) &amp; 0x55555555);<br />x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);<br />x = (x &amp; 0x0F0F0F0F) + ((x &gt;&gt; 4) &amp; 0x0F0F0F0F);<br />x = (x &amp; 0x00FF00FF) + ((x &gt;&gt; 8) &amp; 0x00FF00FF);<br />x = (x &amp; 0x0000FFFF) + ((x &gt;&gt; 16) &amp; 0x0000FFFF);
      </p>
      
      <p class="noindent">The first line uses <code>(x &gt;&gt; 1) &amp; 0x55555555</code> rather than the perhaps more natural <code>(x &amp; 0xAAAAAAAA) &gt;&gt; 1,</code> because the code shown avoids generating two large constants in a register. This
         would cost an instruction if the machine lacks the <em>and not</em> instruction. A similar remark applies to the other lines.
      </p>
      
      <p class="indent">Clearly, the last <em>and</em> is unnecessary, and other <em>and</em>’s can be omitted when there is no danger that a field’s sum will carry over into
         the adjacent field. Furthermore, there is a way to code the first line that uses one
         fewer instruction. This leads to the simplification shown in <a href="ch05.html#ch05fig2">Figure 5–2</a>, which executes in 21 instructions and is branch-free.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig02" id="p05fig02a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig2"></a>int pop(unsigned x) {<br />   x = x - ((x &gt;&gt; 1) &amp; 0x55555555);<br />   x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);<br />   x = (x + (x &gt;&gt; 4)) &amp; 0x0F0F0F0F;<br />   x = x + (x &gt;&gt; 8);<br />   x = x + (x &gt;&gt; 16);<br />   return x &amp; 0x0000003F;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–2. Counting 1-bits in a word.
      </p>
      
      <p class="indent">The first assignment to <code>x</code> is based on the first two terms of the rather surprising formula
      </p>
      
      <div class="image"><img alt="Image" src="graphics/05equ01.jpg" /></div>
      
      <p class="noindent">In Equation (1), we must have <em>x</em> ≥ 0. By treating <em>x</em> as an unsigned integer, Equation (1) can be implemented with a sequence of 31 <em>shift right immediate</em>’s of 1, and 31 <em>subtract</em>’s. The procedure of <a href="ch05.html#ch05fig2">Figure 5–2</a> uses the first two terms of this on each 2-bit field, in parallel.
      </p>
      
      <p class="indent"><a id="page_83"></a>There is a simple proof of Equation (1), which is shown below for the case of a four-bit
         word. Let the word be <em>b</em><sub>3</sub><em>b</em><sub>2</sub><em>b</em><sub>1</sub><em>b</em><sub>0</sub>, where each <em>b<sub>i</sub></em> = 0 or 1. Then,
      </p>
      
      <div class="image"><img alt="Image" src="graphics/083equ01.jpg" /></div>
      
      <p class="indent">Alternatively, Equation (1) can be derived by noting that bit <em>i</em> of the binary representation of a nonnegative integer <em>x</em> is given by
      </p>
      
      <div class="image"><img alt="Image" src="graphics/083equ02.jpg" /></div>
      
      <p class="noindent">and summing this for <em>i</em> = 0 to 31. Work it out—the last term is 0 because <em>x</em> &lt; 2<sup>32</sup>. Equation (1) generalizes to other bases. For base ten it is
      </p>
      
      <div class="image"><img alt="Image" src="graphics/083equ03.jpg" /></div>
      
      <p class="noindent">where the terms are carried out until they are 0. This can be proved by essentially
         the same technique used above.
      </p>
      
      <p class="indent">A variation of the above algorithm is to use a base 4 analogue of Equation (1) as
         a substitute for the second executable line of <a href="ch05.html#ch05fig2">Figure 5–2</a>:
      </p>
      
      <p class="codelink"><a href="images4.html#p05pro01" id="p05pro01a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = x - 3*((x &gt;&gt; 2) &amp; 0x33333333)</p>
      
      <p class="noindent">This code, however, uses the same number of instructions as the line it replaces (six),
         and requires a fast <em>multiply-by-3</em> instruction.
      </p>
      
      <p class="indent">An algorithm in HAKMEM memo [HAK, item 169] counts the number of 1-bits in a word
         by using the first three terms of (1) to produce a word of 3-bit fields, each of which
         contains the number of 1-bits that were in it. It then adds adjacent 3-bit fields
         to form 6-bit field sums, and then adds the 6-bit fields by computing the value of
         the word modulo 63. Expressed in C, the algorithm is (the long constants are in octal)
      </p>
      
      <p class="codelink"><a id="page_84"></a><a href="images4.html#p084equ01" id="p084equ01a">Click here to view code image</a></p>
      
      <p class="programlisting">int pop(unsigned x) {<br />   unsigned n;<br /><br />   n = (x &gt;&gt; 1) &amp; 033333333333;       // Count bits in<br />   x = x - n;                         // each 3-bit<br />   n = (n &gt;&gt; 1) &amp; 033333333333;       // field.<br />   x = x - n;<br />   x = (x + (x &gt;&gt; 3)) &amp; 030707070707; // 6-bit sums.<br />   return x%63;                       // Add 6-bit sums.<br />}
      </p>
      
      <p class="indent">The last line uses the <em>unsigned modulus</em> function. (It could be either signed or unsigned if the word length were a multiple
         of 3.) That the modulus function sums the 6-bit fields becomes clear by regarding
         the word <code>x</code> as an integer written in base 64. The remainder upon dividing a base <em>b</em> integer by <em>b</em> – 1 is, for <em>b</em> ≥ 3, congruent mod <em>b</em> – 1 to the sum of the digits and, of course, is less than <em>b</em> – 1. Because the sum of the digits in this case must be less than or equal to 32,
         mod(<em>x</em>, 63) must be equal to the sum of the digits of <em>x</em>, which is to say equal to the number of 1-bits in the original <em>x</em>.
      </p>
      
      <p class="indent">This algorithm requires only ten instructions on the DEC PDP-10, because that machine
         has an instruction for computing the remainder with its second operand directly referencing
         a fullword in memory. On a basic RISC, it requires about 13 instructions, assuming
         the machine has <em>unsigned modulus</em> as one instruction (but not directly referencing a fullword immediate or memory operand).
         It is probably not very fast, because division is almost always a slow operation.
         Also, it doesn’t apply to 64-bit word lengths by simply extending the constants, although
         it does work for word lengths up to 62.
      </p>
      
      <p class="indent">The return statement in the code above can be replaced with the following, which runs
         faster on most machines, but is perhaps less elegant (octal notation again).
      </p>
      
      <p class="codelink"><a href="images4.html#p084equ02" id="p084equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">return ((x * 0404040404) &gt;&gt; 26) +   // Add 6-bit sums.<br />        (x &gt;&gt; 30);
      </p>
      
      <p class="indent">A variation on the HAKMEM algorithm is to use Equation (1) to count the number of
         1’s in each 4-bit field, working on all eight 4-bit fields in parallel [Hay1]. Then,
         the 4-bit sums can be converted to 8-bit sums in a straightforward way, and the four
         bytes can be added with a multiplication by 0x01010101. This gives
      </p>
      
      <p class="codelink"><a href="images4.html#p084equ03" id="p084equ03a">Click here to view code image</a></p>
      
      <p class="programlisting">int pop(unsigned x) {<br />   unsigned n;<br /><br />   n = (x &gt;&gt; 1) &amp; 0x77777777;          // Count bits in<br />   x = x - n;                          // each 4-bit<br />   n = (n &gt;&gt; 1) &amp; 0x77777777;          // field.<br /><a id="page_85"></a>   x = x - n;<br />   n = (n &gt;&gt; 1) &amp; 0x77777777;<br />   x = x - n;<br />   x = (x + (x &gt;&gt; 4)) &amp; 0x0F0F0F0F;    // Get byte sums.<br />   x = x*0x01010101;                   // Add the bytes.<br />   return x &gt;&gt; 24;<br />}
      </p>
      
      <p class="indent">This is 19 instructions on the basic RISC. It works well if the machine is two-address,
         because the first six lines can be done with only one <em>move register</em> instruction. Also, the repeated use of the mask <code>0x77777777</code> permits loading it into a register and referencing it with register-to-register instructions.
         Furthermore, most of the shifts are of only one position.
      </p>
      
      <p class="indent">A quite different bit-counting method, illustrated in <a href="ch05.html#ch05fig3">Figure 5–3</a>, is to turn off the rightmost 1-bit repeatedly [Weg, RND], until the result is 0.
         It is very fast if the number of 1-bits is small, taking 2 + 5pop(<em>x</em>) instructions.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig03" id="p05fig03a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting1"><a id="ch05fig3"></a>int pop(unsigned x) {<br />   int n;<br /><br />   n = 0;<br />   while (x ! = 0) {<br />      n = n+ 1;<br />      x = x &amp; (x - 1);<br />   }<br />   returnn;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–3. Counting 1-bits in a sparsely populated word.
      </p>
      
      <p class="indent">This has a dual algorithm that is applicable if the number of 1-bits is expected to
         be large. The dual algorithm keeps turning on the rightmost 0-bit with <code>x = x | (x + 1),</code> until the result is all 1’s (–1). Then, it returns 32 – <em>n</em>. (Alternatively, the original number <em>x</em> can be complemented, or <em>n</em> can be initialized to 32 and counted down.)
      </p>
      
      <p class="indent">A rather amazing algorithm is to rotate <strong><em>x</em></strong> left one position, 31 times, adding the 32 terms [MM]. The sum is the negative of
         pop(<em>x</em>)! That is,
      </p>
      
      <div class="image"><img alt="Image" src="graphics/05equ02.jpg" /></div>
      
      <p class="noindent">where the additions are done modulo the word size, and the final sum is interpreted
         as a two’s-complement integer. This is just a novelty; it would not be useful on most
         machines, because the loop is executed 31 times and thus it requires 63 instructions,
         plus the loop-control overhead.
      </p>
      
      <p class="indent">To see why Equation (2) works, consider what happens to a single 1-bit of <strong><em>x</em></strong>. It gets rotated to all positions, and when these 32 numbers are added, a word of
         all <a id="page_86"></a>1-bits results. This is –1. To illustrate, consider a 6-bit word size and <strong><em>x</em></strong> = <strong>001001</strong> (binary):
      </p>
      
      <div class="image"><img alt="Image" src="graphics/086equ01.jpg" /></div>
      
      <p class="noindent">Of course, <em>rotate-right</em> would work just as well.
      </p>
      
      <p class="indent">The method of Equation (1) is very similar to this “rotate and sum” method, which
         becomes clear by rewriting (1) as
      </p>
      
      <div class="image"><img alt="Image" src="graphics/086equ02.jpg" /></div>
      
      <p class="noindent">This gives a slightly better algorithm than Equation (2) provides. It is better because
         it uses <em>shift right</em>, which is more commonly available than <em>rotate</em>, and because the loop can be terminated when the shifted quantity becomes 0. This
         reduces the loop-control code and may save a few iterations. The two algorithms are
         contrasted in <a href="ch05.html#ch05fig4">Figure 5–4</a>.
      </p>
      
      <p class="codelink"><a id="page_87"></a><a href="images4.html#p05equ04" id="p05equ04a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig4"></a>int pop(unsigned x) {<br />   int i, sum;<br /><br />// Rotate and sum method            // Shift right &amp; subtract<br /><br />   sum = x; // sum = x;<br />   for (i = 1; i &lt;= 31; i++) {      // while (x != 0) {<br />       x = rotatel (x, 1);          //    x = x &gt;&gt; 1;<br />       sum = sum + x;               //    sum = sum - x;<br />   }                                // }<br />   return -sum;                     // return sum;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–4. Two similar bit-counting algorithms.
      </p>
      
      <p class="indent">A less interesting algorithm that may be competitive with all the algorithms for pop(<em>x</em>) in this section is to have a table that contains pop(<em>x</em>) for, say, <em>x</em> in the range 0 to 255. The table can be accessed four times, adding the four numbers
         obtained. A branch-free version of the algorithm looks like this:
      </p>
      
      <p class="codelink"><a href="images4.html#p086equ03" id="p086equ03a">Click here to view code image</a></p>
      
      <p class="programlisting1">int pop(unsigned x) {               // Table lookup.<br />   static char table[256] = {<br />      0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,<br />      ...<br />      4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8};<br />   return table[x         &amp; 0xFF] +<br />          table[(x &gt;&gt;  8) &amp; 0xFF] +<br />          table[(x &gt;&gt; 16) &amp; 0xFF] +<br />          table[(x &gt;&gt; 24)];<br />}
      </p>
      
      <p class="indent">Item 167 in [HAK] contains a short algorithm for counting the number of 1-bits in
         a 9-bit quantity that is right-adjusted and isolated in a register. It works only
         on machines with registers of 36 or more bits. Below is a version of that algorithm
         that works on 32-bit machines, but only for 8-bit quantities.
      </p>
      
      <p class="codelink"><a href="images4.html#p087equ02" id="p087equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = x * 0x08040201;  // Make 4 copies.<br />x = x &gt;&gt; 3;          // So next step hits proper bits.<br />x = x &amp; 0x11111111;  // Every 4th bit.<br />x = x * 0x11111111;  // Sum the digits (each 0 or 1).<br />x = x &gt;&gt; 28;         // Position the result.
      </p>
      
      <p class="indent">A version for 7-bit quantities is</p>
      
      <p class="codelink"><a href="images4.html#p087equ03" id="p087equ03a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = x * 0x02040810;  // Make 4 copies, left-adjusted.<br />x = x &amp; 0x11111111;  // Every 4th bit.<br />x = x * 0x11111111;  // Sum the digits (each 0 or 1).<br />x = x &gt;&gt; 28;         // Position the result.
      </p>
      
      <p class="indent">In these, the last two steps can be replaced with steps to compute the remainder of
         <code>x</code> modulo 15.
      </p>
      
      <p class="indent">These are not particularly good; most programmers would probably prefer to use table
         lookup. The latter algorithm above, however, has a version that uses 64-bit arithmetic,
         which might be useful for a 64-bit machine that has fast multiplication. Its argument
         is a 15-bit quantity. (I don’t believe there is a similar algorithm that deals with
         16-bit quantities, unless it is known that not all 16 bits are 1.) The data type <code>long long</code> is a C extension found in many C compilers, old and new, for 64-bit integers. It
         is made official in the C99 standard. The suffix <code>ULL</code> makes <code>unsigned long long</code> constants.
      </p>
      
      <p class="codelink"><a href="images4.html#p087equ04" id="p087equ04a">Click here to view code image</a></p>
      
      <p class="programlisting">int pop(unsigned x) {<br />   unsigned long long y;<br />   y = x * 0x0002000400080010ULL;<br />   y = y &amp; 0x1111111111111111ULL;<br />   y = y * 0x1111111111111111ULL;<br />   y = y &gt;&gt; 60;<br />   return y;<br />}
      </p>
      
      <h4><a id="page_88"></a><strong>Sum and Difference of Population Counts of Two Words</strong></h4>
      
      <p class="noindent">To compute pop(<strong><em>x</em></strong>) + pop(<strong><em>y</em></strong>) (if your computer does not have the <em>population count</em> instruction), some time can be saved by using the first two lines of <a href="ch05.html#ch05fig2">Figure 5–2</a> on <strong><em>x</em></strong> and <strong><em>y</em></strong> separately, adding <strong><em>x</em></strong> and <strong><em>y</em></strong>, and then executing the last three stages of the algorithm on the sum. After the
         first two lines of <a href="ch05.html#ch05fig2">Figure 5–2</a> are executed, <strong><em>x</em></strong> and <strong><em>y</em></strong> consist of eight 4-bit fields, each containing a maximum value of 4. Thus, <strong><em>x</em></strong> and <strong><em>y</em></strong> can safely be added, because the maximum value in any 4-bit field of the sum would
         be 8, so no overflow occurs. (In fact, three words can be combined in this way.)
      </p>
      
      <p class="indent">This idea also applies to subtraction. To compute pop(<strong><em>x</em></strong>) – pop(<strong><em>y</em></strong>), use
      </p>
      
      <div class="image"><img alt="Image" src="graphics/088equ01.jpg" /></div>
      
      <p class="noindent">Then, use the technique just described to compute pop(<strong><em>x</em></strong>) + pop(<strong><em>y</em></strong>). The code is shown in <a href="ch05.html#ch05fig5">Figure 5–5</a>. It uses 32 instructions, versus 43 for two applications of the code in <a href="ch05.html#ch05fig2">Figure 5–2</a> followed by a subtraction.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig05" id="p05fig05a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig5"></a>int popDiff(unsigned x, unsigned y) {<br />   x = x - ((x &gt;&gt; 1) &amp; 0x55555555);<br />   x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);<br />   y = ~y;<br />   y = y - ((y &gt;&gt; 1) &amp; 0x55555555);<br />   y = (y &amp; 0x33333333) + ((y &gt;&gt; 2) &amp; 0x33333333);<br />   x = x + y;<br />   x = (x &amp; 0x0F0F0F0F) + ((x &gt;&gt; 4) &amp; 0x0F0F0F0F);<br />   x = x + (x &gt;&gt; 8);<br />   x = x + (x &gt;&gt; 16);<br />   return (x &amp; 0x0000007F) - 32;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–5. Computing pop(<strong><em>x</em></strong>) – pop(<strong><em>y</em></strong>).
      </p>
      
      <h4><strong>Comparing the Population Counts of Two Words</strong></h4>
      
      <p class="noindent">Sometimes one wants to know which of two words has the larger population count without
         regard to the actual counts. Can this be determined without doing a population count
         of the two words? Computing the difference of two population counts as in <a href="ch05.html#ch05fig5">Figure 5–5</a>, and comparing the result to 0 is one way, but there is another way that is preferable
         if either the population counts are expected to be low or if there is a strong correlation
         between the particular bits that are set in the two words.
      </p>
      
      <p class="indent">The idea is to clear a single bit in each word until one of the words is all zero;
         the other word then has the larger population count. The process runs faster in its
         worst and average cases if the bits that are 1 at the same positions in each word
         are first cleared. The code is shown in <a href="ch05.html#ch05fig6">Figure 5–6</a>. The procedure returns a negative integer if pop(<strong><em>x</em></strong>) &lt; pop(<strong><em>y</em></strong>), 0 if pop(<strong><em>x</em></strong>) = pop(<strong><em>y</em></strong>), and a positive integer (1) if pop(<strong><em>x</em></strong>) &gt; pop(<strong><em>y</em></strong>).
      </p>
      
      <p class="codelink"><a id="page_89"></a><a href="images4.html#p05fig06" id="p05fig06a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig6"></a>int popCmpr(unsigned xp, unsigned yp) {<br />   unsigned x, y;<br />   x = xp &amp; ~yp;                // Clear bits where<br />   y = yp &amp; ~xp;                // both are 1.<br />   while (1) {<br />      if (x == 0) return y | -y;<br />      if (y == 0) return 1;<br />      x = x &amp; (x - 1);          // Clear one bit<br />      y = y &amp; (y - 1);          // from each.<br />   }<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–6. Comparing pop(<strong><em>x</em></strong>) with pop(<strong><em>y</em></strong>).
      </p>
      
      <p class="indent">After clearing the common 1-bits in each 32-bit word, the maximum possible number
         of 1-bits in both words together is 32. Therefore, the word with the smaller number
         of 1-bits can have at most 16. Thus, the loop in <a href="ch05.html#ch05fig6">Figure 5–6</a> is executed a maximum of 16 times, which gives a worst case of 119 instructions executed
         on the basic RISC (16 · 7 + 7). A simulation using uniformly distributed random 32-bit
         integers showed that the average population count of the word with the smaller population
         count is approximately 6.186, after clearing the common 1-bits. This gives an average
         execution time of about 50 instructions executed for random 32-bit inputs, not as
         good as using <a href="ch05.html#ch05fig5">Figure 5–5</a>. For this procedure to beat that of <a href="ch05.html#ch05fig5">Figure 5–5</a>, the number of 1-bits in either <code>x</code> or <code>y</code>, after clearing the common 1-bits, would have to be three or less.
      </p>
      
      <h4><strong>Counting the 1-bits in an Array</strong></h4>
      
      <p class="noindent">The simplest way to count the number of 1-bits in an array (vector) of fullwords,
         in the absence of the population count instruction, is to use a procedure such as
         that of <a href="ch05.html#ch05fig2">Figure 5–2</a> on page <a href="ch05.html#page_82">82</a> on each word of the array and simply add the results. We call this the “naive” method.
         Ignoring loop control, the generation of constants, and loads from the array, it takes
         16 instructions per word: 15 for the code of <a href="ch05.html#ch05fig2">Figure 5–2</a>, plus one for the addition. We assume the procedure is expanded in line, the masks
         are loaded outside the loop, and the machine has a sufficient number of registers
         to hold all the quantities used in the calculation.
      </p>
      
      <p class="indent">Another way is to use the first two executable lines of <a href="ch05.html#ch05fig2">Figure 5–2</a> on groups of three words in the array, adding the three partial results. Because
         each partial result has a maximum value of 4 in each four-bit field, the sum of the
         three has a maximum value of 12 in each four-bit field, so no overflow occurs. This
         idea can be applied to the 8- and 16-bit fields. Coding and compiling this method
         indicates that it gives about a 20% reduction over the naive method in total number
         of instructions executed on the basic RISC. Much of the savings are cancelled by the
         additional housekeeping instructions required. We will not dwell on this method because
         there is a <em>much</em> better way to do it.
      </p>
      
      <p class="indent"><a id="page_90"></a>The better way seems to have been invented by Robert Harley and David Seal in about
         1996 [Seal1]. It is based on a circuit called a <em>carry-save adder</em> (CSA), or 3:2 compressor. A CSA is simply a sequence of independent full adders<sup><a id="ch05fna1"></a><a href="footnotes.html#ch05fn1">1</a></sup> [H&amp;P], and it is often used in binary multiplier circuits.
      </p>
      
      <p class="indent">In Boolean algebra notation, the logic for each full adder is</p>
      
      <p class="indenthangingNP"><em>h</em> ← <em>ab</em> + <em>ac</em> + <em>bc</em> = <em>ab</em> + (<em>a</em> + <em>b</em>)<em>c</em> = <em>ab</em> + (<em>a</em> ⊕ <em>b</em>)<em>c</em>,<br /><em>l</em> ← (<em>a</em>⊕ <em>b</em>) ⊕ <em>c</em>.
      </p>
      
      <p class="noindent">where <em>a, b</em>, and <em>c</em> are the 1-bit inputs, <em>l</em> is the low-bit output (sum) and <em>h</em> is the high-bit output (carry). Changing <em>a</em> + <em>b</em> on the first line to <em>a</em> ⊕ <em>b</em> is justified because when <em>a</em> and <em>b</em> are both 1, the term <em>ab</em> makes the value of the whole expression 1. By first assigning <em>a</em> ⊕ <em>b</em> to a temporary, the full adder logic can be evaluated in five logical instructions,
         each operating on 32 bits in parallel (on a 32-bit machine). We will refer to these
         five instructions as CSA(<em>h, l, a, b, c</em>). This is a “macro,” with <em>h</em> and <em>l</em> being outputs.
      </p>
      
      <p class="indent">One way to use the CSA operation is to process elements of the array <em>A</em> in groups of three, reducing each group of three words to two, and applying the population
         count operation to these two words. In the loop, these two population counts are summed.
         After executing the loop, the total population count of the array is twice the accumulated
         population count of the CSA’s high-bit outputs, plus the accumulated population count
         of the low-bit outputs.
      </p>
      
      <p class="indent">Let <em>n<sub>c</sub></em> be the number of instructions required for the CSA steps and <em>n<sub>p</sub></em> be the number of instructions required to do the population count of one word. On
         a typical RISC machine <em>n<sub>c</sub></em> = 5 and <em>n<sub>p</sub></em> = 15. Ignoring loads from the array and loop control (the code for which may vary
         quite a bit from one machine to another), the loop discussed above takes (<em>n<sub>c</sub></em> + 2<em>n<sub>p</sub></em> + 2)/3 ≈ 12.33 instructions per word of the array (the “+2” is for the two additions
         in the loop). This is in contrast to the 16 instructions per word required by the
         naive method.
      </p>
      
      <p class="indent">There is another way to use the CSA operation that results in a program that’s more
         efficient and slightly more compact. This is shown in <a href="ch05.html#ch05fig7">Figure 5–7</a>. It takes (<em>n<sub>c</sub></em> + <em>n<sub>p</sub></em> + 1)/2 =10.5 instructions per word (ignoring loop control and loads). In this code,
         the CSA operation expands into
      </p>
      
      <p class="codelink"><a id="page_91"></a><a href="images4.html#p05fig07" id="p05fig07a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig7"></a>#define CSA(h,l, a,b,c) \<br />   {unsigned u = a ^ b; unsigned v = c; \<br />      h = (a &amp; b) | (u &amp; v); l = u ^ v;}<br /><br />int popArray(unsigned A[], int n) {<br /><br />   int tot, i;<br />   unsigned ones, twos;<br /><br />   tot = 0;                      // Initialize.<br />   ones = 0;<br />   for (i = 0; i &lt;= n - 2; i = i + 2) {<br />      CSA(twos, ones, ones, A[i], A[i+1])<br />      tot = tot + pop(twos);<br />   }<br />   tot = 2*tot + pop(ones);<br /><br />   if (n &amp; 1)                    // If there's a last one,<br />      tot = tot + pop(A[i]);      // add it in.<br /><br />   return tot;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–7. Array population count, processing elements in groups of two.
      </p>
      
      <p class="codelink"><a href="images4.html#p090pro01" id="p090pro01a">Click here to view code image</a></p>
      
      <p class="programlisting1">u = ones ^ A[i];<br />v = A[i+1];<br />twos = (ones &amp; A[i]) | (u &amp; v);<br />ones = u ^ v;<br /></p>
      
      <p class="noindent">The code relies on the compiler to common the loads.</p>
      
      <p class="indent">There are ways to use the CSA operation to further reduce the number of instructions
         required to compute the population count of an array. They are most easily understood
         by means of a circuit diagram. For example, <a href="ch05.html#ch05fig8">Figure 5–8</a> illustrates a way to code a loop that takes array elements eight at a time and compresses
         them into four quantities, labeled <em>eights, fours, twos</em>, and <em>ones</em>. The <em>fours, twos</em>, and <em>ones</em> are fed back into the CSAs on the next loop iteration, and the 1-bits in <em>eights</em> are counted by an execution of the word-level population count function, and this
         count is accumulated. When all of the array has been processed, the total population
         count is
      </p>
      
      <p class="center">8pop(<em>eights</em>) + 4pop(<em>fours</em>) + 2pop(<em>twos</em>) + pop(<em>ones</em>).
      </p>
      
      <div class="image"><a id="ch05fig8"></a><img alt="Image" src="graphics/05fig08.jpg" /></div>
      
      <p class="fig-caption">F<small>IGURE</small> 5–8. A circuit for the array population count.
      </p>
      
      <p class="indent">The code is shown in <a href="ch05.html#ch05fig9">Figure 5–9</a>, which uses the CSA macro defined in <a href="ch05.html#ch05fig7">Figure 5–7</a>. The numbering of the CSA blocks in <a href="ch05.html#ch05fig8">Figure 5–8</a> corresponds to the order of the CSA macro calls in <a href="ch05.html#ch05fig9">Figure 5–9</a>. The execution time of the loop, exclusive of array loads and loop control, is (7<em>n<sub>c</sub></em> + <em>n<sub>p</sub></em> + 1)/8 = 6.375 instructions per word of the array.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig09" id="p05fig09a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting1"><a id="ch05fig9"></a>int popArray(unsigned A[], int n) {<br /><br />   int tot, i;<br />   unsigned ones, twos, twosA, twosB,<br />      fours, foursA, foursB, eights;<br /><br />   tot = 0;                     // Initialize.<br />   fours = twos = ones = 0;<br /><br />   for (i = 0; i &lt;= n - 8; i = i + 8) {<br />      CSA(twosA, ones, ones, A[i], A[i+1])<br />      CSA(twosB, ones, ones, A[i+2], A[i+3])<br />      CSA(foursA, twos, twos, twosA, twosB)<br />      CSA(twosA, ones, ones, A[i+4], A[i+5])<br />      CSA(twosB, ones, ones, A[i+6], A[i+7])<br />      CSA(foursB, twos, twos, twosA, twosB)<br />      CSA(eights, fours, fours, foursA, foursB)<br />      tot = tot + pop(eights);<br />   }<br />   tot = 8*tot + 4*pop(fours + 2*pop(twos) + pop(ones);<br /><br />   for (i = i; i &lt; n; i++)       // Simply add in the last<br />      tot = tot + pop(A[i]);    // 0 to 7 elements.<br />   return tot;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–9. Array population count, processing elements in groups of eight.
      </p>
      
      <p class="indent">The CSAs can be connected in many arrangements other than that shown in <a href="ch05.html#ch05fig8">Figure 5–8</a>. For example, increased parallelism might result from feeding the first three array
         elements into one CSA, and the next three into a second CSA, which allows the instructions
         of these two CSAs to execute in parallel. One might also be able to permute the three
         input operands of the CSA macros for <a id="page_92"></a>increased parallelism. With the plan shown in <a href="ch05.html#ch05fig8">Figure 5–8</a>, one can easily see how to use only the first three CSAs to construct a program that
         processes array elements in groups of four, and also how to expand it to construct
         programs that process array elements in groups of 16 or more. The plan shown also
         spreads out the loads somewhat, which would be advantageous for a machine that has
         a relatively low limit on the number of loads that can be outstanding at any one time.
      </p>
      
      <p class="indent">The plan of <a href="ch05.html#ch05fig8">Figure 5–8</a> can be generalized so that very few word population counts are done. To sketch how
         this program might be constructed, it needs an array of <em>m</em>×2 words to hold two of each of the variables we have called <em>ones, twos, fours</em>, and so forth. For an array of size <em>n</em>, choosing <em>m</em> ≥ <span class="entity">⌈</span>log<sub>2</sub>(<em>n</em> + 1)<span class="entity">⌉</span> + 1 is sufficient (<em>m</em> = 31 is sufficient for any size array that can be held in a machine with a 32-bit
         byte-addressed space). A byte array of size <em>m</em> is also needed to keep track of how many (0, 1, or 2) values are currently in each
         row of the <em>m</em>×2 array. The program processes array elements in groups of two. For each group, the
         CSA is invoked to compress those two array elements with a saved value of <em>ones</em>, which is most conveniently kept in the [0,0] position of the <em>m</em>×2 array. In an inner loop, the resulting <em>twos</em> is saved in the array, by scanning down (usually not far at all) to find a row with
         fewer than two items. If the <em>twos</em> row is full, its two values are combined with <em>twos</em> (using the CSA). The <em>twos</em> output is put in the array, resetting its <a id="page_93"></a>row count to 1. The scan continues with the <em>fours</em> output to find a place to put it, and so forth.
      </p>
      
      <p class="indent">After completing the pass over the input array, the program next makes a pass over
         the (much shorter) <em>m</em>×2 array, compressing all full rows, so that all rows contain only one significant
         value. Lastly, the program invokes the word-level population count operation on the
         first element of each row until a row with a zero count is encountered, computing
         the total array population count as
      </p>
      
      <p class="center">pop(row 0) + 2pop(row 1) + 4pop(row 2) + ....</p>
      
      <p class="noindent">The value suggested above for <em>m</em> ensures that the last row will have a zero count, which can be used to terminate
         the scans.
      </p>
      
      <p class="indent">The resulting program executes exactly <span class="entity">⌈</span>log<sub>2</sub>(<em>n</em> + 3)<span class="entity">⌉</span> word population counts. Unfortunately it is not practical, because the housekeeping
         steps for loading from and storing into the intermediate result arrays outweigh the
         computational instructions that are saved. An experimental program (without trying
         too hard to optimize it) ran in about 29 instructions per array word (counting all
         instructions in the loop). This is significantly worse than the naive method.
      </p>
      
      <p class="indent"><a href="ch05.html#ch05tab1">Table 5–1</a> summarizes the number of instructions executed by this plan for various group sizes.
         The values in the middle two columns ignore loads and loop <a id="page_94"></a>control. The fourth column gives the total loop instruction execution count, per word
         of the input array, produced by a compiler for the basic RISC machine (which does
         not have indexed loads).
      </p>
      
      <p class="tab-caption"><a id="ch05tab1"></a>T<small>ABLE</small> 5–1. I<small>NSTRUCTIONS</small> P<small>ER</small> W<small>ORD FOR THE</small> A<small>RRAY</small> P<small>OPULATION</small> C<small>OUNT</small></p>
      
      <div class="image"><img alt="Image" src="graphics/05tab01.jpg" /></div>
      
      <p class="indent">For small arrays, there are better plans than that of <a href="ch05.html#ch05fig8">Figure 5–8</a>. For example, for an array of seven words, the plan of <a href="ch05.html#ch05fig10">Figure 5–10</a> is quite efficient [Seal1]. It <a id="page_95"></a>executes in 4<em>n<sub>c</sub></em> + 3<em>n<sub>p</sub></em> + 4 = 69 instructions, or 9.86 instructions per word. Similar plans exist that apply
         to arrays of size 2<sup><em>k</em></sup> − 1 words for any positive integer <em>k</em>. The plan for 15 words executes in 11<em>n<sub>c</sub></em> + 4<em>n<sub>p</sub></em> + 6 = 121 instructions, or 8.07 instructions per word.
      </p>
      
      <div class="image"><a id="ch05fig10"></a><img alt="Image" src="graphics/05fig10.jpg" /></div>
      
      <p class="fig-caption">F<small>IGURE</small> 5–10. A circuit for the total population count of seven words.
      </p>
      
      <h4><strong>Applications</strong></h4>
      
      <p class="noindent">An application of the <em>population count</em> function is in computing the “Hamming distance” between two bit vectors, a concept
         from the theory of error-correcting codes. The Hamming distance is simply the number
         of places where the vectors differ; that is,
      </p>
      
      <p class="center">dist(<strong><em>x, y</em></strong>) = pop(<strong><em>x</em></strong>⊕<strong><em>y</em></strong>).
      </p>
      
      <p class="noindent">See, for example, the chapter on error-correcting codes in [Dewd].</p>
      
      <p class="indent">Another application is to allow reasonably fast direct-indexed access to a moderately
         sparse array <em>A</em> that is represented in a certain compact way. In the compact representation, only
         the defined, or nonzero, elements of the array are stored. There is an auxiliary bit
         string array <em>bits</em> of 32-bit words, which has a 1-bit for each index <em>i</em> for which <em>A</em>[<em>i</em>] is defined. As a speedup device, there is also an array of words <em>bitsum</em> such that <em>bitsum</em>[<em>j</em>] is the total number of 1-bits in all the words of <em>bits</em> that precede entry <em>j</em>. This is illustrated below for an array in which elements 0, 2, 32, 47, 48, and 95
         are defined.
      </p>
      
      <div class="image"><img alt="Image" src="graphics/095equ01.jpg" /></div>
      
      <p class="indent">Given an index <em>i</em>, 0 ≤ <em>i</em> ≤ 95, the corresponding index <em>sparse_i</em> into the data array is given by the number of 1-bits in array <em>bits</em> that precede the bit corresponding to <em>i</em>. This can be calculated as follows:
      </p>
      
      <p class="codelink"><a href="images4.html#p095pro01" id="p095pro01a">Click here to view code image</a></p>
      
      <p class="programlisting1">j = i &gt;&gt; 5;                  // j = i/32.<br />k = i &amp; 31;                  // k = rem(i, 32);<br />mask = 1 <span class="entity">&lt;&lt;</span> k;               // A "1" at position k.<br />if ((bits[j] &amp; mask) == 0) goto no_such_element;<br />mask = mask - 1;             // l's to right of k.<br />sparse_i = bitsum[j] + pop(bits[j] &amp; mask);
      </p>
      
      <p class="noindent">The cost of this representation is two bits per element of the full array.</p>
      
      <p class="indent"><a id="page_96"></a>The population function can be used to generate binomially distributed random integers.
         To generate an integer drawn from a population given by BINOMIAL(<em>t, p</em>) where <em>t</em> is the number of trials and <em>p</em> = 1/2, generate <em>t</em> random bits and count the number of 1’s in the <em>t</em> bits. This can be generalized to probabilities <em>p</em> other than 1/2; see for example [Knu2, sec. 3.4.1, prob. 27].
      </p>
      
      <p class="indent">Still another application of the population function is in computing the number of
         trailing 0’s in a word (see “<a href="ch05.html#ch05lev4">Counting Trailing 0’s</a>” on page <a href="ch05.html#ch05lev4">107</a>).
      </p>
      
      <p class="indent">According to computer folklore, the population count function is important to the
         National Security Agency. No one (outside of NSA) seems to know just what they use
         it for, but it may be in cryptography work or in searching huge amounts of material.
      </p>
      
      <h3><a id="ch05lev2"></a><strong>5–2 Parity</strong></h3>
      
      <p class="noindent">The “parity” of a string refers to whether it contains an odd or an even number of
         1-bits. The string has “odd parity” if it contains an odd number of 1-bits; otherwise,
         it has “even parity.”
      </p>
      
      <h4><strong>Computing the Parity of a Word</strong></h4>
      
      <p class="noindent">Here we mean to produce a 1 if a word <strong><em>x</em></strong> has odd parity, and a 0 if it has even parity. This is the sum, modulo 2, of the
         bits of <strong><em>x</em></strong>—that is, the <em>exclusive or</em> of all the bits of <strong><em>x</em></strong>.
      </p>
      
      <p class="indent">One way to compute this is to compute pop(<strong><em>x</em></strong>); the parity is the rightmost bit of the result. This is fine if you have the <em>population count</em> instruction, but if not, there are better ways than using the code for pop(<strong><em>x</em></strong>).
      </p>
      
      <p class="indent">A rather direct method is to compute</p>
      
      <div class="image"><img alt="Image" src="graphics/096equ01.jpg" /></div>
      
      <p class="noindent">where <em>n</em> is the word size, and then the parity of <strong><em>x</em></strong> is given by the rightmost bit of <strong><em>y</em></strong>. (Here ⊕ denotes <em>exclusive or</em>, but for this formula ordinary addition could be used.)
      </p>
      
      <p class="indent">The parity can be computed much more quickly, for moderately large <em>n</em>, as follows (illustrated for <em>n</em> = 32; the shifts can be signed or unsigned):
      </p>
      
      <div class="image"><img alt="Image" src="graphics/05equ03.jpg" /></div>
      
      <p class="noindent">This executes in ten instructions, as compared to 62 for the first method, even if
         the implied loop is completely unrolled. Again, the parity bit is the rightmost bit
         <a id="page_97"></a>of <strong><em>y</em></strong>. In fact, with either of these, if the shifts are unsigned, then bit <em>i</em> of <strong><em>y</em></strong> gives the parity of the bits of <strong><em>x</em></strong> at and to the left of <em>i</em>. Furthermore, because <em>exclusive or</em> is its own inverse, <strong><em>x</em></strong><sub><em>i</em></sub> ⊕ <strong><em>x</em></strong><sub><em>j</em></sub> is the parity of bits <em>i</em> − 1 through <em>j</em>, for <em>i</em> ≥ <em>j</em>.
      </p>
      
      <p class="indent">This is an example of the “parallel prefix,” or “scan” operation, which has applications
         in parallel computing [KRS; HS]. Given a sufficient number of processors, it can convert
         certain seemingly serial processes from <em>O</em>(<em>n</em>) to <em>O</em>(log<sub>2</sub><em>n</em>) time. For example, if you have an array of words and you wish to compute the <em>exclusive or</em> scan operation on the entire array of bits, you can first use (3) on the entire array,
         and then continue with shifts of 32 bits, 64 bits, and so on, doing <em>exclusive or</em>’s on the words of the array. This takes more elementary (word length) <em>exclusive or</em> operations than a simple left-to-right process, and hence it is not a good idea for
         a uniprocessor. But on a parallel computer with a sufficient number of processors,
         it can do the job in <em>O</em>(log<sub>2</sub><em>n</em>) rather than <em>O</em>(<em>n</em>) time (where <em>n</em> is the number of words in the array).
      </p>
      
      <p class="indent">A direct application of (3) is the conversion of a Gray coded integer to binary (see
         page <a href="ch13.html#page_312">312</a>).
      </p>
      
      <p class="indent">If the code (3) is changed to use left shifts, the parity of the whole word <strong><em>x</em></strong> winds up in the leftmost bit position, and bit <em>i</em> of <strong><em>y</em></strong> gives the parity of the bits of <strong><em>x</em></strong> at and to the <em>right</em> of position <em>i</em>. This is called the “parallel suffix” operation, because each bit is a function of
         itself and the bits that follow it.
      </p>
      
      <p class="indent">If <em>rotate shift</em>’s are used, the result is a word of all 1’s if the parity of <strong><em>x</em></strong> is odd, and of all 0’s if even.
      </p>
      
      <p class="indent">The five assignments in (3) can be done in any order (provided variable <code>x</code> is used in the first one). If they are done in reverse order, and if you are interested
         only in getting the parity in the low-order bit of <code>y</code>, then the last two lines:
      </p>
      
      <p class="codelink"><a href="images4.html#p097equ01" id="p097equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">y = y ^(y &gt;&gt; 2);<br />y = y ^(y &gt;&gt; 1);
      </p>
      
      <p class="noindent">can be replaced with [Huef]</p>
      
      <p class="codelink"><a href="images4.html#p097equ02" id="p097equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">y = 0x6996 &gt;&gt; (y &amp; 0xF);</p>
      
      <p class="noindent">This is an “in-register table lookup” operation. On the basic RISC it saves one instruction,
         or two if the load of the constant is not counted. The low-order bit of <code>y</code> has the original word’s parity, but the other bits of <code>y</code> do not contain anything useful.
      </p>
      
      <p class="indent">The following method executes in nine instructions and computes the parity of <strong><em>x</em></strong> as the integer 0 or 1 (the shifts are unsigned).
      </p>
      
      <p class="codelink"><a href="images4.html#p097equ03" id="p097equ03a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = x ^ (x &gt;&gt; 1);<br />x = (x ^ (x &gt;&gt; 2)) &amp; 0x11111111;<br />x = x*0x11111111;<br />p = (x &gt;&gt; 28) &amp; 1;
      </p>
      
      <p class="noindent">After the second statement above, each hex digit of <strong><em>x</em></strong> is 0 or 1, according to the parity of the bits in that hex digit. The <em>multiply</em> adds these digits, putting the sum <a id="page_98"></a>in the high-order hex digit. There can be no carry out of any hex column during the
         <em>add</em> part of the multiply, because the maximum sum of a column is 8.
      </p>
      
      <p class="indent">The <em>multiply</em> and <em>shift</em> could be replaced by an instruction to compute the remainder after dividing <strong><em>x</em></strong> by 15, giving a (slow) solution in eight instructions, if the machine has <em>remainder immediate</em>.
      </p>
      
      <p class="indent">On a 64-bit machine, the above code employing multiplication gives the correct result
         after making the obvious changes (expand the hex constants to 16 nibbles, each with
         value 1, and change the final shift amount from 28 to 60). In this case, the maximum
         sum in any 4-bit column of the partial products, other than the most significant column,
         is 15, so again no overflow occurs that affects the result in the most significant
         column. On the other hand, the variation that computes the remainder upon division
         by 15 does <em>not</em> work on a 64-bit machine, because the remainder is the sum of the nibbles modulo
         15, and the sum may be as high as 16.
      </p>
      
      <h4><strong>Adding a Parity Bit to a 7-Bit Quantity</strong></h4>
      
      <p class="noindent">Item 167 in [HAK] contains a novel expression for putting even parity on a 7-bit quantity
         that is right-adjusted and isolated in a register. By this we mean to set the bit
         to the left of the seven bits, to make an 8-bit quantity with even parity. Their code
         is for a 36-bit machine, but it works on a 32-bit machine as well.
      </p>
      
      <p class="center">modu((<strong><em>x</em></strong> * <strong>0x10204081</strong>) &amp; <strong>0x888888FF, 1920</strong>)
      </p>
      
      <p class="noindent">Here, modu(<strong><em>a, b</em></strong>) denotes the remainder of <strong><em>a</em></strong> upon division by <strong><em>b</em></strong>, with the arguments and result interpreted as unsigned integers, “*” denotes multiplication
         modulo 2<sup>32</sup>, and the constant 1920 is 15 · 2<sup>7</sup>. Actually, this computes the sum of the bits of <strong><em>x</em></strong>, and places the sum just to the left of the seven bits comprising <strong><em>x</em></strong>. For example, the expression maps <strong>0x0000007F</strong> to <strong>0x000003FF</strong>, and <strong>0x00000055</strong> to <strong>0x00000255</strong>.
      </p>
      
      <p class="indent">Another ingenious formula from [HAK] is the following, which puts odd parity on a
         7-bit integer:
      </p>
      
      <p class="center">modu((<strong><em>x</em></strong> * <strong>0x00204081</strong>) | <strong>0x3DB6DB00, 1152</strong>),
      </p>
      
      <p class="noindent">where 1152 = 9 · 2<sup>7</sup>. To understand this, it helps to know that the powers of 8 are ±1 modulo 9. If the
         <strong>0x3DB6DB00</strong> is changed to <strong>0xBDB6DB00</strong>, this formula applies even parity.
      </p>
      
      <p class="indent">These methods are not practical on today’s machines, because memory is cheap but division
         is still slow. Most programmers would compute these functions with a simple table
         lookup.
      </p>
      
      <h4><strong>Applications</strong></h4>
      
      <p class="noindent">The parity operation is widely used to calculate a check bit to append to data. It
         is also useful in multiplying bit matrices in GF(2) (in which the <em>add</em> operation is <em>exclusive or</em>).
      </p>
      
      <h3><a id="page_99"></a><a id="ch05lev3"></a><strong>5–3 Counting Leading 0’s</strong></h3>
      
      <p class="noindent">There are several simple ways to count leading 0’s with a binary search technique.
         Below is a model that has several variations. It executes in 20 to 29 instructions
         on the basic RISC. The comparisons are “logical” (unsigned integers).
      </p>
      
      <p class="codelink"><a href="images4.html#p099equ01" id="p099equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">if (x == 0) return(32);<br />n = 0;<br />if (x &lt;= 0x0000FFFF) {n = n +16; x = x <span class="entity">&lt;&lt;</span>16;}<br />if (x &lt;= 0x00FFFFFF) {n = n + 8; x = x <span class="entity">&lt;&lt;</span> 8;}<br />if (x &lt;= 0x0FFFFFFF) {n = n + 4; x = x <span class="entity">&lt;&lt;</span> 4;}<br />if (x &lt;= 0x3FFFFFFF) {n = n + 2; x = x <span class="entity">&lt;&lt;</span> 2;}<br />if (x &lt;= 0x7FFFFFFF) {n = n + 1;}<br />return n;
      </p>
      
      <p class="indent">One variation is to replace the comparisons with <em>and</em>’s:
      </p>
      
      <p class="codelink"><a href="images4.html#p099equ02" id="p099equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">if ((x &amp; 0xFFFF0000) == 0) {n = n +16; x = x <span class="entity">&lt;&lt;</span>16;}<br />if ((x &amp; 0xFF000000) == 0) {n = n + 8; x = x <span class="entity">&lt;&lt;</span> 8}<br />...
      </p>
      
      <p class="indent">Another variation, which avoids large immediate values, is to use <em>shift right</em> instructions.
      </p>
      
      <p class="indent">The last <code>if</code> statement is simply adding 1 to <code>n</code> if the high-order bit of <code>x</code> is 0, so an alternative, which saves a branch instruction, is:
      </p>
      
      <p class="codelink"><a href="images4.html#p099equ03" id="p099equ03a">Click here to view code image</a></p>
      
      <p class="programlisting1">n = n + 1 - (x &gt;&gt; 31);</p>
      
      <p class="noindent">The “+ 1” in this assignment can be omitted if <code>n</code> is initialized to 1 rather than to 0. These observations lead to the algorithm (12
         to 20 instructions on the basic RISC) shown in <a href="ch05.html#ch05fig11">Figure 5–11</a>. A further improvement is possible for the case in which <code>x</code> begins with a 1-bit: change the first line to
      </p>
      
      <p class="codelink"><a href="images4.html#p099equ04" id="p099equ04a">Click here to view code image</a></p>
      
      <p class="programlisting1">if ((int)x &lt;= 0) return (~x &gt;&gt; 26) &amp; 32;</p>
      
      <p class="codelink"><a href="images4.html#p05fig11" id="p05fig11a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting1"><a id="ch05fig11"></a>int nlz(unsigned x) {<br />   int n;<br /><br />   if (x == 0) return(32);<br />   n = 1;<br />   if ((x &gt;&gt; 16) == 0) {n = n +16; x = x <span class="entity">&lt;&lt;</span>16;}<br />   if ((x &gt;&gt; 24) == 0) {n = n + 8; x = x <span class="entity">&lt;&lt;</span> 8;}<br />   if ((x &gt;&gt; 28) == 0) {n = n + 4; x = x <span class="entity">&lt;&lt;</span> 4;}<br />   if ((x &gt;&gt; 30) == 0) {n = n + 2; x = x <span class="entity">&lt;&lt;</span> 2;}<br />   n = n - (x &gt;&gt; 31);<br />   return n;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–11. <em>Number of leading zeros</em>, binary search.
      </p>
      
      <p class="indent"><a id="page_100"></a><a href="ch05.html#ch05fig12">Figure 5–12</a> illustrates a sort of reversal of the above. It requires fewer operations the more
         leading 0’s there are, and avoids large immediate values and large shift amounts.
         It executes in 12 to 20 instructions on the basic RISC.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig12" id="p05fig12a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig12"></a>int nlz(unsigned x)  {<br />   unsigned y;<br />   int n;<br /><br />   n = 32;<br />   y = x &gt;&gt;16; if (y != 0) {n = n -16; x = y;}<br />   y = x &gt;&gt; 8; if (y != 0) {n = n - 8; x = y;}<br />   y = x &gt;&gt; 4; if (y != 0) {n = n - 4; x = y;}<br />   y = x &gt;&gt; 2; if (y != 0) {n = n - 2; x = y;}<br />   y = x &gt;&gt; 1; if (y != 0) return n - 2;<br />   return n - x;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–12. <em>Number of leading zeros</em>, binary search, counting down.
      </p>
      
      <p class="indent">This algorithm is amenable to a “table assist”: the last four executable lines can
         be replaced by
      </p>
      
      <p class="codelink"><a href="images4.html#p100equ01" id="p100equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">static char table[256] = {0,1,2,2,3,3,3,3,4,4,...,8);<br />return n - table[x];
      </p>
      
      <p class="noindent">Many algorithms can be aided by table lookup, but this will not often be mentioned
         here.
      </p>
      
      <p class="indent">For compactness, this and the preceding algorithms in this section can be coded as
         loops. For example, the algorithm of <a href="ch05.html#ch05fig12">Figure 5–12</a> becomes the algorithm shown in <a href="ch05.html#ch05fig13">Figure 5–13</a>. This executes in 23 to 33 basic RISC instructions, ten of which are conditional
         branches.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig13" id="p05fig13a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting1"><a id="ch05fig13"></a>int nlz(unsigned x) {<br />   unsigned y;<br />   int n, c;<br /><br />   n = 32;<br />   c = 16;<br />   do {<br />      y = x &gt;&gt; c; if (y != 0) {n = n - c; x = y;}<br />      c = c &gt;&gt; 1;<br />   } while (c != 0);<br />   return n - x;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–13. <em>Number of leading zeros</em>, binary search, coded as a loop.
      </p>
      
      <p class="indent"><a id="page_101"></a>One can, of course, simply shift left one place at a time, counting, until the sign
         bit is on; or shift right one place at a time until the word is all 0. These algorithms
         are compact and work well if the number of leading 0’s is expected to be small or
         large, respectively. One can combine the methods, as shown in <a href="ch05.html#ch05fig14">Figure 5–14</a>. We mention this because the technique of merging two algorithms and choosing the
         result of whichever one stops first is more generally applicable. It leads to code
         that runs fast on superscalar machines, because of the proximity of independent instructions.
         (These machines can execute two or more instructions simultaneously, provided they
         are independent.)
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig14" id="p05fig14a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting1"><a id="ch05fig14"></a>int nlz(int x) {<br />   int y, n;<br /><br />   n = 0;<br />   y = x;<br />L: if (x &lt; 0) return n;<br />   if (y == 0) return 32 - n;<br />   n = n + 1;<br />   x = x <span class="entity">&lt;&lt;</span> 1;<br />   y = y &gt;&gt; 1;<br />   goto L;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–14. <em>Number of leading zeros</em>, working both ends at the same time.
      </p>
      
      <p class="indent">On the basic RISC, this executes in min(3 + 6nlz(<strong><em>x</em></strong>), 5 + 6(32 – nlz(<strong><em>x</em></strong>))) instructions, or 99 worst case. One can imagine a superscalar machine executing
         the entire loop body in one cycle if the comparison results are obtained as a by-product
         of the shifts, or in two cycles otherwise, plus the branch overhead.
      </p>
      
      <p class="indent">It is straightforward to convert either of the algorithms of <a href="ch05.html#ch05fig11">Figure 5–11</a> or <a href="ch05.html#ch05fig12">Figure 5–12</a> to a branch-free counterpart. <a href="ch05.html#ch05fig15">Figure 5–15</a> shows a version that does the job in 28 basic RISC instructions.
      </p>
      
      <p class="codelink"><a id="page_102"></a><a href="images4.html#p05fig15" id="p05fig15a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig15"></a>int nlz(unsigned x) {<br />   int y, m, n;<br /><br />   y = -(x &gt;&gt; 16);      // If left half of x is 0,<br />   m = (y &gt;&gt; 16) &amp; 16;  // set n = 16. If left half<br />   n = 16 - m;          // is nonzero, set n = 0 and<br />   x = x &gt;&gt; m;          // shift x right 16.<br />                        // Now x is of the form 0000xxxx.<br />   y = x - 0x100;       // If positions 8–15 are 0,<br />   m = (y &gt;&gt; 16) &amp; 8;   // add 8 to n and shift x left 8.<br />   n = n + m;<br />   x = x <span class="entity">&lt;&lt;</span> m;<br /><br />   y = x - 0x1000;      // If positions 12–15 are 0,<br />   m = (y &gt;&gt; 16) &amp; 4;   // add 4 to n and shift x left 4.<br />   n = n + m;<br />   x = x <span class="entity">&lt;&lt;</span> m;<br /><br />   y = x - 0x4000;      // If positions 14–15 are 0,<br />   m = (y &gt;&gt; 16) &amp; 2;   // add 2 to n and shift x left 2.<br />   n = n + m;<br />   x = x <span class="entity">&lt;&lt;</span> m;<br /><br />   y = x &gt;&gt; 14;         // Set y = 0, 1, 2, or 3.<br />   m = y &amp; ~(y &gt;&gt; 1);   // Set m = 0, 1, 2, or 2 resp.<br />   return n + 2 - m;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–15. <em>Number of leading zeros</em>, branch-free binary search.
      </p>
      
      <p class="indent">If your machine has the <em>population count</em> instruction, a good way to compute the <em>number of leading zeros</em> function is given in <a href="ch05.html#ch05fig16">Figure 5–16</a>. The five assignments to <code>x</code> can be reversed, or, in fact, done in any order. This is branch-free and takes 11
         instructions. Even if <em>population count</em> is not available, this algorithm may be useful. Using the 21-instruction code for
         counting 1-bits given in <a href="ch05.html#ch05fig2">Figure 5–2</a> on page <a href="ch05.html#page_82">82</a>, it executes in 32 branch-free basic RISC instructions.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig16" id="p05fig16a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig16"></a>int nlz(unsigned x) {<br />   int pop(unsigned x);<br /><br />   x = x | (x &gt;&gt; 1);<br />   x = x | (x &gt;&gt; 2);<br />   x = x | (x &gt;&gt; 4);<br />   x = x | (x &gt;&gt; 8);<br />   x = x | (x &gt;&gt;16);<br />   return pop(~x);<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–16. <em>Number of leading zeros</em>, right-propagate and count 1-bits.
      </p>
      
      <p class="indent">Robert Harley [Harley] devised an algorithm for nlz(<strong><em>x</em></strong>) that is very similar to Seal’s algorithm for ntz(<strong><em>x</em></strong>) (see <a href="ch05.html#ch05fig25">Figure 5–25</a> on page <a href="ch05.html#page_111">111</a>). Harley’s method propagates the most significant 1-bit to the right using <em>shift</em>’s and <em>or</em>’s, and multiplies modulo 2<sup>32</sup> by a special constant, producing a product whose high-order six bits uniquely identify
         the number of leading 0’s in <strong><em>x</em></strong>. It then does a <em>shift right</em> and a table lookup (indexed load) to translate the six-bit identifier to the actual
         number of leading 0’s. As shown in <a href="ch05.html#ch05fig17">Figure 5–17</a>, it consists of 14 instructions, including a <em>multiply</em>, plus an indexed load. Table entries shown as <code>u</code> are unused.
      </p>
      
      <p class="codelink"><a id="page_103"></a><a href="images4.html#p05fig17" id="p05fig17a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting1"><a id="ch05fig17"></a>int nlz(unsigned x) {<br /><br />   static char table[64] =<br />     {32,31, u,16, u,30, 3, u,  15, u, u, u,29,10, 2, u,<br />       u, u,12,14,21, u,19, u,   u,28, u,25, u, 9, 1, u,<br />      17, u, 4, u, u, u,11, u,  13,22,20, u,26, u, u,18,<br />       5, u, u,23, u,27, u, 6,   u,24, 7, u, 8, u, 0, u};<br /><br />   x = x | (x &gt;&gt; 1);     // Propagate leftmost<br />   x = x | (x &gt;&gt; 2);     // 1-bit to the right.<br />   x = x | (x &gt;&gt; 4);<br />   x = x | (x &gt;&gt; 8);<br />   x = x | (x &gt;&gt;16);<br />   x = x*0x06EB14F9;     // Multiplier is 7*255**3.<br />   return table[x &gt;&gt; 26];<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–17. <em>Number of leading zeros</em>, Harley’s algorithm.
      </p>
      
      <p class="indent">The multiplier is 7·255<sup>3</sup>, so the multiplication can be done as shown below. In this form, the function consists
         of 19 elementary instructions, plus an indexed load.
      </p>
      
      <p class="codelink"><a href="images4.html#p103equ01" id="p103equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = (x <span class="entity">&lt;&lt;</span> 3) - x;     // Multiply by 7.<br />x = (x <span class="entity">&lt;&lt;</span> 8) - x;     // Multiply by 255.<br />x = (x <span class="entity">&lt;&lt;</span> 8) - x;     // Again.<br />x = (x <span class="entity">&lt;&lt;</span> 8) - x;     // Again.
      </p>
      
      <p class="indent">There are many multipliers that have the desired uniqueness property and whose factors
         are all of the form 2<sup><em>k</em></sup> ± 1. The smallest is 0x045BCED1 = 17 · 65· 129 ·513. There are no such multipliers
         consisting of three factors if the table size is 64 or 128 entries. If the table size
         is 256 entries, however, there are a number of such multipliers. The smallest is 0x01033CBF
         = 65·255·1025 (using this would save two instructions at the expense of a larger table).
      </p>
      
      <p class="indent">Julius Goryavsky [Gor] has found several variations of Harley’s algorithm that reduce
         the table size at the expense of a few instructions, or have improved parallelism,
         or have other desirable properties. One, shown in <a href="ch05.html#ch05fig18">Figure 5–18</a>, is a clear winner if the multiplication is done with shifts and adds. The code changes
         only the table and the lines that contain the <em>shift right</em> of 16 and the following <em>multiply</em> in <a href="ch05.html#ch05fig17">Figure 5–17</a>. If the machine has <em>and not</em>, this saves two instructions because the multiplier can be factored as 511·2047 ·
         16383 (mod 2<sup>32</sup>), which can be done in six elementary instructions rather than eight. If the machine
         does not have <em>and not</em>, it saves one instruction.
      </p>
      
      <p class="codelink"><a id="page_104"></a><a href="images4.html#p05fig18" id="p05fig18a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig18"></a>...<br />static char table[64] =<br />  {32,20,19, u, u,18, u, 7,  10,17, u, u,14, u, 6, u,<br />    u, 9, u,16, u, u, 1,26,   u,13, u, u,24, 5, u, u,<br />    u,21, u, 8,11, u,15, u,   u, u, u, 2,27, 0,25, u,<br />   22, u,12, u, u, 3,28, u,  23, u, 4,29, u, u,30,31};<br />...<br />x = x &amp; ~(x &gt;&gt; 16);<br />x = x*0xFD7049FF;<br />...
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–18. <em>Number of leading zeros</em>, Goryavsky’s variation of Harley’s algorithm.
      </p>
      
      <h4><strong>Floating-Point Methods</strong></h4>
      
      <p class="noindent">The floating-point post-normalization facilities can be used to count leading zeros.
         It works out quite well with IEEE-format floating-point numbers. The idea is to convert
         the given unsigned integer to double-precision floating-point, extract the exponent,
         and subtract it from a constant. <a href="ch05.html#ch05fig19">Figure 5–19</a> illustrates a complete procedure for this.
      </p>
      
      <p class="codelink"><a id="ch05fig19"></a><a href="images4.html#p05fig19" id="p05fig19a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting">int nlz(unsigned k) {<br />   union {<br />      unsigned asInt[2];<br />      doubleasDouble;<br />   };<br />   int n;<br /><br />   asDouble = (double)k + 0.5;<br />   n = 1054 - (as!nt[LE] &gt;&gt; 20);<br />   return n;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–19. <em>Number of leading zeros</em>, using IEEE floating-point.
      </p>
      
      <p class="indent">The code uses the C++ “anonymous union” to overlay an integer with a double-precision
         floating-point quantity. Variable <code>LE</code> must be 1 for execution on a little-endian machine, and 0 for big-endian. The addition
         of 0.5, or some other small number, is necessary for the method to work when <code>k =</code> 0.
      </p>
      
      <p class="indent">We will not attempt to assess the execution time of this code, because machines differ
         so much in their floating-point capabilities. For example, many machines have their
         floating-point registers separate from the integer registers, and on such machines
         data transfers through memory may be required to convert an integer to floating-point
         and then move the result to an integer register.
      </p>
      
      <p class="indent">The code of <a href="ch05.html#ch05fig19">Figure 5–19</a> is not valid C or C++ according to the ANSI standard, because it refers to the same
         memory locations as two different types. Thus, one cannot be sure it will work on
         a particular machine and compiler. It does work with IBM’s XLC compiler on AIX, and
         with the GCC compiler on AIX and on <a id="page_105"></a>Windows 2000 and XP, at all optimization levels (as of this writing, anyway). If the
         code is altered to do the overlay defining with something like
      </p>
      
      <p class="codelink"><a href="images4.html#p105equ01" id="p105equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">xx = (double)k + 0.5;<br />n = 1054 - (*((unsigned *)&amp;xx + LE) &gt;&gt; 20);
      </p>
      
      <p class="noindent">it does <em>not</em> work on these systems with optimization turned on. This code, incidentally, violates
         a second ANSI standard, namely, that pointer arithmetic can be performed only on pointers
         to array elements [Cohen]. The failure, however, is due to the first violation, involving
         overlay defining.
      </p>
      
      <p class="indent">In spite of the flakiness of this code,<sup><a id="ch05fna2"></a><a href="footnotes.html#ch05fn2">2</a></sup> three variations are given below.
      </p>
      
      <p class="codelink"><a href="images4.html#p105equ02" id="p105equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">asDouble = (double)k;<br />n = 1054 - (asInt[LE] &gt;&gt; 20);<br />n = (n &amp; 31) + (n &gt;&gt; 9);<br /><br />k = k &amp; ~(k &gt;&gt; 1);<br />asFloat = (float)k + 0.5f;<br />n = 158 - (asInt &gt;&gt; 23);<br /><br />k = k &amp; ~(k &gt;&gt; 1);<br />asFloat = (float)k;<br />n = 158 - (asInt &gt;&gt; 23);<br />n = (n &amp; 31) + (n &gt;&gt; 6);
      </p>
      
      <p class="indent">In the first variation, the problem with <code>k = 0</code> is fixed not by a floating-point addition of 0.5, but by integer arithmetic on the
         result <code>n</code> (which would be 1054, or 0x41E, if the correction were not done).
      </p>
      
      <p class="indent">The next two variations use single-precision floating-point, with the “anonymous union”
         changed in an obvious way. Here there is a new problem: Rounding can throw off the
         result when the rounding mode is either round to nearest (almost universally used)
         or round toward +∞. For round to nearest mode, the rounding problem occurs for <code>k</code> in the ranges hexadecimal FFFFFF80 to FFFFFFFF, 7FFFFFC0 to 7FFFFFFF, 3FFFFFE0 to
         3FFFFFFF, and so on. In rounding, an add of 1 carries all the way to the left, changing
         the position of the most significant 1-bit. The correction steps used above clear
         the bit to the right of the most significant 1-bit, blocking the carry. If <code>k</code> is a 64-bit quantity, this correction is also needed for the code of <a href="ch05.html#ch05fig19">Figure 5–19</a> and for the first of the three variations given above.
      </p>
      
      <p class="indent">The GNU C/C++ compiler has a unique feature that allows coding any of these schemes
         as a macro, giving in-line code for the function references [Stall]. This feature
         allows statements, including declarations, to be inserted in code where an expression
         is called for. The sequence of statements would usually end <a id="page_106"></a>with an expression, which is taken to be the value of the construction. Such a macro
         definition is shown below, for the first single-precision variation. (In C, it is
         customary to use uppercase for macro names.)
      </p>
      
      <p class="codelink"><a href="images4.html#p106equ01" id="p106equ01a">Click here to view code image</a></p>
      
      <p class="programlisting">#define NLZ(kp) \<br />   ({union {unsigned _asInt; float _asFloat;}; \<br />     unsigned _k = (kp), _kk = _k &amp; ~(_k &gt;&gt; 1); \<br />     _asFloat = (float)_kk + 0.5f; \<br />     158 - (_asInt &gt;&gt; 23);})
      </p>
      
      <p class="noindent">The underscores are used to avoid name conflicts with parameter <code>kp;</code> presumably, user-defined names do not begin with underscores.
      </p>
      
      <h4><strong>Comparing the Number of Leading Zeros of Two Words</strong></h4>
      
      <p class="noindent">There is a simple way to determine which of two words <strong><em>x</em></strong> and <strong><em>y</em></strong> has the larger number of leading zeros [Knu5] without actually computing nlz(<strong><em>x</em></strong>) or nlz(<strong><em>y</em></strong>). The methods are shown in the equivalences below. The three relations not shown
         are, of course, obtained by complementing the sense of the comparison on the right.
      </p>
      
      <div class="image"><img alt="Image" src="graphics/106equ02.jpg" /></div>
      
      <h4><strong>Relation to the Log Function</strong></h4>
      
      <p class="noindent">The “nlz” function is, essentially, the “integer log base 2” function. For unsigned
         <strong><em>x</em></strong> ≠ <strong>0</strong>,
      </p>
      
      <div class="image"><img alt="Image" src="graphics/106equ03.jpg" /></div>
      
      <p class="noindent">See also <a href="ch11.html#ch11lev4">Section 11–4</a>, “<a href="ch11.html#ch11lev4">Integer Logarithm</a>,” on page <a href="ch11.html#page_291">291</a>.
      </p>
      
      <p class="indent">Another closely related function is <em>bitsize</em>, the number of bits required to represent its argument as a signed quantity in two’s-complement
         form. We take its definition to be
      </p>
      
      <div class="image"><img alt="Image" src="graphics/106equ04.jpg" /></div>
      
      <p class="indent"><a id="page_107"></a>From this definition, bitsize(<em>x</em>) = bitsize(−<em>x</em>−1). But − <strong><em>x</em></strong> − <strong>1</strong> = ¬<strong><em>x</em></strong>, so an algorithm for bitsize is (where the shift is signed)
      </p>
      
      <p class="codelink"><a href="images4.html#p107equ01" id="p107equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = x ^ (x &gt;&gt; 31);        // If (x &lt; 0) x = -x - 1;<br />return 33 - nlz(x);
      </p>
      
      <p class="indent">An alternative, which is the same function as bitsize(<em>x</em>) except it gives the result 0 for <em>x</em> = 0, is
      </p>
      
      <p class="codelink"><a href="images4.html#p107equ02" id="p107equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">32 - nlz(x ^ (x <span class="entity">&lt;&lt;</span> 1))
      </p>
      
      <h4><strong>Applications</strong></h4>
      
      <p class="noindent">Two important applications of the <em>number of leading zeros</em> function are in simulating floating-point arithmetic operations and in various division
         algorithms (see <a href="ch09.html#ch09fig1">Figure 9–1</a> on page <a href="ch09.html#page_185">185</a> and <a href="ch09.html#ch09fig3">Figure 9–3</a> on page <a href="ch09.html#page_196">196</a>). The instruction seems to have a miscellany of other uses.
      </p>
      
      <p class="indent">It can be used to get the “<strong><em>x</em></strong> = <strong><em>y</em></strong>” predicate in only three instructions (see “<a href="ch02.html#ch02lev12">Comparison Predicates</a>” on page <a href="ch02.html#ch02lev12">23</a>), and as an aid in computing certain elementary functions (see pages <a href="ch11.html#page_281">281</a>, <a href="ch11.html#page_284">284</a>, <a href="ch11.html#page_290">290</a>, and <a href="ch11.html#page_294">294</a>).
      </p>
      
      <p class="indent">A novel application is to generate exponentially distributed random integers by generating
         uniformly distributed random integers and taking nlz of the result [GLS1]. The result
         is 0 with probability 1/2, 1 with probability 1/4, 2 with probability 1/8, and so
         on. Another application is as an aid in searching a word for a consecutive string
         of 1-bits (or 0-bits) of a certain length, a process that is used in some disk block
         allocation algorithms. For these last two applications, the <em>number of trailing zeros</em> function could also be used.
      </p>
      
      <h3><a id="ch05lev4"></a><strong>5–4 Counting Trailing 0’s</strong></h3>
      
      <p class="noindent">If the <em>number of leading zeros</em> instruction is available, then the best way to count trailing 0’s is, most likely,
         to convert it to a count <em>leading</em> 0’s problem:
      </p>
      
      <p class="center"><strong>32</strong> − nlz(¬<strong><em>x</em></strong>&amp;(<strong><em>x</em></strong>−<strong>1</strong>)).
      </p>
      
      <p class="indent">If <em>population count</em> is available, a slightly better method is to form a mask that identifies the trailing
         0’s, and count the 1-bits in it [Hay2], such as
      </p>
      
      <div class="image"><img alt="Image" src="graphics/107equ04.jpg" /></div>
      
      <p class="indent">Variations exist using other expressions for forming a mask that identifies the trailing
         zeros of <strong><em>x</em></strong>, such as those given in <a href="ch02.html#ch02lev1">Section 2–1</a>, “<a href="ch02.html#ch02lev1">Manipulating Rightmost Bits</a>,” on page <a href="ch02.html#page_11">11</a>. These methods are also reasonable even if the machine has none of the bit-counting
         instructions. Using the algorithm for pop(<strong><em>x</em></strong>) given in <a href="ch05.html#ch05fig2">Figure 5–2</a> on page <a href="ch05.html#page_82">82</a>, the first expression above executes in about 3 + 21 = 24 instructions (branch-free).
      </p>
      
      <p class="indent"><a href="ch05.html#ch05fig20">Figure 5–20</a> shows an algorithm that does it directly, in 12 to 20 basic RISC instructions (for
         <em>x</em> ≠ 0).
      </p>
      
      <p class="codelink"><a id="page_108"></a><a href="images4.html#p05fig20" id="p05fig20a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig20"></a>int ntz(unsigned x) {<br />   int n;<br /><br />   if (x == 0) return(32);<br />   n = 1;<br />   if ((x &amp; 0x0000FFFF) == 0) {n = n + 16; x = x &gt;&gt;16;}<br />   if ((x &amp; 0x000000FF) == 0) {n = n +  8; x = x &gt;&gt; 8;}<br />   if ((x &amp; 0x0000000F) == 0) {n = n +  4; x = x &gt;&gt; 4;}<br />   if ((x &amp; 0x00000003) == 0) {n = n +  2; x = x &gt;&gt; 2;}<br />   return n - (x &amp; 1);<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–20. <em>Number of trailing zeros</em>, binary search.
      </p>
      
      <p class="indent">The <code>n + 16</code> can be simplified to <code>17</code> if that helps, and if the compiler is not smart enough to do that for you (this does
         not affect the number of instructions as we are counting them).
      </p>
      
      <p class="indent"><a href="ch05.html#ch05fig21">Figure 5–21</a> shows a variation that uses smaller immediate values and simpler operations. It executes
         in 12 to 21 basic RISC instructions. Unlike the above procedure, when the number of
         trailing 0’s is small, the procedure of <a href="ch05.html#ch05fig21">Figure 5–21</a> executes a larger number of instructions, but also a larger number of “fall-through”
         branches.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig21" id="p05fig21a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig21"></a>int ntz(unsigned x) {<br />   unsigned y;<br />   int n;<br /><br />   if (x == 0) return 32;<br />   n = 31;<br />   y = x <span class="entity">&lt;&lt;</span>16;  if (y != 0) {n = n -16; x = y;}<br />   y = x <span class="entity">&lt;&lt;</span> 8;  if (y != 0) {n = n - 8; x = y;}<br />   y = x <span class="entity">&lt;&lt;</span> 4;  if (y != 0) {n = n - 4; x = y;}<br />   y = x <span class="entity">&lt;&lt;</span> 2;  if (y != 0) {n = n - 2; x = y;}<br />   y = x <span class="entity">&lt;&lt;</span> 1;  if (y != 0) {n = n - 1;}<br />   return n;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–21. <em>Number of trailing zeros</em>, smaller immediate values.
      </p>
      
      <p class="indent">The line just above the <code>return</code> statement can alternatively be coded
      </p>
      
      <p class="codelink"><a href="images4.html#p108pro01" id="p108pro01a">Click here to view code image</a></p>
      
      <p class="programlisting1">n = n - ((x <span class="entity">&lt;&lt;</span> 1) &gt;&gt; 31);
      </p>
      
      <p class="noindent">which saves a branch, but not an instruction.</p>
      
      <p class="indent"><a id="page_109"></a>In terms of number of instructions executed, it is hard to beat the “search tree”
         [Aus2]. <a href="ch05.html#ch05fig22">Figure 5–22</a> illustrates this procedure for an 8-bit argument. This procedure executes in seven
         instructions for all paths except the last two (return 7 or 8), which require nine.
         A 32-bit version would execute in 11 to 13 instructions. Unfortunately, for large
         word sizes, the program is quite large. The 8-bit version above is 12 lines of executable
         source code and would compile into about 41 instructions. A 32-bit version would be
         48 lines and about 164 instructions, and a 64-bit version would be twice that.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig22" id="p05fig22a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig22"></a>int ntz(char x) {<br />   if (x &amp; 15) {<br />      if (x &amp; 3) {<br />         if (x &amp; 1) return 0;<br />         else return 1;<br />      }<br />      else if (x &amp; 4) return 2;<br />      else return 3;<br />   }<br />   else if (x &amp; 0x30) {<br />      if (x &amp; 0x10) return 4;<br />      else return 5;<br />   }<br />   else if (x &amp; 0x40) return 6;<br />   else if (x) return 7;<br />   else return 8;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–22. <em>Number of trailing zeros</em>, binary search tree.
      </p>
      
      <p class="indent">If the number of trailing 0’s is expected to be small or large, then the simple loops
         shown in <a href="ch05.html#ch05fig23">Figure 5–23</a> are quite fast. The algorithm on the left executes in 5 + 3ntz(<strong><em>x</em></strong>), and that on the right in 3 + 3(32 – ntz(<strong><em>x</em></strong>)) basic RISC instructions.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig23" id="p05fig23a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig23"></a>int ntz(unsigned x) {<br />   int n;<br /><br />   x = ~x &amp; (x - 1);<br />   n = 0;                        // n = 32;<br />   while (x != 0) {              // while (x != 0) {<br />      n = n + 1;                 //    n = n - 1;<br />      x = x &gt;&gt; 1;                //    x = x + x;<br />   }                             // }<br />   return n;                     // return n;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–23. <em>Number of trailing zeros</em>, simple counting loops.
      </p>
      
      <p class="indent"><a id="page_110"></a>Dean Gaudet [Gaud] devised an algorithm that is interesting because with the right
         instructions it is branch-free, load-free (does not use table lookup), and has lots
         of parallelism. It is shown in <a href="ch05.html#ch05fig24">Figure 5–24</a>.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig24" id="p05fig24a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig24"></a>int ntz(unsigned x) {<br />   unsigned y, bz, b4, b3, b2, b1, b0;<br /><br />   y = x &amp; -x;               // Isolate rightmost 1-bit.<br />   bz = y ? 0 : 1;           // 1 if y = 0.<br />   b4 = (y &amp; 0x0000FFFF) ? 0 : 16;<br />   b3 = (y &amp; 0x00FF00FF) ? 0 :  8;<br />   b2 = (y &amp; 0x0F0F0F0F) ? 0 :  4;<br />   b1 = (y &amp; 0x33333333) ? 0 :  2;<br />   b0 = (y &amp; 0x55555555) ? 0 :  1;<br />   return bz + b4 + b3 + b2 + bl +b0;<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–24. <em>Number of trailing zeros</em>, Gaudet’s algorithm.
      </p>
      
      <p class="noindent">As shown, the code uses the C “conditional expression” in six places. This construct
         has the form <code>a?b:c</code>. Its value is <code>b</code> if <code>a</code> is <strong>true</strong> (nonzero), and <code>c</code> if <code>a</code> is <strong>false</strong> (zero). Although a conditional expression must, in general, be compiled into compares
         and branches, for the simple cases in <a href="ch05.html#ch05fig24">Figure 5–24</a> branching can be avoided if the machine has a <em>compare for equality to zero</em> instruction that sets a target register to 1 if the operand is 0, and to 0 if the
         operand is nonzero. Branching can also be avoided by using <em>conditional move</em> instructions. Using <em>compare</em>, the assignment to <code>b3</code> can be compiled into five instructions on the basic RISC: two to generate the hex
         constant, an <em>and</em>, the <em>compare</em>, and a <em>shift left</em> of 3. (The first, second, and last conditional expressions require one, three, and
         four instructions, respectively.)
      </p>
      
      <p class="indent">The code can be compiled into a total of 30 instructions. All six lines with the conditional
         expressions can run in parallel. On a machine with a sufficient degree of parallelism,
         it executes in ten cycles. Present machines don’t have that much parallelism, so as
         a practical matter it might help to change the first two uses of <code>y</code> in the program to <code>x</code>. This permits the first three executable statements to run in parallel.
      </p>
      
      <p class="indent">David Seal [Seal2] devised an algorithm for computing ntz(<strong><em>x</em></strong>) that is based on the idea of compressing the 2<sup>32</sup> possible values of <strong><em>x</em></strong> to a small dense set of integers and doing a table lookup. He uses the expression
         <strong><em>x</em></strong> &amp; – <strong><em>x</em></strong> to reduce the number of possible values to a small number. The value of this expression
         is a word that contains a single 1-bit at the position of the least significant 1-bit
         in <strong><em>x</em></strong>, or is 0 if <strong><em>x</em></strong> = 0. Thus, <strong><em>x</em></strong> &amp; – <strong><em>x</em></strong> has only 33 possible values. But they are not dense; they range from 0 to 2<sup>31</sup>.
      </p>
      
      <p class="indent">To produce a dense set of 33 integers that uniquely identify the 33 values of <strong><em>x</em></strong> &amp; –<strong><em>x</em></strong>, Seal found a certain constant which, when multiplied by <strong><em>x</em></strong> &amp; –<strong><em>x</em></strong>, produces the identifying value in the high-order six bits of the low-order half
         of the product of the constant and <strong><em>x</em></strong> &amp; –<strong><em>x</em></strong>. Since <strong><em>x</em></strong> &amp; – <strong><em>x</em></strong> is an integral power of 2 or is 0, <a id="page_111"></a>the multiplication amounts to a left shift of the constant, or it is a multiplication
         by 0. Using only the high-order five bits is not sufficient, because 33 distinct values
         are needed.
      </p>
      
      <p class="indent">The code is shown in <a href="ch05.html#ch05fig25">Figure 5–25</a>, where table entries shown as <code>u</code> are unused.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig25" id="p05fig25a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig25"></a>int ntz(unsigned x) {<br /><br />   static char table[64] =<br />     {32, 0, 1,12, 2, 6, u,13,   3, u, 7, u, u, u, u,14,<br />      10, 4, u, u, 8, u, u,25,   u, u, u, u, u,21,27,15,<br />      31,11, 5, u, u, u, u, u,   9, u, u,24, u, u,20,26,<br />      30, u, u, u, u,23, u,19,  29, u,22,18,28,17,16, u};<br /><br />   x = (x &amp; -x)*0x0450FBAF;<br />   return table[x &gt;&gt; 26];<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–25. <em>Number of trailing zeros</em>, Seal’s algorithm.
      </p>
      
      <p class="indent">As an example, if <code>x</code> is an odd multiple of 16, then <code>x &amp; -x</code> = 16, so the multiplication is simply a left shift of four positions. The high-order
         six bits of the low-order half of the product are then binary 010001, or 17 decimal.
         The table translates 17 to 4, which is the correct number of trailing 0’s for an odd
         multiple of 16.
      </p>
      
      <p class="indent">There are thousands of constants that have the necessary uniqueness property. The
         smallest is 0x0431472F, and the largest is 0xFDE75C6D. Seal chose a constant for which
         the multiplication can be done with a small number of shifts and adds. Since 0x0450FBAF
         = 17–65-65535, the multiplication can be done as follows:
      </p>
      
      <p class="codelink"><a href="images4.html#p111equ01" id="p111equ01a">Click here to view code image</a></p>
      
      <p class="programlisting1">x = (x <span class="entity">&lt;&lt;</span> 4) + x;        // x = x*17. <br />x = (x <span class="entity">&lt;&lt;</span> 6) + x;        // x = x*65.<br />x = (x <span class="entity">&lt;&lt;</span> 16) - x;       // x = x*65535.
      </p>
      
      <p class="noindent">With this substitution, the code of <a href="ch05.html#ch05fig25">Figure 5–25</a> consists of nine elementary instructions, plus an indexed <em>load</em>. Seal was interested in the ARM instruction set, which can do a <em>shift</em> and <em>add</em> in one instruction. On that architecture, the code is six instructions, including
         the indexed load.
      </p>
      
      <p class="indent">To make the multiplication even easier to do with shifts and adds, one might hope
         to find a constant of the form (2<sup><em>k</em><sub>1</sub></sup> ± 1)(2<sup><em>k</em><sub>2</sub></sup> ± 1) that has the necessary uniqueness property. For a table size of 64, there are
         no such integers, and there is only one other suitable integer that is a product of
         three such factors: 0x08A1FBAF = 17 · 65 · 131071. Using a table size of 128 or 256
         does not help. However, for a table size of 512 there are four suitable integers of
         the form (2<sup><em>k</em><sub>1</sub></sup> ± 1)(2<sup><em>k</em><sub>2</sub></sup> ± 1); the smallest is 0x0080FF7F = 129 · 65535. We leave it to the reader to determine
         the table associated with this constant.
      </p>
      
      <p class="indent">There is a variation of Seal’s method that is based on de Bruijn cycles [LPR]. These
         are cyclic sequences over a given alphabet that contain as a subsequence every sequence
         of the letters of the alphabet of a given length exactly once. For example, a cycle
         that contains as a subsequence every sequence of {<em>a, b, c</em>} of <a id="page_112"></a>length 2 is <em>aabacbbcc</em>. Notice that the sequence <em>ca</em> wraps around from the end to the beginning. If the alphabet size is <em>k</em> and the length is <em>n</em>, there are <em>k<sup>n</sup></em> sequences. For a cycle to contain all of these, it must be of length at least <em>k</em><em><sup>n</sup></em>, which would be its length if a different sequence started at each position. It can
         be shown that there is always a cycle of this minimum possible length that contains
         all <em>k<sup>n</sup></em> sequences.
      </p>
      
      <p class="indent">For our purposes, the alphabet is {0, 1}, and for dealing with 32-bit words, we are
         interested in a cycle that contains all 32 sequences 00000, 00001, 00010, ..., 11111.
         Given such a cycle that begins with at least four 0’s, we can compute ntz(<em>x</em>) by first reducing <em>x</em> to a word that contains a single bit at the position of the least significant bit
         of <em>x</em>, as in Seal’s algorithm. Then, by multiplication, we can select a 5-bit field of
         the de Bruijn cycle, which will be a unique value for each multiplier. This can be
         mapped to give the number of trailing 0’s by a table lookup. The algorithm follows.
         The de Bruijn cycle used is
      </p>
      
      <p class="codelink"><a href="images4.html#p112equ01" id="p112equ01a">Click here to view code image</a></p>
      
      <p class="programlisting3">0000 0100 1101 0111 0110 0101 0001 1111.</p>
      
      <p class="noindent">It is in effect a cycle, because in use it has trailing 0’s beyond the 32 bits shown
         above, which is effectively the same as wrapping to the beginning.
      </p>
      
      <p class="indent">There are 33 possible values of ntz(<em>x</em>) and only 32 five-bit subsequences in the de Bruijn cycle. Therefore, two words with
         different values of ntz(<em>x</em>) must map to the same number by the table lookup. The words that conflict are zero
         and words that end with a 1-bit. To resolve this, the code has a test for 0 and returns
         32 in that case. A branch-free way to resolve it, useful if your computer has predicate
         comparison instructions, is to change the last statement to
      </p>
      
      <p class="codelink"><a href="images4.html#p112equ02" id="p112equ02a">Click here to view code image</a></p>
      
      <p class="programlisting1">return table[x &gt;&gt; 27] + 32*(x == 0);</p>
      
      <p class="indent">To compare the two algorithms, Seal’s does not require the test for zero and it allows
         the alternative of doing the multiplication with six elementary instructions. The
         de Bruijn algorithm uses a smaller table. The de Bruijn cycle used in <a href="ch05.html#ch05fig26">Figure 5–26</a>, discovered by Danny Dubé [Dubé], is a good one because multiplication by it can
         be done with eight elementary instructions. The constant is 0x04D7651F = (2047 · 5
         · 256 + 1) · 31, from which one can see the shifts, adds, and subtracts that do the
         job.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig26" id="p05fig26a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig26"></a>int ntz(unsigned x) {<br /><br />   static char table[32] =<br />     { 0, 1, 2,24, 3,19, 6,25,   22, 4,20,10,16, 7,12,26,<br />      31,23,18, 5,21, 9,15,11,   30,17, 8,14,29,13,28,27};<br /><br />   if (x == 0) return 32;<br />   x = (x &amp; -x)*0x04D7651F;<br />   return table[x &gt;&gt; 27];<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–26. <em>Number of trailing zeros</em> using a de Bruijn cycle.
      </p>
      
      <p class="indent">John Reiser [Reiser] observed that there is another way to map the 33 values of the
         factor <code>x &amp; -x</code> in Seal’s algorithm to a dense set of unique integers: divide and use the remainder.
         The smallest divisor that has the necessary uniqueness property is 37. The resulting
         code is shown in <a href="ch05.html#ch05fig27">Figure 5–27</a>, where table entries shown as <code>u</code> are unused.
      </p>
      
      <p class="codelink"><a id="page_113"></a><a href="images4.html#p05fig27" id="p05fig27a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig27"></a>int ntz(unsigned x) {<br /><br />   static char table[37] = {32, 0, 1, 26, 2, 23, 27,<br />                 u, 3, 16, 24, 30, 28, 11, u, 13, 4,<br />                 7, 17, u, 25, 22, 31, 15, 29, 10, 12,<br />                 6, u, 21, 14, 9, 5, 20, 8, 19, 18};<br /><br />   x = (x &amp; -x)%37;<br />   return table[x];<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–27. <em>Number of trailing zeros</em>, Reiser’s algorithm.
      </p>
      
      <p class="indent">It is interesting to note that if the numbers <em>x</em> are uniformly distributed, then the average number of trailing 0’s is, very nearly,
         1.0. To see this, sum the products <em>p<sub>i</sub>n<sub>i</sub></em>, where <em>p<sub>i</sub></em> is the probability that there are exactly <em>n<sub>i</sub></em> trailing 0’s. That is,
      </p>
      
      <div class="image"><img alt="Image" src="graphics/113equ01.jpg" /></div>
      
      <p class="indent">To evaluate this sum, consider the following array:</p>
      
      <div class="image"><img alt="Image" src="graphics/113equ02.jpg" /></div>
      
      <p class="noindent">The sum of each column is a term of the series for <em>S</em>. Hence <em>S</em> is the sum of all the numbers in the array. The sum of the rows are
      </p>
      
      <p class="indenthangingNP1">1/4 + 1/8 + 1/16 + 1/32+ ... = 1/2<br />1/8 + 1/16 + 1/32 + 1/64+ ... = 1/4<br />1/16 + 1/32 + 1/64 + 1/128 + ... = 1/8<br />...
      </p>
      
      <p class="noindent"><a id="page_114"></a>and the sum of these is 1/2 + 1/4 + 1/8 + ... = 1. The absolute convergence of the
         original series justifies the rearrangement.
      </p>
      
      <p class="indent">Sometimes, a function similar to ntz(<strong><em>x</em></strong>) is wanted, but a 0 argument is a special case, perhaps an error, that should be
         identified with a value of the function that’s easily distinguished from the “normal”
         values of the function. For example, let us define “the number of factors of 2 in
         <strong><em>x</em></strong>” to be
      </p>
      
      <div class="image"><img alt="Image" src="graphics/114equ01.jpg" /></div>
      
      <p class="noindent">This can be calculated from</p>
      
      <p class="center"><strong>31</strong> − nlz(<strong><em>x</em></strong> &amp; − <strong><em>x</em></strong>).
      </p>
      
      <h4><strong>Applications</strong></h4>
      
      <p class="noindent">[GLS1] points out some interesting applications of the <em>number of trailing zeros</em> function. It has been called the “ruler function” because it gives the height of
         a tick mark on a ruler that’s divided into halves, quarters, eighths, and so on.
      </p>
      
      <p class="indent">It has an application in R. W. Gosper’s loop-detection algorithm, which will now be
         described in some detail, because it is quite elegant and it does more than might
         at first seem possible.
      </p>
      
      <p class="indent">Suppose a sequence <em>X</em><sub>0</sub>,<em>X</em><sub>1</sub>,<em>X</em><sub>2</sub>, ... is defined by <em>X</em><sub><em>n</em> + 1</sub> = <em>f</em>(<em>X<sub>n</sub></em>). If the range of <em>f</em> is finite, the sequence is necessarily periodic. That is, it consists of a leader
         <em>X</em><sub>0</sub>, <em>X</em><sub>1</sub>,..., <em>X</em><sub><em>μ</em>–1</sub> followed by a cycle <em>X</em><sub><em>μ</em></sub>, <em>X</em><sub><em>u</em>+1</sub>,..., <em>X</em><sub><em>μ</em>+<em>λ</em>−1</sub> that repeats without limit (<em>X</em><sub><em>μ</em></sub> = <em>X</em><sub><em>μ</em>+<em>λ</em></sub>, <em>X</em><sub><em>μ</em>+ 1</sub> = <em>X</em><sub><em>μ</em> + <em>λ</em> + 1</sub>, and so on, where λ is the period of the cycle). Given the function <em>f</em>, the loop-detection problem is to find the index <em>μ</em> of the first element that repeats, and the period λ. Loop detection has applications
         in testing random number generators and detecting a cycle in a linked list.
      </p>
      
      <p class="indent">One could save all the values of the sequence as they are produced and compare each
         new element with all the preceding ones. This would immediately show where the second
         cycle starts. But algorithms exist that are much more efficient in space and time.
      </p>
      
      <p class="indent">Perhaps the simplest is due to R. W. Floyd [Knu2, sec. 3.1, prob. 6]. This algorithm
         iterates the process
      </p>
      
      <div class="image"><img alt="Image" src="graphics/114equ03.jpg" /></div>
      
      <p class="indent">with <em>x</em> and <em>y</em> initialized to <em>X</em><sub>0</sub>. After the <em>n</em>th step, <em>x</em> = <em>X</em><sub><em>n</em></sub> and <em>y</em> = <em>X</em><sub>2<em>n</em></sub>. These are compared, and if equal, it is known that <em>X</em><sub><em>n</em></sub> and <em>X</em><sub>2<em>n</em></sub> are separated by an integral multiple of the period λ—that is, 2<em>n</em> − <em>n</em> = <em>n</em> is a multiple of λ. Then <strong><em>μ</em></strong> can be determined by regenerating the sequence from the beginning, comparing <em>X</em><sub>0</sub> to <em>X</em><sub><em>n</em></sub>, then <em>X</em><sub>1</sub> to <em>X</em><sub><em>n</em> + 1</sub>, and so on. Equality occurs when <em>X</em><sub><em>μ</em></sub> is compared to <a id="page_115"></a><em>X</em><sub><em>n</em>+<em>μ</em></sub>. Finally, λ can be determined by regenerating more elements, comparing <strong><em>X</em></strong><sub><em>μ</em></sub> to <em>X</em><sub><em>μ</em> + 1</sub>, <em>X</em><sub><em>μ</em>+ 2</sub>, .... This algorithm requires only a small and bounded amount of space, but it evaluates
         <em>f</em> many times.
      </p>
      
      <p class="indent">Gosper’s algorithm [HAK, item 132; Knu2, Answers to Exercises for <a href="ch03.html#ch03lev1">Section 3.1</a>, exercise 7] finds the period λ, but not the starting point <em>μ</em> of the first cycle. Its main feature is that it never backs up to reevaluate <em>f</em>, and it is quite economical in space and time. It is not bounded in space; it requires
         a table of size log<sub>2</sub>(Λ) + 1, where Λ is the largest possible period. This is not a lot of space; for example,
         if it is known a priori that <strong>Λ</strong> ≤ 2<sup>32</sup>, then 33 words suffice.
      </p>
      
      <p class="indent">Gosper’s algorithm, coded in C, is shown in <a href="ch05.html#ch05fig28">Figure 5–28</a>. This C function is given the function <em>f</em> being analyzed and a starting value <em>X</em><sub>0</sub>. It returns lower and upper bounds on <strong><em>μ</em></strong>, and the period λ. (Although Gosper’s algorithm cannot compute <strong><em>μ</em></strong>, it can compute lower and upper bounds <em>μ<sub>l</sub></em> and <em>μ<sub>u</sub></em> such that <em>μ<sub>u</sub></em> − <em>μ<sub>l</sub></em> + 1 ≤ max(λ − 1, 1).) The algorithm works by comparing <em>X<sub>n</sub></em>, for <em>n</em> = 1, 2, ..., to a subset of size <span class="entity">⌊</span>log<sub>2</sub><em>n</em><span class="entity">⌋</span> + 1 of the elements of the sequence that precede <em>X<sub>n</sub></em>. The elements of the subset are the closest preceding <em>X<sub>i</sub></em> such that <em>i</em> + 1 ends in a 1-bit (that is, <em>i</em> is the even number preceding <em>n</em>), the closest preceding <em>X<sub>t</sub></em> such that <em>i</em> + 1 ends in exactly one 0-bit, the closest preceding <em>X</em><sub><em>t</em></sub> such that <strong>i</strong> + 1 ends in exactly two 0-bits, and so on.
      </p>
      
      <p class="codelink"><a href="images4.html#p05fig28" id="p05fig28a">Click here to view code image</a></p>
      
      <hr />
      
      <p class="programlisting"><a id="ch05fig28"></a>void ld_Gosper(int (*f)(int), int X0, int *mu_l,<br />                              int*mu_u, int *lambda){<br />   int Xn, k, m, kmax, n, lgl;<br />   int T[33];<br /><br />   T[0] = X0;<br />   Xn = X0;<br />   for (n = 1; ; n++) {<br />      Xn = f(Xn);<br />      kmax = 31 - nlz(n);           // Floor(log2 n).<br />      for (k = 0; k &lt;= kmax; k++) {<br />         if (Xn == T[k]) goto L;<br />      }<br />      T[ntz(n+1)] = Xn;            // No match.<br />   }<br />L:<br />   // Compute m = max{i | i &lt; n and ntz(i+1) = k}.<br /><br />   m = ((((n &gt;&gt; k) - 1) | 1) <span class="entity">&lt;&lt;</span> k) - 1;<br />   *lambda = n - m;<br />   lgl = 31 - nlz(*lambda - 1); // Ceil(log2 lambda) - 1.<br />   *mu_u = m;                       // Upper bound on mu.<br />   *mu_l = m - max(1, 1 <span class="entity">&lt;&lt;</span> lgl) + 1;// Lower bound on mu.<br />}
      </p>
      
      <hr />
      
      <p class="fig-caption">F<small>IGURE</small> 5–28. Gosper’s loop-detection algorithm.
      </p>
      
      <p class="indent"><a id="page_116"></a>Thus, the comparisons proceed as follows:
      </p>
      
      <div class="image"><img alt="Image" src="graphics/116equ01.jpg" /></div>
      
      <p class="noindent">It can be shown that the algorithm always terminates with <em>n</em> somewhere in the second cycle—that is, with <em>n</em> &lt; <em>μ</em> + 2<em>λ</em>. See [Knu2] for further details.
      </p>
      
      <p class="indent">The ruler function reveals how to solve the Tower of Hanoi puzzle. Number the <em>n</em> disks from 0 to <em>n</em> − 1. At each move <em>k</em>, as <em>k</em> goes from 1 to 2<sup><em>n</em></sup> − 1, move disk ntz(<em>k</em>) the minimum permitted distance to the right, in a circular manner.
      </p>
      
      <p class="indent">The ruler function can be used to generate a reflected binary Gray code (see <a href="ch13.html#ch13lev1">Section 13–1</a> on page <a href="ch13.html#page_311">311</a>). Start with an arbitrary <em>n</em>-bit word, and at each step <em>k</em>, as <em>k</em> goes from 1 to 2<sup><em>n</em></sup> − 1, flip bit ntz(<em>k</em>).
      </p>
      
      <h4><strong>Exercises</strong></h4>
      
      <p class="question"><a href="ch19_answer.html#ch05ans1" id="ch05ansa1"><strong>1</strong>.</a> Code Dubé’s algorithm for the ntz function, expanding the multiplication.
      </p>
      
      <p class="question"><a href="ch19_answer.html#ch05ans2" id="ch05ansa2"><strong>2</strong>.</a> Code the “right justify” function, <span class="middle"><img alt="Image" src="graphics/116equ02.jpg" /></span>, <strong><em>x</em></strong> ≠ <strong>0</strong>, in three basic RISC instructions.
      </p>
      
      <p class="question"><a href="ch19_answer.html#ch05ans3" id="ch05ansa3"><strong>3</strong>.</a> Are the parallel prefix and suffix (with XOR) operations invertible? If so, how would
         you compute the inverse functions?
      </p>
      
   </body>
   
</html>