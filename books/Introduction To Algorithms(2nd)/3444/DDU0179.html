<html>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>28.4 Inverting matrices</title>
<link rel="STYLESHEET" type="text/css" href="images/xpolecat.css">
<link rel="STYLESHEET" type="text/css" href="images/ie.content.books24x7.css">
</head>
<body >
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td align="left" width="30%">
<div STYLE="MARGIN-LEFT: 0.15in;">
<a href="DDU0178.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</div></td>
<td align="center" width="40%">
<a href="toc.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td align="right" width="30%">
<div STYLE="MARGIN-RIGHT: 0.15in"><a href="DDU0180.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</div></td></tr>
</table>
<hr size="1">
<br>
<div class="chapter">
<a name="ch28"></a>
<div class="section">
<h2 class="first-section-title">
<a name="2308"></a><a name="ch28lev1sec4"></a><span class="section-titlelabel">28.4 </span>Inverting matrices</h2>
<p class="first-para">Although in practice we do not generally use matrix inverses to solve systems of linear equations, preferring instead to use more numerically stable techniques such as LUP decomposition, it is sometimes necessary to compute a matrix inverse. In this section, we show how LUP decomposition can be used to compute a matrix inverse. We also prove that matrix multiplication and computing the inverse of a matrix are equivalently hard problems, in that (subject to technical conditions) we can use an algorithm for one to solve the other in the same asymptotic running time. Thus, we can use Strassen's algorithm for matrix multiplication to invert a matrix. Indeed, Strassen's original paper was motivated by the problem of showing that a set of a linear equations could be solved more quickly than by the usual method.</p>
<div class="section">
<h4 class="sect4-title">
<a name="2309"></a><a name="ch28lev3sec12"></a>Computing a matrix inverse from an LUP decomposition</h4>
<p class="first-para">Suppose that we have an LUP decomposition of a matrix <i class="emphasis">A</i> in the form of three matrices <i class="emphasis">L</i>, <i class="emphasis">U</i> , and <i class="emphasis">P</i> such that <i class="emphasis">PA</i> = <i class="emphasis">LU</i>. Using LUP-SOLVE, we can solve an equation of the form <i class="emphasis">Ax</i> = <i class="emphasis">b</i> in time <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>2</sup>). Since the LUP decomposition depends on <i class="emphasis">A</i> but not <i class="emphasis">b</i>, we can run LUP-SOLVE on a second set of equations of the form <i class="emphasis">Ax</i> = <i class="emphasis">b</i>' in additional time <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>2</sup>). In general, once we have the LUP decomposition of <i class="emphasis">A</i>, we can solve, in time <span class="unicode">&Theta;</span>(<i class="emphasis">kn</i><sup>2</sup>), <i class="emphasis">k</i> versions of the equation <i class="emphasis">Ax</i> = <i class="emphasis">b</i> that differ only in <i class="emphasis">b</i>.</p>
<p class="para">The equation</p>
<div class="equation">
<a name="2310"></a><a name="ch28eq24"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(28.24)&nbsp;</span></td><td valign="top"><span class="equation-image"><img src="images/fig777_01.jpg" height="15" width="55" alt="" border="0"></span></td>
</tr>
</table>
</div>
<p class="para">can be viewed as a set of <i class="emphasis">n</i> distinct equations of the form <i class="emphasis">Ax</i> = <i class="emphasis">b</i>. These equations define the matrix <i class="emphasis">X</i> as the inverse of <i class="emphasis">A</i>. To be precise, let <i class="emphasis">X<sub>i</sub></i> denote the <i class="emphasis">i</i>th column of <i class="emphasis">X</i>, and recall that the unit vector <i class="emphasis">e<sub>i</sub></i> is the <i class="emphasis">i</i>th column of <i class="emphasis">I<sub>n</sub></i>. <a class="internaljump" href="#ch28eq24">Equation (28.24)</a> can then be solved for <i class="emphasis">X</i> by using the LUP decomposition for <i class="emphasis">A</i> to solve each equation</p>
<p class="para">
<i class="emphasis">AX<sub>i</sub></i> = <i class="emphasis">e<sub>i</sub></i><a name="2311"></a><a name="IDX-756"></a>
</p>
<p class="last-para">separately for <i class="emphasis">X<sub>i</sub></i>. Each of the <i class="emphasis">n</i> columns <i class="emphasis">X<sub>i</sub></i> can be found in time <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>2</sup>), and so the computation of <i class="emphasis">X</i> from the LUP decomposition of <i class="emphasis">A</i> takes time <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>3</sup>). Since the LUP decomposition of <i class="emphasis">A</i> can be computed in time <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>3</sup>), the inverse <i class="emphasis">A</i><sup>-1</sup> of a matrix <i class="emphasis">A</i> can be determined in time <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>3</sup>).</p>

</div>
<div class="section">
<h4 class="sect4-title">
<a name="2312"></a><a name="ch28lev3sec13"></a>Matrix multiplication and matrix inversion</h4>
<p class="first-para">We now show that the theoretical speedups obtained for matrix multiplication translate to speedups for matrix inversion. In fact, we prove something stronger: matrix inversion is equivalent to matrix multiplication, in the following sense. If <i class="emphasis">M</i>(<i class="emphasis">n</i>) denotes the time to multiply two <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices, then there is a way to invert an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix in time <i class="emphasis">O</i> (<i class="emphasis">M</i>(<i class="emphasis">n</i>)). Moreover, if <i class="emphasis">I</i> (<i class="emphasis">n</i>) denotes the time to invert a nonsingular <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix, then there is a way to multiply two <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices in time <i class="emphasis">O</i> (<i class="emphasis">I</i>(<i class="emphasis">n</i>)). We prove these results as two separate theorems.</p>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Theorem 28.7: </span>(Multiplication is no harder than inversion)</span>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">If we can invert an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix in time <i class="emphasis">I</i> (<i class="emphasis">n</i>), where <i class="emphasis">I</i> (<i class="emphasis">n</i>) = <span class="unicode">&#8486;</span> (<i class="emphasis">n</i><sup>2</sup>) and <i class="emphasis">I</i> (<i class="emphasis">n</i>) satisfies the regularity condition <i class="emphasis">I</i> (3<i class="emphasis">n</i>) = <i class="emphasis">O</i>(<i class="emphasis">I</i> (<i class="emphasis">n</i>)), then we can multiply two <i class="emphasis">n</i> <span class="unicode">&times;</span><i class="emphasis">n</i> matrices in time <i class="emphasis">O</i>(<i class="emphasis">I</i> (<i class="emphasis">n</i>)).</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<p class="para">
<b class="bold"><i class="emphasis">Proof</i></b> Let <i class="emphasis">A</i> and <i class="emphasis">B</i> be <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices whose matrix product <i class="emphasis">C</i> we wish to compute. We define the 3<i class="emphasis">n</i> <span class="unicode">&times;</span> 3<i class="emphasis">n</i> matrix <i class="emphasis">D</i> by</p>
<div class="informalequation">
<span class="equation-image"><img src="images/fig778_01.jpg" height="55" width="138" alt="" border="0"></span>
</div>
<p class="para">The inverse of <i class="emphasis">D</i> is</p>
<div class="informalequation">
<span class="equation-image"><img src="images/fig778_02.jpg" height="55" width="172" alt="" border="0"></span>
</div>
<p class="para">and thus we can compute the product <i class="emphasis">AB</i> by taking the upper right <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> submatrix of <i class="emphasis">D</i><sup>-1</sup>.</p>
<p class="para">We can construct matrix <i class="emphasis">D</i> in <span class="unicode">&Theta;</span>(<i class="emphasis">n</i><sup>2</sup>) = <i class="emphasis">O</i>(<i class="emphasis">I</i> (<i class="emphasis">n</i>)) time, and we can invert <i class="emphasis">D</i> in <i class="emphasis">O</i>(<i class="emphasis">I</i> (3<i class="emphasis">n</i>)) = <i class="emphasis">O</i>(<i class="emphasis">I</i> (<i class="emphasis">n</i>)) time, by the regularity condition on <i class="emphasis">I</i>(<i class="emphasis">n</i>). We thus have <i class="emphasis">M</i>(<i class="emphasis">n</i>) = <i class="emphasis">O</i>(<i class="emphasis">I</i> (<i class="emphasis">n</i>)).</p>
<p class="para">Note that <i class="emphasis">I</i> (<i class="emphasis">n</i>) satisfies the regularity condition whenever <i class="emphasis">I</i> (<i class="emphasis">n</i>) = <span class="unicode">&Theta;</span>(<i class="emphasis">n<sup>c</sup></i> lg<sup><i class="emphasis">d</i></sup> <i class="emphasis">n</i>) for any constants <i class="emphasis">c</i> <span class="unicode">&gt;</span> 0 and <i class="emphasis">d</i> <span class="unicode">&ge;</span> 0.</p>
<p class="para">The proof that matrix inversion is no harder than matrix multiplication relies on some properties of symmetric positive-definite matrices that will be proved in <a href="DDU0180.html#2325" target="_parent" class="chapterjump">Section 28.5.</a><a name="2313"></a><a name="IDX-757"></a>
</p>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Theorem 28.8: </span>(Inversion is no harder than multiplication)</span><a name="2314"></a><a name="ch28ex32"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Suppose we can multiply two <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> real matrices in time <i class="emphasis">M</i>(<i class="emphasis">n</i>), where <i class="emphasis">M</i>(<i class="emphasis">n</i>) = <span class="unicode">&#8486;</span>(<i class="emphasis">n</i><sup>2</sup>) and <i class="emphasis">M</i>(<i class="emphasis">n</i>) satisfies the two regularity conditions <i class="emphasis">M</i>(<i class="emphasis">n</i> + <i class="emphasis">k</i>) = <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>)) for any <i class="emphasis">k</i> in the range 0 <span class="unicode">&le;</span> <i class="emphasis">k</i> <span class="unicode">&le;</span> <i class="emphasis">n</i> and <i class="emphasis">M</i>(<i class="emphasis">n</i>/2) <span class="unicode">&le;</span> <i class="emphasis">cM</i>(<i class="emphasis">n</i>) for some constant <i class="emphasis">c</i> <span class="unicode">&lt;</span> 1/2. Then we can compute the inverse of any real nonsingular <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix in time <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>)).</p>
<p class="para">
<b class="bold"><i class="emphasis">Proof</i></b> We can assume that <i class="emphasis">n</i> is an exact power of 2, since we have</p>
<p class="para">
<div class="informalequation">
<span class="equation-image"><img src="images/fig779_01.jpg" height="43" width="172" alt="" border="0"></span>
</div>
</p>
<p class="para">for any <i class="emphasis">k</i> <span class="unicode">&gt;</span> 0. Thus, by choosing <i class="emphasis">k</i> such that <i class="emphasis">n</i> + <i class="emphasis">k</i> is a power of 2, we enlarge the matrix to a size that is the next power of 2 and obtain the desired answer <i class="emphasis">A</i><sup>-1</sup> from the answer to the enlarged problem. The first regularity condition on <i class="emphasis">M</i>(<i class="emphasis">n</i>) ensures that this enlargement does not cause the running time to increase by more than a constant factor.</p>
<p class="para">For the moment, let us assume that the <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix <i class="emphasis">A</i> is symmetric and positive-definite. We partition <i class="emphasis">A</i> into four <i class="emphasis">n</i>/2 <span class="unicode">&times;</span> <i class="emphasis">n</i>/2 submatrices:</p>
<p class="para">
<div class="equation">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(28.25)&nbsp;</span></td><td valign="top"><span class="equation-image"><img src="images/fig779_02.jpg" height="39" width="110" alt="" border="0"></span></td>
</tr>
</table>
</div>
</p>
<p class="para">Then, if we let</p>
<p class="para">
<div class="equation">
<a name="2315"></a><a name="ch28eq26"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(28.26)&nbsp;</span></td><td valign="top"><span class="equation-image"><img src="images/fig779_03.jpg" height="17" width="111" alt="" border="0"></span></td>
</tr>
</table>
</div>
</p>
<p class="para">be the Schur complement of <i class="emphasis">A</i> with respect to <i class="emphasis">B</i> (we shall see more about this form of Schur complement in <a href="DDU0180.html#2325" target="_parent" class="chapterjump">Section 28.5</a>), we have</p>
<p class="para">
<div class="equation">
<a name="2316"></a><a name="ch28eq27"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(28.27)&nbsp;</span></td><td valign="top"><span class="equation-image"><img src="images/fig779_04.jpg" height="41" width="316" alt="" border="0"></span></td>
</tr>
</table>
</div>
</p>
<p class="para">since <i class="emphasis">AA</i><sup>-1</sup> = <i class="emphasis">I<sub>n</sub></i>, as can be verified by performing the matrix multiplication. The matrices <i class="emphasis">B</i><sup>-1</sup> and <i class="emphasis">S</i><sup>-1</sup> exist if <i class="emphasis">A</i> is symmetric and positive-definite, by <a href="DDU0180.html#2327" target="_parent" class="chapterjump">Lemmas 28.9</a>, <a href="DDU0180.html#2328" target="_parent" class="chapterjump">28.10</a>, and <a href="DDU0180.html#2332" target="_parent" class="chapterjump">28.11</a> in <a href="DDU0180.html#2325" target="_parent" class="chapterjump">Section 28.5</a>, because both <i class="emphasis">B</i> and <i class="emphasis">S</i> are symmetric and positive-definite. By <a href="DDU0176.html#2241" target="_parent" class="chapterjump">Exercise 28.1-2</a>, <i class="emphasis">B</i><sup>-1</sup><i class="emphasis">C</i><sup>T</sup> = (<i class="emphasis">C B</i><sup>-1</sup>)<sup>T</sup> and <i class="emphasis">B</i><sup>-1</sup><i class="emphasis">C</i><sup>T</sup><i class="emphasis">S</i><sup>-1</sup> = (<i class="emphasis">S</i><sup>1</sup><i class="emphasis">C B</i><sup>-1</sup>)<sup>T</sup>. <a class="internaljump" href="#ch28eq26">Equations (28.26)</a> and (<a class="internaljump" href="#ch28eq27">28.27</a>) can therefore be used to specify a recursive algorithm involving four multiplications of <i class="emphasis">n</i>/2 <span class="unicode">&times;</span> <i class="emphasis">n</i>/2 matrices:</p>
<p class="para">
<i class="emphasis">C</i> <span class="unicode">&middot;</span> <i class="emphasis">B</i><sup>-1</sup>,</p>
<p class="para">(<i class="emphasis">C B</i><sup>-1</sup>) <span class="unicode">&middot;</span> <i class="emphasis">C<sup>T</sup></i>,</p>
<p class="para">
<i class="emphasis">S</i><sup>-1</sup> <span class="unicode">&middot;</span> (<i class="emphasis">C B</i><sup>-1</sup>),</p>
<p class="para">(<i class="emphasis">C B</i><sup>-1</sup>)<sup>T</sup> <span class="unicode">&middot;</span> (<i class="emphasis">S</i><sup>-1</sup><i class="emphasis">C B</i><sup>-1</sup>).<a name="2317"></a><a name="IDX-758"></a>
</p>
<p class="para">Thus, we can invert an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> symmetric positive-definite matrix by inverting two <i class="emphasis">n</i>/2 <span class="unicode">&times;</span> <i class="emphasis">n</i>/2 matrices (<i class="emphasis">B</i> and <i class="emphasis">S</i>), performing these four multiplications of <i class="emphasis">n</i>/2 <span class="unicode">&times;</span> <i class="emphasis">n</i>/2 matrices (which we can do with an algorithm for <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices), plus an additional cost of <i class="emphasis">O</i>(<i class="emphasis">n</i><sup>2</sup>) for extracting submatrices from <i class="emphasis">A</i> and performing a constant number of additions and subtractions on these <i class="emphasis">n</i>/2 <span class="unicode">&times;</span> <i class="emphasis">n</i>/2 matrices. We get the recurrence</p>
<p class="para">
<div class="informaltable">
<table border="0">
<tbody>
<tr valign="top">
<td class="td" align="left">
<p class="table-para">
<i class="emphasis">I</i> (<i class="emphasis">n</i>)</p>
</td><td class="td" align="center">
<p class="table-para">
<span class="unicode">&le;</span>
</p>
</td><td class="td" align="left">
<p class="table-para">2<i class="emphasis">I</i>(<i class="emphasis">n</i>/2) + 4<i class="emphasis">M</i>(<i class="emphasis">n</i>) + <i class="emphasis">O</i>(<i class="emphasis">n</i><sup>2</sup>)</p>
</td>
</tr>
<tr valign="top">
<td class="td" align="left">&nbsp;</td><td class="td" align="center">
<p class="table-para">=</p>
</td><td class="td" align="left">
<p class="table-para">2<i class="emphasis">I</i>(<i class="emphasis">n</i>/2) + <span class="unicode">&Theta;</span> (<i class="emphasis">M</i>(<i class="emphasis">n</i>))</p>
</td>
</tr>
<tr valign="top">
<td class="td" align="left">&nbsp;</td><td class="td" align="center">
<p class="table-para">=</p>
</td><td class="td" align="left">
<p class="table-para">
<i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>)).</p>
</td>
</tr>
</tbody>
</table>
</div>
</p>
<p class="para">The second line holds because <i class="emphasis">M</i>(<i class="emphasis">n</i>) = <span class="unicode">&#8486;</span>(<i class="emphasis">n</i><sup>2</sup>), and the third line follows because the second regularity condition in the statement of the theorem allows us to apply case 3 of the master theorem (<a href="DDU0024.html#221" target="_parent" class="chapterjump">Theorem 4.1</a>).</p>
<p class="para">It remains to prove that the asymptotic running time of matrix multiplication can be obtained for matrix inversion when <i class="emphasis">A</i> is invertible but not symmetric and positive-definite. The basic idea is that for any nonsingular matrix <i class="emphasis">A</i>, the matrix <i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i> is symmetric (by <a href="DDU0176.html#2241" target="_parent" class="chapterjump">Exercise 28.1-2</a>) and positive-definite (by <a href="DDU0176.html#2239" target="_parent" class="chapterjump">Theorem 28.6</a>). The trick, then, is to reduce the problem of inverting <i class="emphasis">A</i> to the problem of inverting <i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>.</p>
<p class="para">The reduction is based on the observation that when <i class="emphasis">A</i> is an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> nonsingular matrix, we have</p>
<p class="para">
<i class="emphasis">A</i><sup>-1</sup> = (<i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>)<sup>-1</sup> <i class="emphasis">A</i><sup>T</sup>,</p>
<p class="last-para">since ((<i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>)<sup>-1</sup> <i class="emphasis">A</i><sup>T</sup>)<i class="emphasis">A</i> = (<i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>)<sup>-1</sup>(<i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>) = <i class="emphasis">I<sub>n</sub></i> and a matrix inverse is unique. Therefore, we can compute <i class="emphasis">A</i><sup>-1</sup> by first multiplying <i class="emphasis">A</i><sup>T</sup> by <i class="emphasis">A</i> to obtain <i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>, then inverting the symmetric positive-definite matrix <i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i> using the above divide-and-conquer algorithm, and finally multiplying the result by <i class="emphasis">A</i><sup>T</sup>. Each of these three steps takes <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>)) time, and thus any nonsingular matrix with real entries can be inverted in <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>)) time.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<p class="para">The proof of <a class="internaljump" href="#ch28ex32">Theorem 28.8</a> suggests a means of solving the equation <i class="emphasis">Ax</i> = <i class="emphasis">b</i> by using LU decomposition without pivoting, so long as <i class="emphasis">A</i> is nonsingular. We multiply both sides of the equation by <i class="emphasis">A</i><sup>T</sup>, yielding (<i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i>)<i class="emphasis">x</i> = <i class="emphasis">A</i><sup>T</sup><i class="emphasis">b</i>. This transformation doesn't affect the solution <i class="emphasis">x</i>, since <i class="emphasis">A</i><sup>T</sup> is invertible, and so we can factor the symmetric positive-definite matrix <i class="emphasis">A</i><sup>T</sup> <i class="emphasis">A</i> by computing an LU decomposition. We then use forward and back substitution to solve for <i class="emphasis">x</i> with the right-hand side <i class="emphasis">A</i><sup>T</sup><i class="emphasis">b</i>. Although this method is theoretically correct, in practice the procedure LUP-DECOMPOSITION works much better. LUP decomposition requires fewer arithmetic operations by a constant factor, and it has somewhat better numerical properties.<a name="2318"></a><a name="IDX-759"></a>
</p>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Exercises 28.4-1</span></span><a name="2319"></a><a name="ch28ex33"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Let <i class="emphasis">M</i>(<i class="emphasis">n</i>) be the time to multiply <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices, and let <i class="emphasis">S</i>(<i class="emphasis">n</i>) denote the time required to square an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix. Show that multiplying and squaring matrices have essentially the same difficulty: an <i class="emphasis">M</i>(<i class="emphasis">n</i>)-time matrix-multiplication algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>))-time squaring algorithm, and an <i class="emphasis">S</i>(<i class="emphasis">n</i>)-time squaring algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">S</i>(<i class="emphasis">n</i>))-time matrix-multiplication algorithm.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Exercises 28.4-2</span></span><a name="2320"></a><a name="ch28ex34"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Let <i class="emphasis">M</i>(<i class="emphasis">n</i>) be the time to multiply <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices, and let <i class="emphasis">L</i>(<i class="emphasis">n</i>) be the time to compute the LUP decomposition of an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix. Show that multiplying matrices and computing LUP decompositions of matrices have essentially the same difficulty: an <i class="emphasis">M</i>(<i class="emphasis">n</i>)-time matrix-multiplication algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>))-time LUP-decomposition algorithm, and an <i class="emphasis">L</i>(<i class="emphasis">n</i>)-time LUP-decomposition algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">L</i>(<i class="emphasis">n</i>))-time matrix-multiplication algorithm.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Exercises 28.4-3</span></span><a name="2321"></a><a name="ch28ex35"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Let <i class="emphasis">M</i>(<i class="emphasis">n</i>) be the time to multiply <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrices, and let <i class="emphasis">D</i>(<i class="emphasis">n</i>) denote the time required to find the determinant of an <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> matrix. Show that multiplying matrices and computing the determinant have essentially the same difficulty: an <i class="emphasis">M</i>(<i class="emphasis">n</i>)-time matrix-multiplication algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>))-time determinant algorithm, and a <i class="emphasis">D</i>(<i class="emphasis">n</i>)-time determinant algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">D</i>(<i class="emphasis">n</i>))-time matrix-multiplication algorithm.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Exercises 28.4-4</span></span><a name="2322"></a><a name="ch28ex36"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Let <i class="emphasis">M</i>(<i class="emphasis">n</i>) be the time to multiply <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> boolean matrices, and let <i class="emphasis">T</i> (<i class="emphasis">n</i>) be the time to find the transitive closure of <i class="emphasis">n</i> <span class="unicode">&times;</span> <i class="emphasis">n</i> boolean matrices. (See <a href="DDU0157.html#1909" target="_parent" class="chapterjump">Section 25.2.</a>) Show that an <i class="emphasis">M</i>(<i class="emphasis">n</i>)-time boolean matrix-multiplication algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">M</i>(<i class="emphasis">n</i>) lg <i class="emphasis">n</i>)-time transitive-closure algorithm, and a <i class="emphasis">T</i> (<i class="emphasis">n</i>)-time transitive-closure algorithm implies an <i class="emphasis">O</i>(<i class="emphasis">T</i> (<i class="emphasis">n</i>))-time boolean matrix-multiplication algorithm.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Exercises 28.4-5</span></span><a name="2323"></a><a name="ch28ex37"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Does the matrix-inversion algorithm based on <a class="internaljump" href="#ch28ex32">Theorem 28.8</a> work when matrix elements are drawn from the field of integers modulo 2? Explain.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<div class="example">
<span class="example-title"><span class="example-titlelabel">Exercises 28.4-6: </span><span class="unicode">&#9733;</span></span><a name="2324"></a><a name="ch28ex38"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="Start example" border="0"></b></font></td>
</tr>
</table>
<p class="first-para">Generalize the matrix-inversion algorithm of <a class="internaljump" href="#ch28ex32">Theorem 28.8</a> to handle matrices of complex numbers, and prove that your generalization works correctly. (<i class="emphasis">Hint:</i> Instead of the transpose of <i class="emphasis">A</i>, use the <b class="bold"><i class="emphasis">conjugate transpose</i></b> <i class="emphasis">A</i>*, which is obtained from the transpose of <i class="emphasis">A</i> by replacing every entry with its complex conjugate. Instead of symmetric matrices, consider <b class="bold">Hermitian</b> matrices, which are matrices <i class="emphasis">A</i> such that <i class="emphasis">A</i> = <i class="emphasis">A</i>*.)</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img src="_.gif" width="1" height="2" alt="End example" border="0"></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>

</div>

</div>
</div>
</div>
</div>
<br><hr size="1">
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td align="left" width="30%">
<div STYLE="MARGIN-LEFT: 0.15in;">
<a href="DDU0178.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</div></td>
<td align="center" width="40%">
<a href="toc.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td align="right" width="30%">
<div STYLE="MARGIN-RIGHT: 0.15in"><a href="DDU0180.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</div></td></tr>
</table>
</body>
</html>
