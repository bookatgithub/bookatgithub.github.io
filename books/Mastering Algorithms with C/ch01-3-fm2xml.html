<HTML><HEAD><TITLE>ch01-3-fm2xml</TITLE>
<META http-equiv=Content-Type content="text/html; charset=windows-1252"><LINK 
href="image/style.css" type=text/css rel=STYLESHEET><LINK 
href="image/docsafari.css" type=text/css rel=STYLESHEET>

<META content="MSHTML 6.00.2800.1141" name=GENERATOR></HEAD>
<BODY leftMargin=0 topMargin=0 marginheight="0" marginwidth="0"><A 
name=toppage></A><SPAN class=v2></SPAN>
<TABLE cellSpacing=0 cellPadding=0 width="100%" border=0>
  <TBODY>
  <TR vAlign=top>
    <TD align=middle>
      <TABLE width="95%">
        <TBODY>
        <TR>
          <TD class=v2 align=left>
            <HR SIZE=1>

            <TABLE cellSpacing=0 cellPadding=5 width="100%" border=0>
              <TBODY>
              <TR>
                <TD vAlign=top width=76 rowSpan=4><A 
                  ><IMG 
                  height=100 src="image/masteralgoc_xs.gif" width=76 
                  border=0></A></TD>
                <TD class=v2 vAlign=top><A class=t1 
                  >Mastering 
                  Algorithms with C</A><BR>By Kyle&nbsp;Loudon<BR>Slots : 
                1<BR></TD></TR>
              <TR>
                <TD class=v1><A class=v1 
                  href="table.html">Table 
                  of Contents</A></TD></TR>
              <TR>
                <TD></TD></TR>
              <TR>
                <TD class=t1 vAlign=bottom>Chapter 1.&nbsp; 
              Introduction</TD></TR></TBODY></TABLE>
            <HR SIZE=1>
            <TABLE cellSpacing=0 cellPadding=2 width="100%" border=0>
              <TBODY>
              <TR>
              <TR>
                <TD class=v2 vAlign=top align=center>&nbsp; <A accessKey=2 
                  href="ch01-2-fm2xml.html"><IMG 
                  height=16 src="image/btn_prev.gif" width=56 align=left 
                  border=0></A> &nbsp; <A  
href="table.html" align=center> Content </A>	<A accessKey=1                  href="ch01-10-fm2xml.html"><IMG 
                  height=16 src="image/btn_next.gif" width=41 align=right 
                  border=0></A></TD></TR></TBODY></TABLE>
            <BR>
            <TABLE cellSpacing=0 cellPadding=0 width="100%" border=0>
              <TBODY>
              <TR>
                <TD vAlign=top><A name=ch01-3-fm2xml></A>
                  <H3 class=docSection1Title>1.2 An Introduction to 
                  Algorithms</H3>
                  <P class=docText><A name=ch01-idx-985751-1></A>Algorithms<A 
                  name=IXT-1-313192></A> are well-defined procedures for solving 
                  problems. In computing, <A 
                  name=ch01-idx-985742-1></A>algorithms are essential because 
                  they serve as the systematic procedures that computers 
                  require. A good algorithm is like using the right tool in a 
                  workshop. It does the job with the right amount of effort. 
                  Using the wrong algorithm or one that is not clearly defined 
                  is like cutting a piece of paper with a table saw, or trying 
                  to cut a piece of plywood with a pair of scissors: although 
                  the job may get done, you have to wonder how effective you 
                  were in completing it. As with data structures, three reasons 
                  for using formal algorithms are efficiency, abstraction, and 
                  reusability.</P><A name=IXT-1-313193></A><A name=IXTR3-0></A>
                  <DL class=docList>
                    <DT><I><SPAN class=docPubcolor>Efficiency</SPAN></I> 
                    <DD>
                    <P class=docList>Because certain types of problems occur 
                    often in computing, researchers have found efficient ways of 
                    solving them over time. For example, imagine trying to sort 
                    a number of entries in an index for a book. Since sorting is 
                    a common task that is performed often, it is not surprising 
                    that there are many efficient algorithms for doing this. We 
                    explore some of these in <A class=docLink 
                    href="ch12-1-fm2xml.html#ch12-1-fm2xml">Chapter 
                    12</A>.</P>
                    <DT><I><SPAN class=docPubcolor>Abstraction</SPAN></I> 
                    <DD>
                    <P class=docList>Algorithms provide a level of abstraction 
                    in solving problems because many seemingly complicated 
                    problems can be distilled into simpler ones for which 
                    well-known algorithms exist. Once we see a more complicated 
                    problem in a simpler light, we can think of the simpler 
                    problem as just an abstraction of the more complicated one. 
                    For example, imagine trying to find the shortest way to 
                    route a packet between two gateways in an internet. Once we 
                    realize that this problem is just a variation of the more 
                    general <SPAN class=docEmphasis>single-pair shortest-paths 
                    problem</SPAN> (see <A class=docLink 
                    href="ch16-1-fm2xml.html#ch16-1-fm2xml">Chapter 
                    16</A>), we can approach it in terms of this 
                    generalization.</P>
                    <DT><I><SPAN class=docPubcolor>Reusability</SPAN></I> 
                    <DD>
                    <P class=docList><A name=IXT-1-313193></A>Algorithms are 
                    often reusable in many different situations. Since many 
                    well- known algorithms solve problems that are 
                    generalizations of more complicated ones, and since many 
                    complicated problems can be distilled into simpler ones, an 
                    efficient means of solving certain simpler problems 
                    potentially lets us solve many others.<A 
                    name=IXTR3-0></A></P></DD></DL><A name=ch01-4-fm2xml></A>
                  <H4 class=docSection2Title>1.2.1 General Approaches in 
                  Algorithm Design</H4>
                  <P class=docText><A name=ch01-idx-985625-1></A>In a broad 
                  sense, many algorithms approach problems in the same way. 
                  Thus, it is often convenient to classify them based on the 
                  approach they employ. One reason to classify algorithms in 
                  this way is that often we can gain some insight about an 
                  algorithm if we understand its general approach. This can also 
                  give us ideas about how to look at similar problems for which 
                  we do not know algorithms. Of course, some algorithms defy 
                  classification, whereas others are based on a combination of 
                  approaches. This section presents some common 
                  approaches.</P><A name=ch01-5-fm2xml></A>
                  <H5 class=docSection3Title>1.2.1.1 Randomized algorithms</H5>
                  <P class=docText><A name=IXT-1-313194></A><A 
                  name=IXT-1-313195></A>Randomized algorithms rely on the 
                  statistical properties of random numbers. One example of a 
                  randomized algorithm is <SPAN 
                  class=docEmphasis>quicksort</SPAN> (see <A class=docLink 
                  href="ch12-1-fm2xml.html#ch12-1-fm2xml">Chapter 
                  12</A>).</P>
                  <P class=docText>Quicksort<A name=IXT-1-313196></A> works as 
                  follows. Imagine sorting a pile of canceled checks by hand. We 
                  begin with an unsorted pile that we partition in two. In one 
                  pile we place all checks numbered less than or equal to what 
                  we think may be the median value, and in the other pile we 
                  place the checks numbered greater than this. Once we have the 
                  two piles, we divide each of them in the same manner and 
                  repeat the process until we end up with one check in every 
                  pile. At this point the checks are sorted.</P>
                  <P class=docText>In order to achieve good performance, 
                  quicksort relies on the fact that each time we partition the 
                  checks, we end up with two partitions that are nearly equal in 
                  size. To accomplish this, ideally we need to look up the 
                  median value of the check numbers before partitioning the 
                  checks. However, since determining the median requires 
                  scanning all of the checks, we do not do this. Instead, we 
                  randomly select a check around which to partition. Quicksort 
                  performs well on average because the normal distribution of 
                  random numbers leads to relatively balanced partitioning 
                  overall.</P><A name=ch01-6-fm2xml></A>
                  <H5 class=docSection3Title>1.2.1.2 Divide-and-conquer 
                  algorithms</H5>
                  <P class=docText><A name=IXT-1-313197></A>Divide-and-conquer 
                  algorithms revolve around three steps: <SPAN 
                  class=docEmphasis>divide</SPAN>, <SPAN 
                  class=docEmphasis>conquer</SPAN>, and <SPAN 
                  class=docEmphasis>combine</SPAN>. In the divide step, we 
                  divide the data into smaller, more manageable pieces. In the 
                  conquer step, we process each division by performing some 
                  operation on it. In the combine step, we recombine the 
                  processed divisions. One example of a divide-and-conquer 
                  algorithm is <SPAN class=docEmphasis>merge sort</SPAN> (see <A 
                  class=docLink 
                  href="ch12-1-fm2xml.html#ch12-1-fm2xml">Chapter 
                  12</A>).</P>
                  <P class=docText>Merge sort<A name=IXT-1-313198></A> works as 
                  follows. As before, imagine sorting a pile of canceled checks 
                  by hand. We begin with an unsorted pile that we divide in 
                  half. Next, we divide each of the resulting two piles in half 
                  and continue this process until we end up with one check in 
                  every pile. Once all piles contain a single check, we merge 
                  the piles two by two so that each new pile is a sorted 
                  combination of the two that were merged. Merging continues 
                  until we end up with one big pile again, at which point the 
                  checks are sorted.</P>
                  <P class=docText>In terms of the three steps common to all 
                  divide-and-conquer algorithms, merge sort can be described as 
                  follows. First, in the divide step, divide the data in half. 
                  Next, in the conquer step, sort the two divisions by 
                  recursively applying merge sort to them. Last, in the combine 
                  step, merge the two divisions into a single sorted set.</P><A 
                  name=ch01-7-fm2xml></A>
                  <H5 class=docSection3Title>1.2.1.3 Dynamic-programming 
                  solutions</H5>
                  <P class=docText><A name=IXT-1-313199></A><A 
                  name=IXT-1-313200></A>Dynamic-programming solutions are 
                  similar to divide-and-conquer methods in that both solve 
                  problems by breaking larger problems into subproblems whose 
                  results are later recombined. However, the approaches differ 
                  in how subproblems are related. In divide-and-conquer 
                  algorithms, each subproblem is independent of the others. 
                  Therefore, we solve each subproblem using recursion (see <A 
                  class=docLink 
                  href="ch03-1-fm2xml.html#ch03-1-fm2xml">Chapter 
                  3</A>) and combine its result with the results of other 
                  subproblems. In dynamic-programming solutions, subproblems are 
                  not independent of one another. In other words, subproblems 
                  may share subproblems. In problems like this, a 
                  dynamic-programming solution is better than a 
                  divide-and-conquer approach because the latter approach will 
                  do more work than necessary, as shared subproblems are solved 
                  more than once. Although it is an important technique used by 
                  many algorithms, none of the algorithms in this book use 
                  dynamic programming.</P><A name=ch01-8-fm2xml></A>
                  <H5 class=docSection3Title>1.2.1.4 Greedy algorithms</H5>
                  <P class=docText><A name=IXT-1-313201></A><A 
                  name=IXT-1-313202></A>Greedy algorithms make decisions that 
                  look best at the moment. In other words, they make decisions 
                  that are locally optimal in the hope that they will lead to 
                  globally optimal solutions. Unfortunately, decisions that look 
                  best at the moment are not always the best in the long run. 
                  Therefore, greedy algorithms do not always produce optimal 
                  results; however, in some cases they do. One example of a 
                  greedy algorithm is <SPAN class=docEmphasis>Huffman 
                  coding</SPAN>, which is an algorithm for data compression (see 
                  <A class=docLink 
                  href="ch14-1-fm2xml.html#ch14-1-fm2xml">Chapter 
                  14</A>).</P>
                  <P class=docText>The most significant part of Huffman coding<A 
                  name=IXT-1-313203></A> is building a <SPAN 
                  class=docEmphasis>Huffman tree</SPAN>. To build a Huffman 
                  tree<A name=IXT-1-313204></A>, we proceed from its leaf nodes 
                  upward. We begin by placing each symbol to compress and the 
                  number of times it occurs in the data (its frequency) in the 
                  root node of its own binary tree (see <A class=docLink 
                  href="ch09-1-fm2xml.html#ch09-1-fm2xml">Chapter 
                  9</A>). Next, we merge the two trees whose root nodes have the 
                  smallest frequencies and store the sum of the frequencies in 
                  the new tree's root. We then repeat this process until we end 
                  up with a single tree, which is the final Huffman tree. The 
                  root node of this tree contains the total number of symbols in 
                  the data, and its leaf nodes contain the original symbols and 
                  their frequencies. Huffman coding is greedy because it 
                  continually seeks out the two trees that appear to be the best 
                  to merge at any given time.</P><A name=ch01-9-fm2xml></A>
                  <H5 class=docSection3Title>1.2.1.5 Approximation 
                  algorithms</H5>
                  <P class=docText><A name=IXT-1-313205></A>Approximation 
                  algorithms are algorithms that do not compute optimal 
                  solutions; instead, they compute solutions that are "good 
                  enough." Often we use approximation algorithms to solve 
                  problems that are computationally expensive but are too 
                  significant to give up on altogether. The <SPAN 
                  class=docEmphasis>traveling-salesman problem</SPAN> (see <A 
                  class=docLink 
                  href="ch16-1-fm2xml.html#ch16-1-fm2xml">Chapter 
                  16</A>) is one example of a problem usually solved using an 
                  approximation<A name=IXT-1-313206></A> algorithm.</P>
                  <P class=docText><A name=IXT-1-313207></A>Imagine a salesman 
                  who needs to visit a number of cities as part of the route he 
                  works. The goal in the traveling-salesman problem is to find 
                  the shortest route possible by which the salesman can visit 
                  every city exactly once before returning to the point at which 
                  he starts. Since an optimal solution to the traveling-salesman 
                  problem is possible but computationally expensive, we use a 
                  <SPAN class=docEmphasis>heuristic</SPAN> to come up with an 
                  approximate solution. A heuristic<A name=IXT-1-313208></A> is 
                  a less than optimal strategy that we are willing to accept 
                  when an optimal strategy is not feasible.</P>
                  <P class=docText>The traveling-salesman problem can be 
                  represented graphically by depicting the cities the salesman 
                  must visit as points on a grid. We then look for the shortest 
                  tour of the points by applying the following heuristic. Begin 
                  with a tour consisting of only the point at which the salesman 
                  starts. Color this point black. All other points are white 
                  until added to the tour, at which time they are colored black 
                  as well. Next, for each point <SPAN class=docEmphasis>v</SPAN> 
                  not already in the tour, compute the distance between the last 
                  point <SPAN class=docEmphasis>u</SPAN> added to the tour and 
                  <SPAN class=docEmphasis>v</SPAN>. Using this, select the point 
                  closest to <SPAN class=docEmphasis>u</SPAN>, color it black, 
                  and add it to the tour. Repeat this process until all points 
                  have been colored black. Lastly, add the starting point to the 
                  tour again, thus making the tour<A name=IXTR3-1></A> 
                  complete.<A name=IXTR3-2></A></P>                  <UL></UL></TD></TR></TBODY></TABLE>
            <HR SIZE=1>

            <TABLE cellSpacing=0 cellPadding=2 width="100%" border=0>
              <TBODY>
              <TR>
              <TR>
                <TD class=v2 vAlign=top align=right>&nbsp; <A accessKey=2 
                  href="ch01-2-fm2xml.html"><IMG 
                  height=16 src="image/btn_prev.gif" width=56 align=absMiddle 
                  border=0></A> &nbsp; <A accessKey=1 
                  href="ch01-10-fm2xml.html"><IMG 
                  height=16 src="image/btn_next.gif" width=41 align=absMiddle 
                  border=0></A></TD></TR></TBODY></TABLE>
            <TABLE cellSpacing=0 cellPadding=0 width="100%" border=0>
              <TBODY>
              <TR>
                <TD vAlign=top align=right><A class=v1 
                  href="#toppage">Top</A></TD></TR></TBODY></TABLE>
            </TD></TR></TBODY></TABLE></TD>
</BODY></HTML>
