<HTML><HEAD><TITLE>ch14-59-fm2xml</TITLE>
<META http-equiv=Content-Type content="text/html; charset=windows-1252"><LINK 
href="image/style.css" type=text/css rel=STYLESHEET><LINK 
href="image/docsafari.css" type=text/css rel=STYLESHEET>

<META content="MSHTML 6.00.2800.1141" name=GENERATOR></HEAD>
<BODY leftMargin=0 topMargin=0 marginheight="0" marginwidth="0"><A 
name=toppage></A><SPAN class=v2></SPAN>
<TABLE cellSpacing=0 cellPadding=0 width="100%" border=0>
  <TBODY>
  <TR vAlign=top>
    <TD align=middle>
      <TABLE width="95%">
        <TBODY>
        <TR>
          <TD class=v2 align=left>
            <HR SIZE=1>

            <TABLE cellSpacing=0 cellPadding=5 width="100%" border=0>
              <TBODY>
              <TR>
                <TD vAlign=top width=76 rowSpan=4><A 
                  ><IMG 
                  height=100 src="image/masteralgoc_xs.gif" width=76 
                  border=0></A></TD>
                <TD class=v2 vAlign=top><A class=t1 
                  >Mastering 
                  Algorithms with C</A><BR>By Kyle&nbsp;Loudon<BR>Slots : 
                1<BR></TD></TR>
              <TR>
                <TD class=v1><A class=v1 
                  href="table.html">Table 
                  of Contents</A></TD></TR>
              <TR>
                <TD></TD></TR>
              <TR>
                <TD class=t1 vAlign=bottom>Chapter 14.&nbsp; Data 
                Compression</TD></TR></TBODY></TABLE>
            <HR SIZE=1>
            <TABLE cellSpacing=0 cellPadding=2 width="100%" border=0>
              <TBODY>
              <TR>
              <TR>
                <TD class=v2 vAlign=top align=center>&nbsp; <A accessKey=2 
                  href="ch14-56-fm2xml.html"><IMG 
                  height=16 src="image/btn_prev.gif" width=56 
                  align=left border=0></A> &nbsp; <A  
href="table.html" align=center> Content </A>	<A accessKey=1                  href="ch14-60-fm2xml.html"><IMG 
                  height=16 src="image/btn_next.gif" width=41 
                  align=right border=0></A></TD></TR></TBODY></TABLE>
            <BR>
            <TABLE cellSpacing=0 cellPadding=0 width="100%" border=0>
              <TBODY>
              <TR>
                <TD vAlign=top><A name=ch14-59-fm2xml></A>
                  <H3 class=docSection1Title>14.11 Questions and Answers</H3>
                  <P class=docText><A name=IXT-14-314697></A><SPAN 
                  class=docEmphBold>Q:</SPAN> There are certain cases where 
                  compressing data may generate poor results. When might we 
                  encounter this with Huffman coding?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> Effective 
                  compression with Huffman coding depends on symbols occurring 
                  in the data at varying frequencies. If all possible symbols 
                  occur at nearly the same frequency, poor compression results. 
                  Huffman coding also performs poorly when used to compress 
                  small amounts of data. In this case, the space required by the 
                  table in the header negates the compression achieved in the 
                  data. Fortunately, these limitations are not normally a 
                  problem because the symbols in most data are not uniformly 
                  distributed, and we are usually not interested in compressing 
                  small amounts of data.</P>
                  <P class=docText><A name=IXT-14-314698></A><SPAN 
                  class=docEmphBold>Q:</SPAN> Just as with Huffman coding, there 
                  are certain cases in which LZ77 achieves poor compression. 
                  What are some of these cases?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> Effective 
                  compression with LZ77 depends on being able to encode many 
                  sequences of symbols using phrase tokens. If we generate a 
                  large number of symbol tokens and only a few phrase tokens 
                  representing predominantly short phrases, poor compression 
                  results. An excessive number of symbol tokens may even cause 
                  the compressed data to be larger than the original data 
                  itself. This occurs when the sliding window is made too small 
                  to take advantage of recurring phrases effectively.</P>
                  <P class=docText><A name=IXT-14-314699></A><SPAN 
                  class=docEmphBold>Q:</SPAN> In the implementation of both 
                  Huffman coding and LZ77 presented in this chapter, the end of 
                  the compressed data is recognized by counting symbols. This 
                  means we must store a symbol count along with the compressed 
                  data itself. What is another approach to recognizing the end 
                  of the data? What impact would this have on each 
                  implementation?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> When 
                  uncompressing data, we must have a way to determine exactly 
                  where the data ends. An alternative to storing a symbol count 
                  is to encode a special end-of-data symbol. In the 
                  implementations in this chapter, this would mean encoding 257 
                  symbols instead of 256. To account for this with Huffman 
                  coding, we need only make the symbol member of the 
                  <TT><I>HuffNode</I></TT> structure a short integer instead of 
                  an unsigned character. Thus, the size of the compressed data 
                  is affected very little. On the other hand, in the 
                  implementation of LZ77, without substantial changes to the way 
                  we interpret tokens, we would need to store an extra bit with 
                  each token to represent the 257 possible symbols. Thus, the 
                  size of the compressed data would increase, making this method 
                  less effective than simply counting symbols.</P>
                  <P class=docText><A name=IXT-14-314700></A><A 
                  name=IXT-14-314701></A><SPAN class=docEmphBold>Q:</SPAN> With 
                  LZ77, what factors must be balanced in selecting the size of 
                  the sliding window? What factors must be balanced in selecting 
                  the size of the look-ahead buffer?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> Recall that 
                  the implementation of LZ77 presented in this chapter used a 
                  sliding window 4K (4096 bytes) in size and a look-ahead buffer 
                  of 32 bytes, which are common choices. The size of the sliding 
                  window determines how far back in the data we search for 
                  matching phrases. Generally, it is a good idea to search quite 
                  far back to allow a good opportunity for matches. However, we 
                  must balance this against the time it takes to search through 
                  the sliding window. Also, we must balance this against the 
                  space penalty of using more bits for offsets in phrase tokens. 
                  The size we choose for the look-ahead buffer determines the 
                  maximum length of phrases we can match. If the data has many 
                  long phrases that are duplicated, choosing a buffer size that 
                  is too small results in multiple phrase tokens where we might 
                  otherwise get just one. However, we must balance this against 
                  the space penalty of using more bits for lengths in phrase 
                  tokens.</P>
                  <P class=docText><A name=IXT-14-314702></A><SPAN 
                  class=docEmphBold>Q:</SPAN> In Huffman coding, how might we 
                  decrease the space required by the header at the front of 
                  compressed data? Are there any problems associated with 
                  this?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> Recall that 
                  in the implementation of Huffman coding presented in this 
                  chapter a header was prepended to the compressed data. This 
                  header contained a table of 256 entries, one entry for each 
                  possible symbol. If several symbols have frequencies of 0, 
                  this is somewhat wasteful. For example, when compressing ASCII 
                  text, many symbols are not used, so their frequencies are 0. A 
                  better approach to storing the table in this case is to use 
                  <SPAN class=docEmphasis>count runs</SPAN><A 
                  name=IXT-14-314703></A>. A count run consists of the value of 
                  a starting symbol <SPAN class=docEmphasis>c</SPAN> followed by 
                  a length <SPAN class=docEmphasis>l</SPAN>. It tells us that 
                  the next <SPAN class=docEmphasis>l</SPAN> entries in the table 
                  will be entries for the symbols <SPAN 
                  class=docEmphasis>c</SPAN>, <SPAN class=docEmphasis>c</SPAN> + 
                  1, . . ., <SPAN class=docEmphasis>c</SPAN> + <SPAN 
                  class=docEmphasis>l</SPAN> - 1. In many cases, this reduces 
                  the size of the table. However, when the table is nearly full 
                  to begin with, it actually increases the table size 
                  slightly.</P>
                  <P class=docText><A name=IXT-14-314704></A><SPAN 
                  class=docEmphBold>Q:</SPAN> One of the most costly aspects of 
                  LZ77 is scanning the sliding window for matching phrases. How 
                  can we improve the performance of this?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> LZ77 looks 
                  for matching phrases by comparing portions of the sliding 
                  window to portions of the look-ahead buffer essentially symbol 
                  by symbol. A more effective approach is to replace the sliding 
                  window with some type of data structure for efficient 
                  searching. For example, we might use a hash table (see <A 
                  class=docLink 
                  href="ch08-1-fm2xml.html#ch08-1-fm2xml">Chapter 
                  8</A>) or a binary search tree (see <A class=docLink 
                  href="ch09-1-fm2xml.html#ch09-1-fm2xml">Chapter 
                  9</A>) to store phrases encountered earlier. In fact, this is 
                  the approach employed by several more efficient variations of 
                  LZ77 (see the related topics at the end of the chapter).</P>
                  <P class=docText><A name=IXT-14-314705></A><A 
                  name=IXT-14-314706></A><SPAN class=docEmphBold>Q:</SPAN> 
                  Considering the performance differences and compression 
                  normally achieved by Huffman coding and LZ77, when might we 
                  use one over the other?</P>
                  <P class=docText><SPAN class=docEmphBold>A:</SPAN> LZ77 
                  generally results in better compression than Huffman coding, 
                  but with a significant performance penalty during the 
                  compression process. One situation in which this might not 
                  pose a problem is the distribution of large software packages. 
                  LZ77 works well here because the data only needs to be 
                  compressed once (at the production facility), and clients 
                  benefit from the considerably faster operation of 
                  uncompressing the data. On the other hand, suppose we are 
                  sending large amounts of data across a network interactively 
                  and would like to compress it before each transmission. In 
                  this case, for every transmission, we must compress data on 
                  one end of the connection and uncompress it on the other. 
                  Therefore, it is best to use Huffman coding. We may not 
                  achieve as much compression as with LZ77, but compressing and 
                  uncompressing together are faster.</P>
                  <UL></UL></TD></TR></TBODY></TABLE>
            <HR SIZE=1>

            <TABLE cellSpacing=0 cellPadding=2 width="100%" border=0>
              <TBODY>
              <TR>
              <TR>
                <TD class=v2 vAlign=top align=right>&nbsp; <A accessKey=2 
                  href="ch14-56-fm2xml.html"><IMG 
                  height=16 src="image/btn_prev.gif" width=56 
                  align=absMiddle border=0></A> &nbsp; <A accessKey=1 
                  href="ch14-60-fm2xml.html"><IMG 
                  height=16 src="image/btn_next.gif" width=41 
                  align=absMiddle border=0></A></TD></TR></TBODY></TABLE>
            <TABLE cellSpacing=0 cellPadding=0 width="100%" border=0>
              <TBODY>
              <TR>
                <TD vAlign=top align=right><A class=v1 
                  href="#toppage">Top</A></TD></TR></TBODY></TABLE>
            </TD></TR></TBODY></TABLE></TD>
</BODY></HTML>
