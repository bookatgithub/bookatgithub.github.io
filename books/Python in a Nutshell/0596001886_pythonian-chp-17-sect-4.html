<html><head>
<META http-equiv="Content-Type" content="text/html">
<!--SafClassName="docSection1Title"--><!--SafTocEntry="17.4 Optimization"-->
<link rel="STYLESHEET" type="text/css" href="FILES/style.css">
<link rel="STYLESHEET" type="text/css" href="FILES/docsafari.css">
<style type="text/css">	.tt1    {font-size: 10pt;}</style>
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
	<a href="0596001886_pythonian-chp-17-sect-3.html"><img src="FILES/previous.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
	<a href="0596001886_pythonian-part-4.html"><img src="FILES/next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><A NAME="pythonian-CHP-17-SECT-4"></A>
<H3 class="docSection1Title">17.4 Optimization</H3>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7927"></A>"First
make it work. Then make it right. Then make it
fast." This quotation, often with slight variations,
is widely known as the golden rule of programming. As far as
I've been able to ascertain, the quotation is
attributed to Kent Beck, who credits his father with it. Being widely
known makes the principle no less important, particularly because
it's more honored in the breach than in the
observance. A negative form, slightly exaggerated for emphasis, is in
a quotation by Don Knuth: "Premature optimization is
the root of all evil in programming."</P>

<P class="docText">Optimization is premature if your code is not working yet. First make
it work. Optimization is also premature if your code is working but
you are not satisfied with the overall architecture and design.
Remedy structural flaws before worrying about optimization: first
make it work, then make it right. These first two steps are not
optional—working, well-architected code is always a must.</P>

<P class="docText">In contrast, you don't always need to make it fast.
Benchmarks may show that your code's performance is
already acceptable after the first two steps. When performance is not
acceptable, profiling often shows that all performance issues are in
a small subset, perhaps 10% to 20% of the code where your program
spends 80% or 90% of the time. Such performance-crucial regions of
your code are also known as its <I>bottlenecks</I>, or
<I>hot spots</I>. It's a waste of
effort to optimize large portions of code that account for, say, 10%
of your program's running time. Even if you made
that part run 10 times as fast (a rare feat), your
program's overall runtime would only decrease by 9%,
a speedup no user will even notice. If optimization is needed, focus
your efforts where they'll matter, on bottlenecks.
You can optimize bottlenecks while keeping your code 100% pure
Python. In some cases, you can resort to recoding some computational
bottlenecks as Python extensions, potentially gaining even better
performance.</P>

<A NAME="pythonian-CHP-17-SECT-4.1"></A>
<H4 class="docSection2Title">17.4.1 Developing a Fast-Enough Python Application</H4>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7928"></A>Start by designing,
coding, and testing your application in Python, often using some
already available extension modules. This takes much less time than
it would take with a classic compiled language. Then benchmark the
application to find out if the resulting code is fast enough. Often
it is, and you're done—congratulations!</P>

<P class="docText">Since much of Python itself is coded in highly optimized C, as are
many of its standard and extension modules, your application may even
turn out to be already faster than typical C code. However, if the
application is too slow, you need to re-examine your algorithms and
data structures. Check for bottlenecks due to application
architecture, network traffic, database access, and operating system
interactions. For typical applications, each of these factors is more
likely than language choice to cause slowdowns. Tinkering with
large-scale architectural aspects can often speed up an application
dramatically, and Python is an excellent medium for such
experimentation.</P>

<P class="docText">If your program is still too slow, you should profile it to find out
where the time is going. Applications often exhibit computational
bottlenecks—small areas of the source code, generally between
10% and 20%, which account for 80% or more of the running time. You
can now optimize the bottlenecks, applying the techniques suggested
in the rest of this chapter.</P>

<P class="docText">If normal Python-level optimizations still leave some outstanding
computational bottlenecks, you can recode them as Python extension
modules, as covered in <A class="docLink" HREF="0596001886_pythonian-chp-24.html#pythonian-CHP-24">Chapter 24</A>. In the end, your
application will run at roughly the same speed as if you had coded it
all in C, C++, or Fortran—or faster, when large-scale
experimentation has let you find a better architecture. Your overall
programming productivity with this process is not much less than if
you coded everything in Python. Future changes and maintenance are
easy, since you use Python to express the overall structure of the
program, and lower-level, harder-to-maintain languages only for a few
specific computational bottlenecks.</P>

<P class="docText">As you produce applications in a given area according to this
process, you will accumulate a library of reusable Python extension
modules for that area. You therefore become more and more productive
at developing other fast-running Python applications in the same
field.</P>

<P class="docText">Even if external constraints should eventually force you to recode
the whole application in a lower-level language,
you're still better off for having started in
Python. Rapid prototyping has long been acknowledged as the best way
to get a software architecture just right. A working prototype lets
you check that you have identified the right problems and taken the
best path to their solution. A prototype affords the kind of
large-scale architectural experimentation that can make a real
difference to performance. Starting your prototype with Python allows
a gradual migration to other languages by way of extension modules.
The application remains in a fully functional and testable state at
each stage. This ensures against the risk of compromising a
design's architectural integrity in the coding
stage. The resulting software is likely to be faster and more robust
than if all of the coding had been lower-level from the start, and
your productivity, while not quite as good as with a pure Python or
mostly Python application, is still better than if you had been
coding at a lower level throughout.</P>


<A NAME="pythonian-CHP-17-SECT-4.2"></A>
<H4 class="docSection2Title">17.4.2 Benchmarking</H4>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7929"></A>
<A NAME="pythonian-CHP-17-ITERM-7930"></A>Benchmarking is
similar to system testing: both activities are like running the
program as it's meant to be run for production
purposes. In both cases, you need to have at least some subset of the
program's intended functionality working, and you
need to use known, reproducible inputs. In the case of benchmarking,
you don't need to capture and check your
program's output: since you make it work and make it
right before you make it fast, you are already confident about your
program's correctness by the time you benchmark it.
You do need inputs that are representative of typical system
operations, particularly those that may be most challenging for your
program's performance. If your program performs
several kinds of operations, make sure you run one or two benchmarks
for each different kind of operation.</P>

<P class="docText">Elapsed time as measured by your wristwatch is probably precise
enough to benchmark most programs. Programs with hard real-time
constraints are obviously another matter, but they have needs very
different from those of normal programs in most respects. A 5% or 10%
difference in performance, except for programs with very peculiar
constraints, makes no practical difference to a
program's real-life usability.</P>

<P class="docText">When you benchmark "toy" programs
in order to help you choose an algorithm or data structure, you may
need more precision. In that case, you may want to set up an
artificial environment, with a machine as quiescent as possible, no
network activity, and accurate timekeeping. Python time operations
are covered in <A class="docLink" HREF="0596001886_pythonian-chp-12.html#pythonian-CHP-12">Chapter 12</A>. The benchmarking
discussed in this section is a different kind of issue: an
approximation of real-life program operation, for the sole purpose of
checking whether the program's performance at each
task is acceptable, before embarking on profiling and other
optimization activities. For such system benchmarking, a situation
that approximates the program's normal operating
conditions is best, and accuracy in timing is not particularly
important.</P>


<A NAME="pythonian-CHP-17-SECT-4.3"></A>
<H4 class="docSection2Title">17.4.3 Large-Scale Optimization</H4>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7931"></A>The
aspects of your program that are most important for performance are
large-scale ones: choice of algorithms, overall architecture, and
choice of data
structures.<A NAME="pythonian-CHP-17-ITERM-7932"></A></P>

<P class="docText">The performance issues that you must almost always take into account
are those connected with the traditional big-O notation of computer
science. Informally, if you call <TT>N</TT> the input size
of an algorithm, big-O notation expresses algorithm performance, for
large values of <TT>N</TT>, as proportional to a function
of <TT>N</TT> (in precise computer science lingo, this
should actually be called big-Theta, but in practical use programmers
in the field call this big-O). An <TT>O(N)</TT> algorithm
is one where, for large enough <TT>N</TT>, handling twice
as much data takes about twice as much time, three times as much data
three times as much time, and so on, growing linearly with
<TT>N</TT>. An
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
algorithm is one where, for large enough <TT>N</TT>,
handling twice as much data takes about four times as much time,
three times as much data nine times as much time, and so on, growing
with <TT>N</TT> squared.</P>

<P class="docText">You will find more information on big-O notation, as well as other
issues about algorithms and their complexity, in any good book about
algorithms and data structures. Unfortunately, at the time of this
writing, there aren't yet any such books using
Python. However, if you are at least moderately familiar with C, I
can recommend <span class="docEmphasis">Mastering</span>
<span class="docEmphasis">Algorithms</span> <span class="docEmphasis">with</span>
<span class="docEmphasis">C</span>, by Kyle Loudon (O'Reilly).</P>

<P class="docText">To understand the practical importance of big-O considerations in
your programs, consider two different ways to accept all items from
an input iterator and accumulate them into a list in reverse order:</P>

<PRE>def slow(it):
    result = [  ]
    for item in it: result.insert(0, item)
    return result

def fast(it):
    result = [  ]
    for item in it: result.append(item)
    result.reverse(  )
    return result</PRE>

<P class="docText">We could express each of these functions more concisely, but the key
difference is best appreciated by presenting them in these elementary
terms. Function <TT>slow</TT> builds the result list by
inserting each input item before all previously received ones.
Function <TT>fast</TT> appends each input item after all
previously received ones, then reverses the result list just before
returning it. Intuitively, one might think that the final reversing
represents extra work, and therefore <TT>slow</TT> should
be faster than <TT>fast</TT>. But that's
not the way things work out.</P>

<P class="docText">Each call to <TT>result.append</TT> takes roughly the same
amount of time, independent of how many items are already in list
<TT>result</TT>, since there is always a free slot for an
extra item at the end of the list. The <TT>for</TT> loop in
function <TT>fast</TT> executes <TT>N</TT> times
to receive <TT>N</TT> items. Since each iteration of the
loop takes a constant time, overall loop time is
<TT>O(N)</TT>. <TT>result.reverse</TT> also takes
time <TT>O(N)</TT>, as it is directly proportional to the
total number of items. Thus, the total running time of
<TT>fast</TT> is also <TT>O(N)</TT>. (If you
don't understand why a sum of two quantities, each
<TT>O(N)</TT>, is also <TT>O(N)</TT>, consider
that the sum of two linear functions of <TT>N</TT> is also
a linear function of <TT>N</TT>).</P>

<P class="docText">In contrast, each call to <TT>result.insert</TT> must make
space at slot <TT>0</TT> for the new item to insert, by
moving all items that are already in list <TT>result</TT>
forward one slot. That takes a time proportional to the number of
items that are already in the list. The overall amount of time to
receive <TT>N</TT> items is therefore proportional to
<TT>1+2+3+...N-1</TT>, a sum whose value is
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>.
Therefore, the total running time of <TT>slow</TT> is also
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>.</P>

<P class="docText">It's almost always worth replacing an
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
solution with an <TT>O(N)</TT> one, unless you can somehow
assign rigorous limits to the input size <TT>N</TT>. If
<TT>N</TT> can grow without bounds, the
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
solution will inevitably turn out to be disastrously slower than the
<TT>O(N)</TT> one for large enough values of
<TT>N</TT>, no matter what the proportionality constants in
each case may be (and no matter what profiling tells you). Unless you
have other
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
or even worse bottlenecks elsewhere that you cannot eliminate, a part
of the program that is
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
will inevitably turn into the program's bottleneck
and dominate runtime for large enough values of <TT>N</TT>.
Do yourself a favor and watch out for the big O: all other
performance issues, in comparison, are insignificant.</P>

<P class="docText">Incidentally, function <TT>fast</TT> can be made
substantially faster by expressing it in more idiomatic Python. Just
replace the first two lines with the single statement:</P>

<PRE>result = list(it)</PRE>

<P class="docText">This change does not affect
<TT>fast</TT>'s big-O character
(<TT>fast</TT> is still <TT>O(N)</TT> after the
change), but does speed things up by a constant factor. Often, in
Python, the simplest, clearest, most idiomatic way to express
something is also the fastest.</P>

<P class="docText">Choosing algorithms with good big-O characteristics is roughly the
same task in Python as in any other language. You just need a few
indications about the big-O performance of Python's
elementary building blocks.</P>

<A NAME="pythonian-CHP-17-SECT-4.3.1"></A>
<H5 class="docSection3Title">17.4.3.1 List operations</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7933"></A>
<A NAME="pythonian-CHP-17-ITERM-7934"></A>Python lists are internally implemented
with vectors (also known as arrays), not with linked lists. This
fundamental implementation choice determines just about all
performance characteristics of Python lists, in big-O terms.</P>

<P class="docText">Chaining two lists of length <TT>N1</TT> and
<TT>N2</TT> is <TT>O(N1+N2)</TT>. Multiplying a
list of length <TT>N</TT> by the number
<TT>M</TT> is <TT>O(N*M)</TT>. Accessing or
rebinding any list item is <TT>O(1)</TT> (also known as
constant time, meaning that the time taken does not depend on how
many items are in the list). <TT>len( )</TT> on a list is
also <TT>O(1)</TT>. Accessing any slice of length
<TT>M</TT> is <TT>O(M)</TT>. Rebinding a slice of
length <TT>M</TT> with one of identical length is also
<TT>O(M)</TT>. Rebinding a slice of length
<TT>M1</TT> with one of different length
<TT>M2</TT> is <TT>O(M1+M2+N1)</TT>, where
<TT>N1</TT> is the number of items after the slice in the
target list.</P>

<P class="docText">Most list methods, as shown way back in <A class="docLink" HREF="0596001886_pythonian-chp-4-sect-6.html#pythonian-CHP-4-TABLE-3">Table 4-3</A>,
are equivalent to slice rebindings and have the same big-O
performance. Methods <TT>count</TT>,
<TT>index</TT>, <TT>remove</TT>, and
<TT>reverse</TT>, and operator <TT>in</TT>, are
<TT>O(N)</TT>. Method <TT>sort</TT> is generally
<TT>O(N*log(N))</TT>, but has optimizations that let it be
<TT>O(N)</TT> in some important special cases, like when
the list is already sorted, reverse sorted, or sorted except for a
few items at the end (in Python 2.3, <TT>sort</TT> will
also be <TT>O(N)</TT> in a few more important special
cases). <TT>range(a,b,c)</TT> is
<TT>O((b-a)/c)</TT>. <TT>xrange(a,b,c)</TT> is
<TT>O(1)</TT>, but looping on
<TT>xrange</TT>'s result is
<TT>O((b-a)/c)</TT>.</P>



<A NAME="pythonian-CHP-17-SECT-4.3.2"></A>
<H5 class="docSection3Title">17.4.3.2 String operations</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7935"></A>
<A NAME="pythonian-CHP-17-ITERM-7936"></A>Most methods on a string of length
<TT>N</TT> (be it plain or Unicode) are
<TT>O(N)</TT>. <TT>len(astring)</TT> is
<TT>O(1)</TT>. The fastest way to produce a copy of a
string with transliterations and/or removal of specified characters
is the string's method <TT>translate</TT>.
The most practically important big-O consideration involving strings
is covered in <A class="docLink" HREF="#pythonian-CHP-17-SECT-4.5">Section 17.4.5</A> later in
this chapter.</P>



<A NAME="pythonian-CHP-17-SECT-4.3.3"></A>
<H5 class="docSection3Title">17.4.3.3 Dictionary operations</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7937"></A>
<A NAME="pythonian-CHP-17-ITERM-7938"></A>Python dictionaries are
internally implemented with hash tables. This fundamental
implementation choice determines just about all performance
characteristics of Python dictionaries, in big-O terms.</P>

<P class="docText">Accessing, rebinding, adding, or removing a dictionary item is
generally <TT>O(1)</TT>, as are methods
<TT>has_key</TT>, <TT>get</TT>,
<TT>setdefault</TT>, and <TT>popitem</TT>, and
operator <TT>in</TT>.
<TT><I>d1</I></TT><TT>.update(</TT><TT><I>d2</I></TT><TT>)</TT>
is
<TT>O(len(</TT><TT><I>d2</I></TT><TT>))</TT>.
<TT>len(</TT><TT><I>adict</I></TT><TT>)</TT>
is <TT>O(1)</TT>. Methods <TT>keys</TT>,
<TT>items</TT>, and <TT>values</TT> are
<TT>O(N)</TT>. Methods <TT>iterkeys</TT>,
<TT>iteritems</TT>, and <TT>itervalues</TT> are
<TT>O(1)</TT>, but looping on the iterators that those
methods return is <TT>O(N)</TT>. When the keys in a
dictionary are instances of classes that define <TT>_ _hash_
_</TT> and equality comparison methods, dictionary performance
is of course affected by those methods. The indications presented in
this paragraph are valid only if both hashing and equality comparison
are <TT>O(1)</TT>.<A NAME="pythonian-CHP-17-ITERM-7939"></A></P>



<A NAME="pythonian-CHP-17-SECT-4.4"></A>
<H4 class="docSection2Title">17.4.4 Profiling</H4>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7940"></A>Most
programs have hot spots (i.e., regions of source code that account
for most of the time elapsed during a program run).
Don't try to guess where your
program's hot spots are;
programmers' intuition is notoriously unreliable in
this field. Use module <TT>profile</TT> to collect profile
data over one or more runs of your program, with known inputs. Then,
use module <TT>pstats</TT> to collate, interpret, and
display that profile data. To gain accuracy, you can calibrate the
Python profiler for your machine (i.e., determine what overhead
profiling incurs on your machine). Module <TT>profile</TT>
can then subtract this overhead from the times it measures so that
the profile data you collect is closer to reality.</P>

<A NAME="pythonian-CHP-17-SECT-4.4.1"></A>
<H5 class="docSection3Title">17.4.4.1 The profile module</H5>

<P class="docText">The <TT>profile</TT> module supplies one function you will
often use.</P>

<A NAME="ch17-77076"></A><A NAME="pythonian-CHP-17-ITERM-7941"></A><A NAME="pythonian-CHP-17-ITERM-7942"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>run</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre>run(<TT><I>code</I></TT>,<TT><I>filename</I></TT>=None)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText"><TT><I>code</I></TT> is a string such as you could use
with statement <TT>exec</TT>, normally a call to the main
function of the program you're profiling.
<TT><I>filename</I></TT> is the path of a file that
<TT>run</TT> creates or rewrites with profile data. Usually
you call <TT>run</TT> a few times, specifying different
filenames, and possibly different arguments to your
program's main function, in order to exercise
various program parts proportionately. Then, you use module
<TT>pstats</TT> to display collated results.</P>
<P class="docText">You may call <TT>run</TT> without a
<TT><I>filename</I></TT> to obtain a summary report,
similar to the one module <TT>pstats</TT> could give you,
directly on standard output. However, this approach gives no control
at all over output format, nor does it offer any way to consolidate
several runs into one report. In practice, you rarely use this
feature: collecting profile data into files is generally preferable.</P>

<P class="docText">Module <TT>profile</TT> also supplies class
<TT>Profile</TT>, mentioned in the next section. By
instantiating <TT>Profile</TT> directly, you can access
advanced functionality, such as the ability to run a command in
specified local and global dictionaries. I do not cover such advanced
functionality of class <TT>profile.Profile</TT> further in
this book.</P>



<A NAME="pythonian-CHP-17-SECT-4.4.2"></A>
<H5 class="docSection3Title">17.4.4.2 Calibration</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7943"></A>
<A NAME="pythonian-CHP-17-ITERM-7944"></A>To calibrate <TT>profile</TT>
for your machine, you need to use class <TT>Profile</TT>,
which module <TT>profile</TT> supplies and internally uses
in function <TT>run</TT>. An instance
<TT><I>p</I></TT> of <TT>Profile</TT> supplies
one method you use for calibration.</P>

<A NAME="ch17-77078"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>calibrate</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre><TT><I>p</I></TT>.calibrate(<TT><I>N</I></TT>)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText">Loops <TT><I>N</I></TT> times, then returns a number that
is the profiling overhead per call on your machine.
<TT><I>N</I></TT> must be large if your machine is fast.
Call <TT><I>p</I></TT><TT>.calibrate(10000)</TT>
a few times and check that the various numbers it returns are very
close to each other, then pick the smallest one of them. If the
numbers exhibit substantial variation, try again with larger values
of <TT><I>N</I></TT>.</P>
<P class="docText">The calibration procedure can be time consuming. However, you need to
perform it only once, repeating it only when you make changes that
could alter your machine's characteristics, such as
applying patches to your operating system, adding memory, or changing
Python version. Once you know your machine's
overhead, you can tell <TT>profile</TT> about it each time
you import it, right before using <TT>profile.run</TT>. The
simplest way to do this is as follows:</P>
<PRE>import profile
profile.Profile.bias = ...<TT><I>the overhead you measured</I></TT>...
profile.run('main(  )', 'somefile')</PRE>



<A NAME="pythonian-CHP-17-SECT-4.4.3"></A>
<H5 class="docSection3Title">17.4.4.3 The pstats module</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7945"></A> <A NAME="pythonian-CHP-17-ITERM-7946"></A> <A NAME="pythonian-CHP-17-ITERM-7947"></A>The <TT>pstats</TT> module
supplies a single class, <TT>Stats</TT>, that you use to
analyze, consolidate, and report on the profile data contained in one
or more files written by function <TT>profile.run</TT>.</P>

<A NAME="ch17-77080"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>Stats</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre>class Stats(<TT><I>filename</I></TT>,*<TT><I>filenames</I></TT>)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText">Instantiates <TT>Stats</TT> with one or more filenames of
files of profile data written by function
<TT>profile.run</TT>.</P>

<P class="docText">An instance <TT><I>s</I></TT> of class
<TT>Stats</TT> provides methods to add profile data and
sort and output results. Each method returns
<TT><I>s</I></TT>, so you can chain several calls in the
same expression. <TT><I>s</I></TT>'s main
methods are as follows.</P>

<A NAME="ch17-77081"></A><A NAME="pythonian-CHP-17-ITERM-7948"></A><A NAME="pythonian-CHP-17-ITERM-7949"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>add</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre><TT><I>s</I></TT>.add(<TT><I>filename</I></TT>)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7948"></A> <A NAME="pythonian-CHP-17-ITERM-7949"></A>Adds
another file of profile data to the set that
<TT><I>s</I></TT> is holding for analysis.</P>

<A NAME="ch17-77082"></A><A NAME="pythonian-CHP-17-ITERM-7950"></A><A NAME="pythonian-CHP-17-ITERM-7951"></A><A NAME="pythonian-CHP-17-ITERM-7952"></A><A NAME="pythonian-CHP-17-ITERM-7953"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>print_callees, print_callers</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre><TT><I>s</I></TT>


.print_callees(*<TT><I>restrictions</I></TT>)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText">Outputs the list of functions in
<TT><I>s</I></TT>'s profile data, sorted
according to the latest call to
<TT><I>s</I></TT><TT>.sort_stats</TT>, and
subject to the given restrictions, if any. You can call each printing
method with zero or more <TT><I>restrictions</I></TT>,
which are applied one after the other, in order, to reduce the number
of output lines. A restriction that is an integer
<TT><I>n</I></TT> limits the output to the first
<TT><I>n</I></TT> lines. A restriction that is a
floating-point value <TT><I>f</I></TT> between
<TT>0.0</TT> and <TT>1.0</TT> limits the output
to a fraction <TT><I>f</I></TT> of the lines. A
restriction that is a string is compiled as a regular expression (as
covered in <A class="docLink" HREF="0596001886_pythonian-chp-9.html#pythonian-CHP-9">Chapter 9</A>); only lines satisfying a
<TT>search</TT> method call on the regular expressions are
output. Restrictions are cumulative. For example,
<TT><I>s</I></TT><TT>.print_calls(10,0.5)</TT>
outputs the first 5 lines (half of 10). Output restrictions apply
only after the summary and header lines: summary and header are
output unconditionally.</P>
<P class="docText">Each function <TT><I>f</I></TT> that is output is
accompanied by the list of
<TT><I>f</I></TT>'s callers (the
functions that called <TT><I>f</I></TT>) or
<TT><I>f</I></TT>'s callees (the
functions that <TT><I>f</I></TT> called) according to the
name of the method.</P>

<A NAME="ch17-77083"></A><A NAME="pythonian-CHP-17-ITERM-7954"></A><A NAME="pythonian-CHP-17-ITERM-7955"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>print_stats
</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre><TT><I>s</I></TT>.print_stats(*<TT><I>restrictions</I></TT>)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText">Outputs statistics about
<TT><I>s</I></TT>'s profile data, sorted
according to the latest call to
<TT><I>s</I></TT><TT>.sort_stats</TT>, and
subject to the given restrictions, if any, as covered in
<TT>print_callees</TT>. After a few summary lines (date and
time on which profile data was collected, number of function calls,
and sort criteria used), the output, absent restrictions, is one line
per function, with six fields per line, labeled in a header line. For
each function <TT><I>f</I></TT>,
<TT>print_stats</TT> outputs six fields:</P><span style="font-weight:bold"><OL class="docList" TYPE="1">
<LI><span style="font-weight:normal"><P class="docList">Total number of calls to function <TT><I>f</I></TT></P></span></LI>
<LI><span style="font-weight:normal"><P class="docList">Total time spent in function <TT><I>f</I></TT>, exclusive
of other functions that <TT><I>f</I></TT> called</P></span></LI>
<LI><span style="font-weight:normal"><P class="docList">Total time per call (i.e., field <TT>2</TT> divided by
field <TT>1</TT>)</P></span></LI>
<LI><span style="font-weight:normal"><P class="docList">Cumulative time spent in function <TT><I>f</I></TT>, and
in all functions directly or indirectly called from
<TT><I>f</I></TT></P></span></LI>
<LI><span style="font-weight:normal"><P class="docList">Cumulative time per call (i.e., field <TT>4</TT> divided by
field <TT>1</TT>)</P></span></LI>
<LI><span style="font-weight:normal"><P class="docList">The name of function <TT><I>f</I></TT></P></span></LI>
</OL></span>

<A NAME="ch17-77084"></A><A NAME="pythonian-CHP-17-ITERM-7956"></A><A NAME="pythonian-CHP-17-ITERM-7957"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>sort_stats</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre><TT><I>s</I></TT>.sort_stats(<TT><I>key</I></TT>, *<TT><I>keys</I></TT>)</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText">Gives one or more keys (primary first, if more than one) on which to
sort future output. Each key is a string. The sort is descending for
keys indicating times or numbers, alphabetical (ascending) for key
'<TT>nfl</TT>'. The most frequently used keys when calling
<TT>sort_stats</TT> are:</P>
<DL class="docList">
<DT><span class="docPubcolor">'<span class="docPubcolor"><span class="docMonofont">calls</span></span>'</span></DT>
<DD>
<P class="docList">Number of calls to the function (like field <TT>1</TT>
covered in <TT>print_stats</TT>)</P>
</DD>
<DT><span class="docPubcolor">'<span class="docPubcolor"><span class="docMonofont">cumulative</span></span>'</span></DT>
<DD>
<P class="docList">Cumulative time spent in the function and all functions it called
(like field <TT>4</TT> i covered in
<TT>print_stats</TT>)</P>
</DD>
<DT><span class="docPubcolor">'<span class="docPubcolor"><span class="docMonofont">nfl</span></span>'</span></DT>
<DD>
<P class="docList">Name of the function, its module, line number of the function in its
file (like field <TT>6</TT> covered in
<TT>print_stats</TT>)</P>
</DD>
<DT><span class="docPubcolor">'<span class="docPubcolor"><span class="docMonofont">time</span></span>'</span></DT>
<DD>
<P class="docList">Total time spent in the function itself, exclusive of functions it
called (like field <TT>2</TT> covered in
<TT>print_stats</TT>)</P>
</DD>
</DL>

<A NAME="ch17-77085"></A><A NAME="pythonian-CHP-17-ITERM-7958"></A><A NAME="pythonian-CHP-17-ITERM-7959"></A><table width="515" border="0" cellpadding="5">
<tr>
<td align="left"><b><i>strip_dirs</i></b></td>
<td align="right"></td>
</tr>
</table>
<hr width="515" size="3" noshade="true" align="left" color="black">
<table width="515" border="0" cellpadding="5">
<tr>
<td align="left">
<pre><TT><I>s</I></TT>.strip_dirs(  )</pre>
</td>
<td align="right"></td>
</tr>
</table>
<P class="docText">Alters <TT><I>s</I></TT> by stripping directory names from
all the module names that <TT><I>s</I></TT> holds, to make
future output more compact. <TT><I>s</I></TT> is unsorted
after <TT><I>s</I></TT><TT>.strip_dirs( )</TT>,
and therefore you normally call
<TT><I>s</I></TT><TT>.sort_stats</TT> with the
arguments you desire right after calling
<TT><I>s</I></TT><TT>.strip_dirs</TT>.</P>



<A NAME="pythonian-CHP-17-SECT-4.5"></A>
<H4 class="docSection2Title">17.4.5 Small-Scale Optimization</H4>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7960"></A>Fine
tuning of program operations is rarely important. Such tuning may
make a small but meaningful difference in some particularly hot spot,
but hardly ever is it a decisive factor. And yet, such fine tuning,
in the pursuit of mostly irrelevant microefficiencies, is where a
programmer's instincts are likely to lead. It is in
good part because of this that most optimization is premature and
best avoided. The most that can be said in favor of fine tuning is
that, if one idiom is always speedier than another when the
difference is measurable, it's worth getting into
the habit of always using the former and not the latter.</P>

<P class="docText">Most often, in Python, if you do what comes naturally and choose
simplicity and elegance, you end up with code that has good
performance as well as clarity and maintainability. In a few cases,
an approach that may not be intuitive offers performance advantages,
as discussed in the rest of this section.</P>

<P class="docText">The simplest possible optimization is to run your Python programs
using <TT>python</TT> <TT>-O</TT> or
<TT>-OO</TT>. <TT>-OO</TT> makes little direct
difference to performance compared to <TT>-O</TT>, but
<TT>-OO</TT> may save memory, since it removes docstrings
from the bytecode, and memory availability is sometimes (indirectly)
a performance bottleneck. The optimizer is not very powerful in
current releases of Python, but it may still gain you performance
advantages on the order of 10%, sometimes as large as 20%
(potentially even larger, if you make heavy use of
<TT>assert</TT> statements and <TT>if</TT>
<TT>_ _debug_ _</TT>: guards as suggested in <A class="docLink" HREF="0596001886_pythonian-chp-6.html#pythonian-CHP-6">Chapter 6</A>). The best aspect of <TT>-O</TT> is
that it costs nothing—as long as your optimization
isn't premature, of course. <TT>-O</TT>
does impede use of debuggers, such as <TT>pdb</TT>, and may
thus make debugging somewhat harder if your program
isn't fully tested and working correctly. So,
don't use <TT>-O</TT> on a program
you're still developing.</P>

<A NAME="pythonian-CHP-17-SECT-4.5.1"></A>
<H5 class="docSection3Title">17.4.5.1 Building up a string from pieces</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7961"></A>The single Python
anti-idiom that's likeliest to kill your
program's performance, to the point that you should
never use it, is to build up a large string from pieces by looping on
string concatenation statements such as
<TT><I>big_string</I></TT><TT>+=</TT><TT><I>piece</I></TT>.
Since Python strings are immutable, such a concatenation makes Python
free the <TT>M</TT> bytes previously allocated for
<TT><I>big_string</I></TT>, and allocate and fill
<TT>M+K</TT> bytes for the new version. Doing this
repeatedly in a loop, you end up with roughly
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
performance, where <TT>N</TT> is the total number of
characters. More often than not,
<TT>O(N</TT><SUP>2</SUP><TT>)</TT>
performance where <TT>O(N)</TT> is available is a
performance disaster. On some platforms, things may be even bleaker
due to memory fragmentation effects caused by freeing many memory
areas, all of different sizes, and allocating progressively larger
ones.</P>

<P class="docText">To achieve <TT>O(N)</TT> performance, accumulate
intermediate pieces in a list rather than building up the string
piece by piece. Lists, unlike strings, are mutable, so appending to a
list has <TT>O(1)</TT> performance (amortized). Change each
occurrence of
<TT><I>big_string</I></TT><TT>+=</TT><TT><I>piece</I></TT>
into
<TT><I>temp_list</I></TT><TT>.append(</TT><TT><I>piece</I></TT><TT>)</TT>.
Then, when you're done accumulating, use the
following to build your desired string result in
<TT>O(N)</TT> time:</P>

<PRE><TT><I>big_string</I></TT> = ''.join(<TT><I>temp_list</I></TT>)</PRE>

<P class="docText">Other <TT>O(N)</TT> ways to build up big strings are to
concatenate the pieces to an instance of
<TT>array.array('c')</TT>, or to write the pieces to an
instance of <TT>cStringIO.StringIO</TT>.</P>

<P class="docText">In the special case where you want to output the resulting string,
you may gain a further small slice of performance by using
<TT>writelines</TT> on <TT><I>temp_list</I></TT>
(never building <TT><I>big_string</I></TT> in memory).
When feasible (i.e., when you have the output file object open and
available in the loop), it's at least as effective
to perform a <TT>write</TT> call for each
<TT><I>piece</I></TT>, without any accumulation.</P>

<P class="docText">Although not nearly as crucial as <TT>+=</TT> on a big
string in a loop, another case where removing string concatenation
may give a slight performance improvement is when
you're concatenating several values in an
expression:</P>

<PRE>oneway = str(x)+' eggs and '+str(y)+' slices of '+k+' ham'
another = '%s eggs and %s slices of %s ham' % (x, y, k)</PRE>

<P class="docText">Using operator <TT>%</TT> for string formatting is often a
good performance choice.</P>



<A NAME="pythonian-CHP-17-SECT-4.5.2"></A>
<H5 class="docSection3Title">17.4.5.2 Searching and sorting</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7962"></A>Operator
<TT>in</TT>, the most natural tool for searching, is
<TT>O(1)</TT> when the right-hand side operand is a
dictionary, but <TT>O(N)</TT> when the right-hand side
operand is a list. If you need to perform many searches on a
container, you're generally much better off using a
dictionary, rather than a list, as the container. Python dictionaries
are highly optimized for searching and fetching items by key.</P>

<P class="docText">Method <TT>sort</TT> of Python lists is also a highly
optimized and sophisticated tool. You can rely on
<TT>sort</TT>'s performance. Performance
dramatically degrades, however, if you pass <TT>sort</TT> a
custom callable to perform comparisons in order to sort a list based
on anything but built-in comparisons. To satisfy such needs, consider
using the decorate-sort-undecorate (DSU) idiom instead. This idiom
has the following steps:</P>

<DL class="docList">
<DT><I><span class="docPubcolor">decorate</span></I></DT>
<DD>
<P class="docList">Build an auxiliary list <TT>A</TT> where each item is a
tuple made up of the sort keys, ending with the item of the original
list <TT>L</TT> or with the item's index</P>
</DD>
<DT><I><span class="docPubcolor">sort</span></I></DT>
<DD>
<P class="docList">Call <TT>A.sort(  )</TT> without arguments</P>
</DD>
<DT><I><span class="docPubcolor">undecorate</span></I></DT>
<DD>
<P class="docList">Extract the items in order from the now-sorted <TT>A</TT></P>
</DD>
</DL>

<P class="docText">The decorate and undecorate steps are most often handily performed
with list comprehensions. If you need the sort to be in-place, assign
the final sorted list to <TT>L[:]</TT>. Otherwise, DSU
provides a sorted copy, without disturbing the original list
<TT>L</TT>.</P>

<P class="docText">For example, say we have in <TT>L</TT> a large list of
strings, each of at least two words, and we want to sort
<TT>L</TT> in-place by the second word of each string:</P>

<PRE>A = [ (s.split(  )[1], s) for s in L ]
A.sort(  )
L[:] = [ t[1] for t in A ]</PRE>

<P class="docText">This is much faster than passing to <TT>L.sort</TT> a
function that compares two strings by their second words, as in:</P>

<PRE>def cmp2ndword(a, b): return cmp(a.split(  )[1], b.split(  )[1])
L.sort(cmp2ndword)</PRE>

<P class="docText">On a series of benchmarks with Python 2.2 on lists of 10,000 strings,
I measured the DSU version as 7 to 10 times faster than the non-DSU
one.</P>



<A NAME="pythonian-CHP-17-SECT-4.5.3"></A>
<H5 class="docSection3Title">17.4.5.3 Avoiding exec and from ... import *</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7963"></A>
<A NAME="pythonian-CHP-17-ITERM-7964"></A> <A NAME="pythonian-CHP-17-ITERM-7965"></A>If a function contains an
<TT>exec</TT> statement without explicit dictionaries, the
whole function slows down substantially. The presence of such an
<TT>exec</TT> statement forces the Python compiler to avoid
the modest but precious optimizations it normally performs because
such an <TT>exec</TT> might cause any alteration at all to
the function's namespace. A <TT>from</TT>
statement of the form:</P>

<PRE>from <TT><I>MyModule</I></TT> import *</PRE>

<P class="docText">causes similar performance loss, since it, too, can alter a
function's namespace unpredictably.</P>

<P class="docText"><TT>exec</TT> itself is also quite slow, particularly if
you apply it to a string of source code rather than to a code object.
By far the best approach, for performance, for correctness, and for
clarity, is to avoid <TT>exec</TT> altogether.
It's most often possible to find better (faster,
more solid, and clearer) solutions. If you must use
<TT>exec</TT>, always use it with explicit dictionaries. If
you need to <TT>exec</TT> a dynamically obtained string
more than once, <TT>compile</TT> the string one time and
repeatedly <TT>exec</TT> the resulting code object.</P>

<P class="docText"><TT>eval</TT> works on expressions, not on statements;
therefore, although it's still slow, at least it
avoids some of the worst performance impacts of
<TT>exec</TT>. With <TT>eval</TT>, too,
you're best advised to use explicit dictionaries,
and, if you need repeated evaluation of the same dynamically obtained
string, <TT>compile</TT> the string just once, then
repeatedly <TT>eval</TT> the resulting code object.</P>



<A NAME="pythonian-CHP-17-SECT-4.5.4"></A>
<H5 class="docSection3Title">17.4.5.4 Optimizing loops</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7966"></A> <A NAME="pythonian-CHP-17-ITERM-7967"></A>Most of your
program's bottlenecks will be in loops, particularly
nested loops, because loop bodies often execute repeatedly. Python
does not implicitly perform any code hoisting: if you have any code
inside a loop that might be executed just once by hoisting it out of
the loop, and the loop is a performance bottleneck, hoist the code
out yourself. Sometimes the presence of code to hoist may not be
immediately obvious:</P>

<PRE>def slower(anobject, ahugenumber):
    for i in xrange(ahugenumber): anobject.amethod(i)
def faster(anobject, ahugenumber):
    themethod = anobject.amethod
    for i in xrange(ahugenumber): themethod(i)</PRE>

<P class="docText">In this case, the code that <TT>faster</TT> hoists out of
the <TT>for</TT> loop is the attribute lookup
<TT>anobject.amethod</TT>. <TT>slower</TT>
repeats the lookup each and every time, while
<TT>faster</TT> performs it just once. The two functions
are not 100% equivalent: it is (just barely) conceivable that
executing <TT>amethod</TT> might cause such changes on
<TT>anobject</TT> that the next lookup for the same named
attribute fetches a different method object. This is part of why
Python doesn't perform such optimizations itself. In
practice, such subtle, obscure, and tricky cases happen far less than
one time in ten thousand. So you're quite safe
performing such optimizations yourself, when you're
trying to squeeze the last drop of performance out of some crucial
bottleneck.</P>

<P class="docText">It's faster for Python to use local variables than
global ones. So, if one of your loops is repeatedly accessing a
global variable whose value does not change between iterations of the
loop, put the value in a local variable and have the loop access the
local variable instead. This also applies to built-in functions:</P>

<PRE>def slightly_slower(asequence, adict):
    for x in asequence: adict[x] = hex(x)
def slightly_faster(asequence, adict):
    myhex = hex
    for x in asequence: adict[x] = myhex(x)</PRE>

<P class="docText">Here, the speedup is very modest, on the order of 5% or so.</P>

<P class="docText">Do not cache <TT>None</TT>. <TT>None</TT> is
currently an ordinary built-in identifier, but it is scheduled to
become a keyword in Python 2.3 or 2.4, so no further optimization
will be needed.</P>

<P class="docText">List comprehensions can be faster than loops, and so can
<TT>map</TT> and <TT>filter</TT>. For
optimization purposes, try changing loops into list comprehensions or
<TT>map</TT> and <TT>filter</TT> calls where
feasible. However, the performance advantage of
<TT>map</TT> and <TT>filter</TT> is nullified if
you have to use a <TT>lambda</TT> or an extra level of
function call. Only when you pass to <TT>map</TT> or
<TT>filter</TT> a built-in function, or a function
you'd have to call anyway even from an explicit
loop, do you stand to gain.</P>

<P class="docText">The loops that you can replace most naturally with list
comprehensions, or <TT>map</TT> and
<TT>filter</TT> calls, are loops that build up a list by
repeatedly calling <TT>append</TT> on the list. In such
cases, if you know in advance the length of the resulting list, a
further optimization is available. Predefine the result list to the
right length (e.g., with <TT>result=[None]*N</TT>),
introduce an explicit index <TT>i</TT> that starts at
<TT>0</TT> and grows by one at each iteration of the loop,
and change each call to <TT>result.append(x)</TT> into
<TT>result[i]=x</TT>. The following example shows this
optimization in the context of a typical microperformance benchmark
script:</P>

<PRE>import time

def slow(asequence):
    result = [  ]
    for x in asequence: result.append(-x)
    return result

def middling(asequence):
    return [ -x for x in asequence ]

def fast(asequence):
    result = [None]*len(asequence)
    for i in xrange(len(asequence)): result[i] = -asequence[i]
    return result

biggie = xrange(500*1000)
tentimes = [None]*10
def timit(afunc):
    lobi = biggie
    start = time.clock(  )
    for x in tentimes: afunc(lobi)
    stend = time.clock(  )
    return "%-10s: %.2f" % (afunc._ _name_ _, stend-start)

for afunc in slow, middling, fast, fast, middling, slow:
    print timit(afunc)</PRE>

<P class="docText">Running this example with <TT>python</TT>
<TT>-O</TT> (on a PC with a 1.2 GHz Athlon CPU, Python
2.2.1) shows <TT>fast</TT> taking 4.30 seconds,
<TT>middling</TT> 4.81 to 4.84 seconds, and
<TT>slow</TT> 6.50 to 7.02 seconds, on Windows 98. The time
ranges on Linux are 4.19- 4.20, 5.15-5.20, and 6.91-7.00,
respectively. With the current alpha version of Python 2.3 on Linux,
the time ranges are 3.35-3.37 for <TT>fast</TT>, 4.61-4.64
for <TT>middling</TT>, and 6.43-6.44 for
<TT>slow</TT>. In summary, on this machine,
<TT>slow</TT> is 35%-40% slower than
<TT>middling</TT>, and <TT>middling</TT> is about
15%-25% slower than <TT>fast</TT> (and Python 2.2 is
10%-25% slower than the current alpha of Python 2.3).</P>



<A NAME="pythonian-CHP-17-SECT-4.5.5"></A>
<H5 class="docSection3Title">17.4.5.5 Optimizing I/O</H5>

<P class="docText"><A NAME="pythonian-CHP-17-ITERM-7968"></A> <A NAME="pythonian-CHP-17-ITERM-7969"></A>If
your program does substantial amounts of I/O, it's
likely that performance bottlenecks are due to I/O, not to
computation. Such programs are said to be I/O bound, rather than CPU
bound. Your operating system tries to optimize I/O performance, but
you can help it in a couple of ways. One such way is to perform your
I/O in chunks of a size that is optimal for performance, rather than
simply being convenient for your program's
operations. Another way is to use threading.</P>

<P class="docText">From the point of view of a program's convenience
and simplicity, the ideal amount of data to read or write at a time
is generally small (one character or one line) or very large (an
entire file at a time). That's often okay, because
Python and your operating system work behind the scenes to let your
program use convenient logical chunks for I/O, while arranging
physical I/O operations with chunk sizes that are more attuned to
performance. Reading and writing a whole file at a time is quite
likely to be okay for performance as long as the file is not
inordinately large. Specifically, file-at-a-time I/O is fine as long
as the file's data fits in your
machine's physical memory, leaving enough physical
memory available for your program and operating system to perform
whatever other tasks they need to perform at the same time. The hard
problems of I/O-bound program performance tend to come with huge
files.</P>

<P class="docText">If performance is an issue, don't use a file
object's <TT>readline</TT> method, which
is limited in the amount of chunking and buffering it can perform.
Using <TT>writeline</TT>, on the other hand, gives no
performance problem when that method is the one most convenient for
your program. Loop directly on the file object (in Python 2.2) to get
one line at a time with the best performance. If the file
isn't too huge, time two versions of your program,
one that loops directly on the file object and one that calls method
<TT>readlines</TT>, which reads the whole file into memory.
Either solution may prove faster. In Python 2.1, you
can't loop directly on the file object. Instead, use
method <TT>xreadlines</TT> in a <TT>for</TT>
loop. <TT>xreadlines</TT> will be deprecated in Python 2.3,
but if you need top performance in this specific case and need to
support Python 2.1, there is no alternative.</P>

<P class="docText">For binary files, specifically large binary files of whose contents
you need just a part on each run of your program, module
<TT>mmap</TT>, covered in <A class="docLink" HREF="0596001886_pythonian-chp-14.html#pythonian-CHP-14">Chapter 14</A>, can
often give you both good performance and program simplicity.</P>

<P class="docText">Making an I/O-bound program multithreaded may sometimes afford
substantial performance gains if you can arrange your
program's architecture accordingly. Start a few
worker threads devoted exclusively to I/O, have the computational
threads request I/O operations from the I/O threads via
<TT>Queue</TT> instances, and try to post the request for
each input operation as soon as you know you'll
eventually need that data. Performance will increase only if there
are other tasks your computational threads can perform while an I/O
thread is blocked waiting for data. Basically, you get better
performance this way if you can manage to overlap computation and
waiting for data, by having different threads do the computing and
the waiting. See <A class="docLink" HREF="0596001886_pythonian-chp-14.html#pythonian-CHP-14">Chapter 14</A> for detailed coverage
of Python threading and a suggested architecture.<A NAME="pythonian-CHP-17-ITERM-7970"></A> <A NAME="pythonian-CHP-17-ITERM-7971"></A></P>




<ul></ul>
</td>
</tr>
</table>
<td></td>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
          <a href="0596001886_pythonian-chp-17-sect-3.html"><img src="FILES/previous.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
          <a href="0596001886_pythonian-part-4.html"><img src="FILES/next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
</body></html>
