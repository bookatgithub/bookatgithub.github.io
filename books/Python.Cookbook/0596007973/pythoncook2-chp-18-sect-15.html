<html>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<head>
<title>Recipe&nbsp;18.15.&nbsp;Summing Numbers with Maximal Accuracy</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr><td><div STYLE="MARGIN-LEFT: 0.15in;"><a href="toc.html"><img src="images/teamlib.gif" width="62" height="15" border="0" align="absmiddle"  alt="Team LiB"></a></div></td>
<td align="right"><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=pythoncook2-chp-18-sect-14.html><img src="images/previous.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
<a href=pythoncook2-chp-18-sect-16.html><img src="images/next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</div></td></tr></table>
<br><table width="100%" border="0" cellspacing="0" cellpadding="0"><TR><td valign="top"><a name="pythoncook2-CHP-18-SECT-15"></a>
<h3 class="docSection1Title">Recipe 18.15. Summing Numbers with Maximal Accuracy</h3>

<p class="docText"><span class="docEmphasis">Credit: Yaroslav Bulatov, Connelly Barnes</span></p>

<a name="pythoncook2-CHP-18-SECT-15.1"></a>
<h4 class="docSection2Title">Problem</h4>

<p class="docText"><a name="pythoncook2-CHP-18-ITERM-3112"></a>Due to the properties of floating point
arithmetic, the simplest loop to sum a list of numbers (also embodied
in the built-in <tt>sum</tt> function, as well as similar
functions such as <tt>add.reduce</tt> in add-on modules
such as <tt>Numeric</tt> and <tt>numarray</tt>)
is not maximally accurate. You wish to minimize such numeric
inaccuracy.</P>


<a name="pythoncook2-CHP-18-SECT-15.2"></a>
<h4 class="docSection2Title">Solution</H4>

<p class="docText">A careful and accurate algorithm, using and progressively
accumulating partial sums (i.e., <i>partials</I>),
can reduce inaccuracy:</p>

<pre>import math
def sum_with_partials(arr):
    arr = list(arr)
    size = len(arr)
    iters = int(math.ceil(math.log(size) / math.log(2)))
    step = 1
    for itr in xrange(iters):
        for i in xrange(0, size-step, step+step):
            next_i = i+step
            arr[i] += arr[next_i]
        step += step
    return arr[0]</pre><BR>



<a name="pythoncook2-CHP-18-SECT-15.3"></a>
<H4 class="docSection2Title">Discussion</h4>

<p class="docText">Here is an example of the numeric behavior of this
<I>sum_with_partials</I> function compared to that of the
built-in <tt>sum</tt>:</p>

<pre>if _ _name_ _ == '_ _main_ _':
    arr = [0.123456789012345]*10000000
    true_answer = arr[0] * len(arr)
    print '"True" result: %r' % true_answer
    sum_result = sum(arr)
    print '"sum"  result: %r' % sum_result
    sum_p_resu = sum_with_partials(arr)
    print 'sum_p. result: %r' % sum_p_resu
# emits:
# <b>"True" result: 1234567.89012345</b>
# <b>"sum"  result: 1234567.8902233159</b>
# <b>sum_p. result: 1234567.89012345</b></pre><BR>


<p class="docText">As you can see, in this case, the built-in <tt>sum</tt>
accumulated a relative error of almost
10<sup>-10</sup> after summing 10 million
<tt>float</tt>s all equal to each other (giving less than
11 digits of accuracy in the result), while
<i>sum_with_partials</i> happens to be
"perfect" for this case to within
machine precision (15 digits of accuracy). Summing just a million
copies rather than 10 million lowers
<tt>sum</tt>'s relative error only to a
bit more than 10<sup>-11</sup>.</P>

<a name="pythoncook2-CHP-18-SIDEBAR-1"></a><p><table cellspacing="0" width="90%" border="1" cellpadding="5"><TR><td>
<H2 class="docSidebarTitle">The Trouble with Summations</H2>

<p class="docText">How come a simple summing loop is less than maximally accurate? The
root of the trouble is that summing two floating-point numbers of
very different magnitudes loses accuracy. For example, suppose we
used decimal floating-point numbers with a precision of four digits:
then, summing 1.234 to 123.4 would give 124.6,
"losing" 0.034 from the smaller
number. Such artefacts are inevitable, as long as we have finite
precision during our computations.</p>

<p class="docText">Now, imagine we're using a simple loop such as:</p>

<pre>    total = 0.0
    for number in numbers:
        total += number</pre><br>


<p class="docText">to sum a million numbers, all positive and of reasonably similar
magnitudes. Built-in <tt>sum</tt> internally uses exactly
this kind of simple loop. By the time we've summed,
say, the first 100,000 numbers, the running <i>total</i>
<span class="docEmphasis">has</span> become much larger than each new number
we're adding to it. We have thus put ourselves in
exactly the situation just shown to be problematic: after a while,
we're systematically summing floating-point numbers
of very different magnitudes, and thus systematically losing
accuracy.</p>

<p class="docText">The partials algorithm shown in this recipe works by summing numbers
two at a timetherefore, no major loss of accuracy occurs,
since we're assuming that the numbers we start with
are of reasonably similar magnitudes. So, after the first pass of the
partials algorithm, we're left with half as many
partials as the amount of numbers we started with. All the partials
are of reasonably similar magnitudes, so we just iterate the same
procedure: at each step, we keep halving the number of partials that
are left, until we're down to just one number, the
grand total, having lost along the way as little accuracy as
feasible.</p>
</td></tr></table></p><br>

<p class="docText">If you know that the input argument <i>arr</i> is a list,
and you don't mind destroying that list as part of
the summation, you can omit from the body of
<I>sum_with_partials</I> the statement:</p>

<pre>    arr = list(arr)</pre><br>


<p class="docText">and recover a little bit of performance. Without this small
enhancement, on one slow laptop, summing a million floats with the
built-in <tt>sum</tt> takes 360 milliseconds, while the
more accurate function <I>sum_with_partials</i> shown in
this recipe takes 1.8 seconds to perform the same task (a slowdown of
five times). In theory, <i>sum_with_partials</i> should be
asymptotically faster than built-in <tt>sum</tt> if
you're doing unbounded-precision arithmetic (e.g.,
with Python's built-in <tt>long</tt>s or
other unbounded-precision data types from such add-ons as
<tt>gmpy</tt>, which you can download from <a class="docLink" target="_blank" href="http://gmpy.sourceforge.net">http://gmpy.sourceforge.net</a>). To sum a list
of <tt><i>n</i></tt> elements with
<tt><i>d</I></tt> digits of precision, in
unbounded-precision exact arithmetic, <tt>sum</tt> takes
<tt><i>O</I></tt><tt>(</tt><tt><i>n</I></tt><tt>(</tt><tt><i>d</I></tt><tt>+logd))</tt>
time, while <I>sum_with_partials</i> takes
<tt><I>O</I></tt><tt>(</tt><tt><i>nd</i></tt><tt>)</tt>.
However, I have not been able to observe that effect in empirical
measurements.</p>

<p class="docText">Most of the time, you probably don't want to pay the
price of slowing down a summation by five times in order to increase
your digits of accuracy from 10 or 11 to 15. However, for those
occasions in which this tradeoff is right for your applications, and
you need to sum millions and millions of floating-point numbers, this
recipe might well prove rather useful to you. Another simple way to
increase accuracy, particularly when your input numbers are
<span class="docEmphasis">not</span> necessarily all of similar magnitude, is to
ensure the small-magnitude ones are summed first. This is
particularly easy to code in Python 2.4, although
it's inevitably
<tt><i>O</I></tt><tt>(</tt><tt><i>n</i></tt>
<tt>log</tt> <tt><I>n</i></tt><tt>)</tt>: just
<tt>sum(sorted(data</tt>, <tt>key=abs))</tt>.
Finally, if precision is <span class="docEmphasis">much</span> more important
than speed, consider using <tt>decimal.Decimal</tt> (which
lets you ask for as much precision as you're willing
to wait for and is part of Python 2.4's standard
library). Or you could use <tt>gmpy.mpf</tt> (which also
allows any precision you require, may even be faster, but must be
downloaded as part of <tt>gmpy</tt> from <a class="docLink" target="_blank" href="http://gmpy.sourceforge.net">http://gmpy.sourceforge.net</a>.)</P>


<a name="pythoncook2-CHP-18-SECT-15.4"></a>
<h4 class="docSection2Title">See Also</H4>

<p class="docText"><a class="docLink" href="pythoncook2-CHP-18-SECT-16.html#pythoncook2-CHP-18-SECT-16">Recipe 18.16</a> shows how to
use a bounded-precision simulation of floating point to estimate the
accuracy of algorithms; <a class="docLink" target="_blank" href="ftp://ftp.icsi.berkeley.edu/pub/theory/priest-thesis.ps.Z">ftp://ftp.icsi.berkeley.edu/pub/theory/priest-thesis.ps.Z</a>
for Douglas M. Priest's Ph.D. thesis <span class="docEmphasis">On
Properties of Floating Point Arithmetics: Numerical Stability and the
Cost of Accurate Computations</span>, covering this entire field
with depth and rigor; <tt>gmpy</tt> is at <a class="docLink" target="_blank" href="http://gmpy.sourceforge.net">http://gmpy.sourceforge.net</a>.</P>



<a href="5991535.html"><img src="images/pixel.gif" alt="" width="1" height="1" border="0"></a><ul></ul></td></tr></table>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr><td><div STYLE="MARGIN-LEFT: 0.15in;"><a href="toc.html"><img src="images/teamlib.gif" width="62" height="15" border="0" align="absmiddle"  alt="Team LiB"></a></div></td>
<td align="right"><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=pythoncook2-chp-18-sect-14.html><img src="images/previous.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
<a href=pythoncook2-chp-18-sect-16.html><img src="images/next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</div></td></tr></table>
</body></html>