<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>6.3 Common Scenarios</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body >
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="squid-CHP-6-SECT-2.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="squid-CHP-6-SECT-4.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="squid-CHP-6-SECT-3"></A>
<H3 class="docSection1Title" id="225793-840">6.3 Common Scenarios</H3>

<P class="docText">Because access controls can be complicated, this section contains a
few examples. They demonstrate some of the common uses for access
controls. You should be able to adapt them to your particular needs.</P>

<A NAME="squid-CHP-6-SECT-3.1"></A>
<H4 class="docSection2Title">6.3.1 Allowing Local Clients Only</H4>

<P class="docText">Almost every Squid <A NAME="squid-CHP-6-ITERM-1406"></A><A NAME="squid-CHP-6-ITERM-1407"></A><A NAME="squid-CHP-6-ITERM-1408"></A>installation should restrict
access based on client IP addresses. This is one of the best ways to
protect your system from abuses. The easiest way to do this is write
an ACL that contains your IP address space and then allow HTTP
requests for that ACL and deny all others:</P>

<PRE>acl All src 0/0
acl MyNetwork src 172.16.5.0/24 172.16.6.0/24

http_access allow MyNetwork
http_access deny All</PRE>

<P class="docText">Most likely, this access control configuration will be too simple, so
you'll need to add more lines. Remember that the
order of the <span class="docEmphasis">http_access</span> lines is important.
Don't add anything after <TT>deny
All</TT>. Instead, add the new rules before or after
<TT>allow MyNetwork</TT> as necessary.</P>


<A NAME="squid-CHP-6-SECT-3.2"></A>
<H4 class="docSection2Title">6.3.2 Blocking a Few Misbehaving Clients</H4>

<P class="docText">For one reason or another, you may
<A NAME="squid-CHP-6-ITERM-1409"></A><A NAME="squid-CHP-6-ITERM-1410"></A><A NAME="squid-CHP-6-ITERM-1411"></A>find it necessary to deny access for
a particular client IP address. This can happen, for example, if an
employee or student launches an aggressive web crawling agent that
consumes too much bandwidth or other resources. Until you can stop
the problem at the source, you can block the requests coming to Squid
with this configuration:</P>

<PRE>acl All src 0/0
acl MyNetwork src 172.16.5.0/24 172.16.6.0/24
acl ProblemHost src 172.16.5.9

http_access deny ProblemHost
http_access allow MyNetwork
http_access deny All</PRE>


<A NAME="squid-CHP-6-SECT-3.3"></A>
<H4 class="docSection2Title">6.3.3 Denying Pornography</H4>

<P class="docText">Blocking access to certain <A NAME="squid-CHP-6-ITERM-1412"></A><A NAME="squid-CHP-6-ITERM-1413"></A>content is a touchy subject.
Often, the hardest part about using Squid to deny pornography is
coming up with the list of sites that should be blocked. You may want
to maintain such a list yourself, or get one from somewhere else. The
"Access Controls" section of the
Squid FAQ has links to freely available lists.</P>

<P class="docText">The ACL syntax for using such a list depends on its contents. If the
list contains regular expressions, you probably want something like
this:</P>

<PRE>acl PornSites url_regex "/usr/local/squid/etc/pornlist"
http_access deny PornSites</PRE>

<P class="docText">On the other hand, if the list contains origin server hostnames,
simply change <span class="docEmphasis">url_regex</span> to
<span class="docEmphasis">dstdomain</span> in this example.</P>


<A NAME="squid-CHP-6-SECT-3.4"></A>
<H4 class="docSection2Title">6.3.4 Restricting Usage During Working Hours</H4>

<P class="docText">Some corporations like to <A NAME="squid-CHP-6-ITERM-1414"></A><A NAME="squid-CHP-6-ITERM-1415"></A><A NAME="squid-CHP-6-ITERM-1416"></A>restrict web usage during
working hours, either to save bandwidth, or because policy forbids
employees from doing certain things while working. The hardest part
about this is differentiating between appropriate and inappropriate
use of the Internet during these times. Unfortunately, I
can't help you with that. For this example,
I'm assuming that you've somehow
collected or acquired a list of web site domain names that are known
to be inappropriate. The easy part is configuring Squid:</P>

<PRE>acl NotWorkRelated dstdomain "/usr/local/squid/etc/not-work-related-sites"
acl WorkingHours time D 08:00-17:30

http_access deny !WorkingHours NotWorkRelated</PRE>

<P class="docText">Notice that I've placed the
<TT>!WorkingHours</TT> ACL first in the rule. The
<span class="docEmphasis">dstdomain</span> ACL is expensive (comparing strings
and traversing lists), but the <span class="docEmphasis">time</span> ACL is a
simple inequality check.</P>

<P class="docText">Let's take this a step further and understand how to
combine something like this with the source address controls
described previously. Here's one way to do it:</P>

<PRE>acl All src 0/0
acl MyNetwork src 172.16.5.0/24 172.16.6.0/24
acl NotWorkRelated dstdomain "/usr/local/squid/etc/not-work-related-sites"
acl WorkingHours time D 08:00-17:30

http_access deny !WorkingHours NotWorkRelated
http_access allow MyNetwork
http_access deny All</PRE>

<P class="docText">This scheme works because it accomplishes our goal of denying certain
requests during working hours and allowing requests only from your
own network. However, it might be somewhat inefficient. Note that the
<TT>NotWorkRelated</TT> ACL is searched for all requests,
regardless of the source IP address. If that list is long,
you'll waste CPU resources by searching it for
requests from outside your network. Thus, you may want to change the
rules around somewhat:</P>

<PRE>http_access deny !MyNetwork
http_access deny !WorkingHours NotWorkRelated
http_access Allow All</PRE>

<P class="docText">Here we've delayed the most expensive check until
the very end. Outsiders that may be trying to abuse Squid will not be
wasting your CPU cycles.</P>


<A NAME="squid-CHP-6-SECT-3.5"></A>
<H4 class="docSection2Title">6.3.5 Preventing Squid from Talking to Non-HTTP Servers</H4>

<P class="docText">You need to minimize the <A NAME="squid-CHP-6-ITERM-1417"></A><A NAME="squid-CHP-6-ITERM-1418"></A>chance that Squid can communicate
with certain types of TCP/IP servers. For example, people should
never be able to use your Squid cache to relay SMTP (email) traffic.
I covered this previously when introducing the
<span class="docEmphasis">port</span> ACL. However, it is such an important part
of your access controls that I'm presenting it here
as well.</P>

<P class="docText">First of all, you have to worry about the <TT>CONNECT</TT>
request method. User agents use this method to tunnel TCP connections
through an HTTP proxy. It was invented for HTTP/TLS (a.k.a SSL)
requests, and this remains the primary use for the
<TT>CONNECT</TT> method. Some user-agents may also tunnel
NNTP/TLS traffic through firewall proxies. All other uses should be
rejected. Thus, you'll need an access list that
allows <TT>CONNECT</TT> requests to HTTP/TLS and NNTP/TLS
ports only.</P>

<P class="docText">Secondly, you should prevent Squid from connecting to certain
services such as SMTP. You can either allow safe ports or deny
dangerous ports. I'll give examples for both
techniques.</P>

<P class="docText">Let's start with the rules present in the default
<I>squid.conf</I> file:</P>

<PRE>acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443 563     # https, snews
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535  # unregistered ports

acl SSL_ports port 443 563
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
&lt;additional http_access lines as necessary...&gt;</PRE>

<P class="docText">Our <TT>Safe_ports</TT> ACL lists all privileged ports
(less than 1024) to which Squid may have valid reasons for
connecting. It also lists the entire nonprivileged port range. Notice
that the <TT>Safe_ports</TT> ACL includes the secure HTTP
and NNTP ports (443 and 563) even though they also appear in the
<TT>SSL_ports</TT> ACL. This is because the
<TT>Safe_ports</TT> ACL is checked first in the rules. If
you swap the order of the first two <TT>http_access</TT>
lines, you could probably remove 443 and 563 from the
<TT>Safe_ports</TT> list, but it's hardly
worth the trouble.</P>

<P class="docText">The other way to approach this is to list the privileged ports that
are known to be unsafe:</P>

<PRE>acl Dangerous_ports 7 9 19 22 23 25 53 109 110 119
acl SSL_ports port 443 563
acl CONNECT method CONNECT

http_access deny Dangerous_ports
http_access deny CONNECT !SSL_ports
&lt;additional http_access lines as necessary...&gt;</PRE>

<P class="docText">Don't worry if you're not familiar
with all these strange port numbers. You can find out what each one
is for by reading the <I>/etc/services</I> file on a
Unix system or by reading IANA's list of registered
TCP/UDP port numbers at <A class="docLink" target="_blank" HREF="http://www.iana.org/assignments/port-numbers">http://www.iana.org/assignments/port-numbers</A>.</P>


<A NAME="squid-CHP-6-SECT-3.6"></A>
<H4 class="docSection2Title">6.3.6 Giving Certain Users Special Access</H4>

<P class="docText">Organizations that employ <A NAME="squid-CHP-6-ITERM-1419"></A><A NAME="squid-CHP-6-ITERM-1420"></A>username-based access controls
often need to give certain users special privileges. In this simple
example, there are three elements: all authenticated users, the
usernames of the administrators, and a list of pornographic web
sites. Normal users aren't allowed to view
pornography, but the admins have the dubious job of maintaining the
list. They need to connect to all servers to verify whether or not a
particular site should be placed in the pornography list.
Here's how to accomplish the task:</P>

<PRE>auth_param basic program /usr/local/squid/libexec/ncsa_auth
    /usr/local/squid/etc/passwd

acl Authenticated proxy_auth REQUIRED
acl Admins proxy_auth Pat Jean Chris
acl Porn dstdomain "/usr/local/squid/etc/porn.domains"
acl All src 0/0

http_access allow Admins
http_access deny Porn
http_access allow Authenticated
http_access deny All</PRE>

<P class="docText">Let's examine how this all works. First, there are
three ACL definitions. The <span class="docEmphasis">Authenticated</span> ACL
matches any valid proxy authentication credentials. The
<span class="docEmphasis">Admins</span> ACL matches valid credentials from users
Pat, Jean, and Chris. The <span class="docEmphasis">Porn</span> ACL matches
certain origin server hostnames found in the
<I>porn.domains</I> file.</P>

<P class="docText">This example has four access control rules. The first checks only the
<span class="docEmphasis">Admins</span> ACL and allows all requests from Pat,
Jean, and Chris. For other users, Squid moves on to the next rule.
According to the second rule, a request is denied if its origin
server hostname is in the <I>porn.domains</I> file. For
requests that don't match the
<span class="docEmphasis">Porn</span> ACL, Squid moves on to the third rule.
Here, the request is allowed if it contains valid authentication
credentials. The external authenticator (<I>ncsa_auth</I>
in this case) is responsible for deciding whether or not the
credentials are valid. If they aren't, the final
rule applies, and the request is denied.</P>

<P class="docText">Note that the <I>ncsa_auth</I> authenticator
isn't a requirement. You can use any of the numerous
authentication helpers described in <A class="docLink" HREF="squid-CHP-12.html#squid-CHP-12">Chapter 12</A>.</P>


<A NAME="squid-CHP-6-SECT-3.7"></A>
<H4 class="docSection2Title">6.3.7 Preventing Abuse from Siblings</H4>

<P class="docText">If you open up your cache to peer with <A NAME="squid-CHP-6-ITERM-1421"></A><A NAME="squid-CHP-6-ITERM-1422"></A>other caches, you need to
take additional precautions. Caches often use ICP to discover which
objects are stored in their neighbors. You should accept ICP queries
only from known and approved neighbors.</P>

<P class="docText">Furthermore, you can configure Squid to enforce a sibling
relationship by using the <TT>miss_access</TT> rule list.
Squid checks these rules only when forwarding cache misses, never
cache hits. Thus, all requests must first pass the
<TT>http_access</TT> rules before the
<TT>miss_access</TT> list comes into play.</P>

<P class="docText">In this example, there are three separate ACLs. One is for the local
users that connect directly to this cache. Another is for a child
cache, which is allowed to forward requests that are cache misses.
The third is a sibling cache, which must never forward a request that
results in a cache miss. Here's how it all works:</P>

<PRE>alc All src 0/0
acl OurUsers src 172.16.5.0/24
acl ChildCache src 192.168.1.1
acl SiblingCache src 192.168.3.3

http_access allow OurUsers
http_access allow ChildCache
http_access allow SiblingCache
http_access deny All

miss_access deny SiblingCache

icp_access allow ChildCache
icp_access allow SiblingCache
icp_access deny All</PRE>


<A NAME="squid-CHP-6-SECT-3.8"></A>
<H4 class="docSection2Title">6.3.8 Denying Requests with IP Addresses</H4>

<P class="docText">As I mentioned in <A NAME="squid-CHP-6-ITERM-1423"></A><A NAME="squid-CHP-6-ITERM-1424"></A><A NAME="squid-CHP-6-ITERM-1425"></A> <A class="docLink" HREF="squid-CHP-6-SECT-1.html#squid-CHP-6-SECT-1.2.4">Section 6.1.2.4</A>, the
<span class="docEmphasis">dstdomain</span> type is good for blocking access to
specific origin servers. However, clever users might be able to get
around the rule by replacing URL hostnames with their IP addresses.
If you are desperate to stop such requests, you may want to block all
requests that contain an IP address. You can do so with a redirector
(see <A class="docLink" HREF="squid-CHP-11.html#squid-CHP-11">Chapter 11</A>) or with a semicomplicated
<span class="docEmphasis">dstdom_regex</span> ACL like this:</P>

<PRE>acl IPForHostname dstdom_regex ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$
http_access deny IPForHostname</PRE>


<A NAME="squid-CHP-6-SECT-3.9"></A>
<H4 class="docSection2Title">6.3.9 An http_reply_access Example</H4>

<P class="docText">Recall that the response's content type
<A NAME="squid-CHP-6-ITERM-1426"></A><A NAME="squid-CHP-6-ITERM-1427"></A>is the only
new information available when Squid checks the
<span class="docEmphasis">http_reply_access</span> rules. Thus, you can keep the
<span class="docEmphasis">http_reply_access</span> rules very simple. You need
only check the <span class="docEmphasis">rep_mime_type</span> ACLs. For example,
here's how you can deny responses with certain
content types:</P>

<PRE>acl All src 0/0
acl Movies rep_mime_type video/mpeg
acl MP3s rep_mime_type audio/mpeg
http_reply_access deny Movies
http_reply_access deny MP3s
http_reply_access allow All</PRE>

<P><table border="0" bgcolor="black" cellspacing="0" cellpadding="1" width="90%" align="center"><tr><td><table bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="6"><tr><td width="60" valign="top"><img src="images/tip_yellow.gif" width="50" height="54"></td><td valign="top">
<P class="docText">You don't need to repeat your
<span class="docEmphasis">http_access</span> rules in the
<span class="docEmphasis">http_reply_access</span> list. The <span class="docEmphasis">allow
All</span> rule shown here doesn't mean that all
requests to Squid are allowed. Any request that is denied by
<span class="docEmphasis">http_access</span> never makes it to the stage where
Squid checks the <span class="docEmphasis">http_reply_access</span> rules.</P>
</td></tr></table></td></tr></table></P><br>


<A NAME="squid-CHP-6-SECT-3.10"></A>
<H4 class="docSection2Title">6.3.10 Preventing Cache Hits for Local Sites</H4>

<P class="docText">If you have a number of origin <A NAME="squid-CHP-6-ITERM-1428"></A><A NAME="squid-CHP-6-ITERM-1429"></A>servers on
your network, you may want to configure Squid so that their responses
are never cached. Because the servers are nearby, they
don't benefit too much from cache hits.
Additionally, it frees up storage space for other (far away) origin
servers.</P>

<P class="docText">The first step is to define an ACL for the local servers. You might
want to use an address-based ACL, such as <span class="docEmphasis">dst</span>:</P>

<PRE>acl LocalServers dst 172.17.1.0/24</PRE>

<P class="docText">If the servers don't live on a single subnet, you
might find it easier to create a <span class="docEmphasis">dstdomain</span> ACL:</P>

<PRE>acl LocalServers dstdomain .example.com</PRE>

<P class="docText">Next, you simply deny caching of those servers with a
<span class="docEmphasis">no_cache</span> access rule:</P>

<PRE>no_cache deny LocalServers</PRE>

<P><table border="0" bgcolor="black" cellspacing="0" cellpadding="1" width="90%" align="center"><tr><td><table bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="6"><tr><td width="60" valign="top"><img src="images/tip_yellow.gif" width="50" height="54"></td><td valign="top">
<P class="docText">The <span class="docEmphasis">no_cache</span> rules don't
prevent your clients from sending these requests to Squid. There is
nothing you can configure in Squid to stop such requests from coming.
Instead, you must configure the user-agent<TT>s</TT>
themselves.</P>
</td></tr></table></td></tr></table></P><br>

<P class="docText">If you add a <span class="docEmphasis">no_cache</span> rule after Squid has been
running for a while, the cache may contain some objects that match
the new rule. Prior to Squid Version 2.5, these previously cached
objects might be returned as cache hits. Now, however, Squid purges
any cached response for a request that matches a
<span class="docEmphasis">no_cache</span> rule.</P>



<ul></ul></td></tr></table>
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#e6e6e6">
<tr style="background-image: url(images/tile_back.gif);">
<td class="v2" align="left" width="30%">
<a href="squid-CHP-6-SECT-2.html"><img src="images/previous.gif" width="70" height="19" border="0" align="absmiddle" alt="Previous Section"></a>
</td>
<td class="v2" align="center" width="40%">
<a href="main.html" style="color:white;text-decoration:none;text-underline:none">&nbsp;&lt;&nbsp;Day Day Up&nbsp;&gt;&nbsp;</a>
</td>
<td class="v2" align="right" width="30%">
<a href="squid-CHP-6-SECT-4.html"><img src="images/next.gif" width="70" height="19" border="0" align="absmiddle" alt="Next Section"></a>
</td>
</tr>
</table>
</body>
</html>
