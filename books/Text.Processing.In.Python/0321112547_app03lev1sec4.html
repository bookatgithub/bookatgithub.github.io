<html><head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<!--SafClassName="docSection1Title"--><!--SafTocEntry="C.4 Declarations"-->
<link rel="STYLESHEET" type="text/css" href="FILES/style.css">
<link rel="STYLESHEET" type="text/css" href="FILES/docsafari.css">
<style type="text/css">	.tt1    {font-size: 10pt;}</style>
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
	<a href="0321112547_app03lev1sec3.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
	<a href="0321112547_app03lev1sec5.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="app03lev1sec4"></A><H3 class="docSection1Title">C.4 Declarations</H3>
<P class="docText">We have seen how Unicode characters are actually encoded, at least briefly, but how do applications know to use a particular decoding procedure when Unicode is encountered? How applications are alerted to a Unicode encoding depends upon the type of data stream in question.</P>
<P class="docText">Normal text files do not have any special header information attached to them to explicitly specify type. However, some operating systems (like MacOS, OS/2, and BeOS—Windows and Linux only in a more limited sense) have mechanisms to attach extended attributes to files; increasingly, MIME header information is stored in such extended attributes. If this happens to be the case, it is possible to store MIME header information such as:</P>
<pre>
Content-Type: text/plain; charset=UTF-8
</pre>
<P class="docText">Nonetheless, having MIME headers attached to files is not a safe, generic assumption. Fortunately, the actual byte sequences in Unicode files provide a tip to applications. A Unicode-aware application, absent contrary indication, is supposed to assume that a given file is encoded with <TT>UTF-8</TT>. A non-Unicode-aware application reading the same file will find a file that contains a mixture of ASCII characters and high-bit characters (for multibyte <TT>UTF-8</TT> encodings). All the ASCII-range bytes will have the same values as if they were ASCII encoded. If any multibyte <TT>UTF-8</TT> sequences were used, those will appear as non-ASCII bytes and should be treated as noncharacter data by the legacy application. This may result in nonprocessing of those extended characters, but that is pretty much the best we could expect from a legacy application (that, by definition, does not know how to deal with the extended characters).</P>
<P class="docText">For <TT>UTF-16</TT> encoded files, a special convention is followed for the first two bytes of the file. One of the sequences <TT>0xFF 0xFE</TT> or <TT>0xFE 0xFF</TT> acts as small headers to the file. The choice of which header specifies the endianness of a platform's bytes (most common platforms are little-endian and will use <TT>0xFF 0xFE</TT>). It was decided that the collision risk of a legacy file beginning with these bytes was small and therefore these could be used as a reliable indicator for <TT>UTF-16</TT> encoding. Within a <TT>UTF-16</TT> encoded text file, plain ASCII characters will appear every other byte, interspersed with <TT>0x00</TT> (null) bytes. Of course, extended characters will produce non-null bytes and in some cases double-word (4 byte) representations. But a legacy tool that ignores embedded nulls will wind up doing the right thing with <TT>UTF-16</TT> encoded files, even without knowing about Unicode.</P>
<P class="docText">Many communications protocols—and more recent document specifications—allow for explicit encoding specification. For example, an HTTP daemon application (a Web server) can return a header such as the following to provide explicit instructions to a client:</P>
<pre>
HTTP/1.1 200 OK
Content-Type: text/html; charset:UTF-8;
</pre>
<P class="docText">Similarly, an NNTP, SMTP/POP3 message can carry a similar <TT>Content-Type:</TT> header field that makes explicit the encoding to follow (most likely as <TT>text/plain</TT> rather than <TT>text/html</TT>, however; or at least we can hope).</P>
<P class="docText">HTML and XML documents can contain tags and declarations to make Unicode encoding explicit. An HTML document can provide a hint in a <TT>META</TT> tag, like:</P>
<pre>
&lt;META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=UTF-8"&gt;
</pre>
<P class="docText">However, a <TT>META</TT> tag should properly take lower precedence than an HTTP header, in a situation where both are part of the communication (but for a local HTML file, such an HTTP header does not exist).</P>
<P class="docText">In XML, the actual document declaration should indicate the Unicode encoding, as in:</P>
<pre>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
</pre>
<P class="docText">Other formats and protocols may provide explicit encoding specification by similar means.</P>
<ul></ul></td></tr></table>
<td></td>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
          <a href="0321112547_app03lev1sec3.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
          <a href="0321112547_app03lev1sec5.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
</body></html>
