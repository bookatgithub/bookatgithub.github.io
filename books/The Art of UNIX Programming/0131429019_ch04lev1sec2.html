<html><head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<!--SafClassName="docSection1Title"--><!--SafTocEntry="4.2 Compactness and Orthogonality"-->
<link rel="STYLESHEET" type="text/css" href="FILES/style.css">
<link rel="STYLESHEET" type="text/css" href="FILES/docsafari.css">
<style type="text/css">	.tt1    {font-size: 10pt;}</style>
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
	<a href="0131429019_ch04lev1sec1.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
	<a href="0131429019_ch04lev1sec3.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch04lev1sec2"></A>
<H3 class="docSection1Title">4.2 Compactness and Orthogonality</H3>
<P class="docText">Code is not the only sort of thing with an optimal chunk size. Languages and APIs (such as sets of library or system calls) run up against the same sorts of human cognitive constraints that produce Hatton's U-curve.</P>
<P class="docText">Accordingly, Unix programmers have learned to think very hard about two other properties when designing APIs, command sets, protocols, and other ways to make computers do tricks: <span class="docEmphasis">compactness</span> and <span class="docEmphasis">orthogonality</span>.<A NAME="idd1e9874"></A></P>
<A NAME="ch04lev2sec1"></A>
<H4 class="docSection2Title">4.2.1 Compactness</H4>
<P class="docText"><A NAME="idd1e9884"></A><A NAME="idd1e9887"></A><A NAME="idd1e9890"></A>Compactness<A NAME="idd1e9896"></A> is the property that a design can fit inside a human being's head. A good practical test for compactness is this: Does an experienced user normally need a manual? If not, then the design (or at least the subset of it that covers normal use) is compact.</P>
<P class="docText">Compact software tools have all the virtues of physical tools that fit well in the hand. They feel pleasant to use, they don't obtrude themselves between your mind and your work, they make you more productive—and they are much less likely than unwieldy tools to turn in your hand and injure you.</P>
<P class="docText">Compact is not equivalent to 'weak'. A design can have a great deal of power and flexibility and still be compact if it is built on abstractions that are easy to think about and fit together well. Nor is compact equivalent to 'easily learned'; some compact designs are quite difficult to understand until you have mastered an underlying conceptual model that is tricky, at which point your view of the world changes and compact <span class="docEmphasis">becomes</span> simple. For a lot of people, the Lisp language is a classic example of this<A NAME="idd1e9909"></A>.</P>
<blockquote>

<p class="docText"><A NAME="idd1e9920"></A>Nor does compact mean 'small'. If a well-designed system is predictable and 'obvious' to the experienced user, it might have quite a few pieces.</p>
<p class="docText">—Ken Arnold</p></blockquote>
<P class="docText">Very few software designs are compact in an absolute sense, but many are compact in a slightly looser sense of the term. They have a compact working set, a subset of capabilities that suffices for 80% or more of what expert users normally do with them. Practically speaking, such designs normally need a reference card or cheat sheet but not a manual. We'll call such designs <span class="docEmphasis">semi-compact</span><A NAME="idd1e9930"></A>, as opposed to <span class="docEmphasis">strictly compact</span>.</P>
<P class="docText">The concept is perhaps best illustrated by examples. The Unix system call API is semi-compact, but the standard C<A NAME="idd1e9943"></A> library is not compact in any sense. While Unix programmers easily keep a subset of the system calls sufficient for most applications programming (file system operations, signals, and process control) in their heads, the C library on modern Unixes includes many hundreds of entry points, e.g., mathematical functions, that won't all fit inside a single programmer's cranium.</P>
<P class="docText"><span class="docEmphasis">The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information</span> <A class="docLink" HREF="0131429019_app02.html#biblio54">[Miller]</A> is one of the foundation papers in cognitive psychology (and, incidentally, the specific reason that U.S. local telephone numbers have seven digits). It showed that the number of discrete items of information human beings can hold in short-term memory is seven, plus or minus two. This gives us a good rule of thumb for evaluating the compactness of APIs: Does a programmer have to remember more than seven entry points? Anything larger than this is unlikely to be strictly compact.</P>
<P class="docText">Among Unix tools, <span class="docEmphasis">make</span>(1)<A NAME="idd1e9964"></A> is compact; <span class="docEmphasis">autoconf</span>(1) and <span class="docEmphasis">automake</span>(1) are not. Among markup languages, HTML is semi-compact, but DocBook (a documentation markup language we shall discuss in <A class="docLink" HREF="0131429019_ch18.html#ch18">Chapter 18</A>) is not. The <span class="docEmphasis">man</span>(7)<A NAME="idd1e9981"></A> macros are compact, but <span class="docEmphasis">troff</span>(1)<A NAME="idd1e9990"></A> markup is not.</P>
<P class="docText">Among general-purpose programming languages, C<A NAME="idd1e9999"></A><A NAME="idd1e10004"></A> and Python<A NAME="idd1e10008"></A> are semi-compact; Perl<A NAME="idd1e10012"></A>, Java<A NAME="idd1e10016"></A>, Emacs Lisp<A NAME="idd1e10020"></A>, and shell<A NAME="idd1e10024"></A><A NAME="idd1e10027"></A> are not (especially since serious shell programming requires you to know half-a-dozen other tools like <span class="docEmphasis">sed</span>(1)<A NAME="idd1e10034"></A> and <span class="docEmphasis">awk</span>(1)<A NAME="idd1e10041"></A>). C++<A NAME="idd1e10045"></A> is anti-compact—the language's designer has admitted that he doesn't expect any one programmer to ever understand it all.</P>
<P class="docText">Some designs that are not compact have enough internal redundancy of features that individual programmers end up carving out compact dialects sufficient for that 80% of common tasks by choosing a working subset of the language. Perl has this kind of pseudo-compactness, for example. Such designs have a built-in trap; when two programmers try to communicate about a project, they may find that differences in their working subsets are a significant barrier to understanding and modifying the code.</P>
<P class="docText">Noncompact designs<A NAME="idd1e10055"></A> are not automatically doomed or bad, however. Some problem domains are simply too complex for a compact design to span them. Sometimes it's necessary to trade away compactness for some other virtue, like raw power and range. Troff markup is a good example of this. So is the BSD<A NAME="idd1e10059"></A> sockets API. The purpose of emphasizing compactness as a virtue is not to condition you to treat compactness as an absolute requirement, but to teach you to do what Unix programmers do: value compactness properly, design for it whenever possible, and not throw it away casually.</P>

<A NAME="ch04lev2sec2"></A>
<H4 class="docSection2Title">4.2.2 Orthogonality</H4>
<P class="docText"><A NAME="idd1e10074"></A><A NAME="idd1e10077"></A><A NAME="idd1e10080"></A>Orthogonality<A NAME="idd1e10086"></A> is one of the most important properties that can help make even complex designs compact<A NAME="idd1e10090"></A>. In a purely orthogonal design, operations do not have side effects; each action (whether it's an API call, a macro invocation, or a language operation) changes just one thing without affecting others. There is one and only one way to change each property of whatever system you are controlling.</P>
<P class="docText">Your monitor has orthogonal controls. You can change the brightness independently of the contrast level, and (if the monitor has one) the color balance control will be independent of both. Imagine how much more difficult it would be to adjust a monitor on which the brightness knob affected the color balance: you'd have to compensate by tweaking the color balance every time after you changed the brightness. Worse, imagine if the contrast control also affected the color balance; then, you'd have to adjust both knobs simultaneously in exactly the right way to change either contrast or color balance alone while holding the other constant.</P>
<P class="docText">Far too many software designs are non-orthogonal. One common class of design mistake, for example, occurs in code that reads and parses data from one (source) format to another (target) format. A designer who thinks of the source format as always being stored in a disk file may write the conversion function to open and read from a named file. Usually the input could just as well have been any file handle. If the conversion routine were designed orthogonally, e.g., without the side effect of opening a file, it could save work later when the conversion has to be done on a data stream supplied from standard input, a network socket, or any other source.</P>
<P class="docText">Doug McIlroy's<A NAME="idd1e10106"></A> advice to "Do one thing well" is usually interpreted as being about simplicity. But it's also, implicitly and at least as importantly, about orthogonality.</P>
<P class="docText">It's not a problem for a program to do one thing well and other things as side effects, provided supporting those other things doesn't raise the complexity of the program and its vulnerability to bugs. In <A class="docLink" HREF="0131429019_ch09.html#ch09">Chapter 9</A> we'll examine a program called <span class="docEmphasis">ascii</span><A NAME="idd1e10119"></A> that prints synonyms for the names of ASCII characters, including hex, octal, and binary values; as a side effect, it can serve as a quick base converter for numbers in the range 0–255. This second use is not an orthogonality violation because the features that support it are all necessary to the primary function; they do not make the program more difficult to document or maintain.</P>
<P class="docText">The problems with non-orthogonality arise when side effects complicate a programmer's or user's mental model, and beg to be forgotten, with results ranging from inconvenient to dire. Even when you do not forget the side effects, you're often forced to do extra work to suppress them or work around them.</P>
<P class="docText">There is an excellent discussion of orthogonality and how to achieve it in <span class="docEmphasis">The Pragmatic Programmer</span> [Hunt-Thomas]. As they point out, orthogonality reduces test and development time, because it's easier to verify code that neither causes side effects nor depends on side effects from other code—there are fewer combinations to test. If it breaks, orthogonal code is more easily replaced without disturbance to the rest of the system. Finally, orthogonal code is easier to document and reuse.</P>
<P class="docText">The concept of <span class="docEmphasis">refactoring</span><A NAME="idd1e10137"></A>, which first emerged as an explicit idea from the 'Extreme Programming' school, is closely related to orthogonality. To refactor code is to change its structure and organization without changing its observable behavior. Software engineers have been doing this since the birth of the field, of course, but naming the practice and identifying a stock set of refactoring techniques has helped concentrate peoples' thinking in useful ways. Because these fit so well with the central concerns of the Unix design tradition, Unix developers have quickly coopted the terminology and ideas of refactoring.<sup class="docFootnote"><A class="docLink" HREF="#ch04en03">[3]</A></sup></P><blockquote><p class="docFootnote"><sup><A NAME="ch04en03">[3]</A></sup> In the foundation text on this topic, <span class="docEmphasis">Refactoring</span> <A class="docLink" HREF="0131429019_app02.html#biblio21">[Fowler]</A>, the author comes very close to stating that the principal goal of refactoring is to improve orthogonality. But lacking the concept, he can only approximate this idea from several different directions: eliminating code duplication and various other "bad smells" many of which are some sort of orthogonality violation.</p></blockquote>
<P class="docText">The basic Unix APIs<A NAME="idd1e10156"></A> were designed for orthogonality with imperfect but considerable success. We take for granted being able to open a file for write access without exclusive-locking it for write, for example; not all operating systems are so graceful. Old-style (System III<A NAME="idd1e10162"></A>) signals were non-orthogonal, because signal receipt had the side-effect of resetting the signal handler to the default die-on-receipt. There are large non-orthogonal patches like the BSD sockets<A NAME="idd1e10166"></A> API and <span class="docEmphasis">very</span> large ones like the X windowing system's drawing libraries.</P>
<P class="docText">But on the whole the Unix API is a good example: Otherwise it not only would not but <span class="docEmphasis">could</span> not be so widely imitated by C<A NAME="idd1e10185"></A> libraries on other operating systems. This is also a reason that the Unix API repays study even if you are not a Unix programmer; it has lessons about orthogonality to teach.</P>

<A NAME="ch04lev2sec3"></A>
<H4 class="docSection2Title">4.2.3 The SPOT Rule</H4>
<P class="docText"><A NAME="idd1e10200"></A><A NAME="idd1e10203"></A><span class="docEmphasis">The Pragmatic Programmer</span> articulates a rule for one particular kind of orthogonality that is especially important. Their "Don't Repeat Yourself" rule is: every piece of knowledge must have a <span class="docEmphasis">single</span>, unambiguous, authoritative representation within a system. In this book we prefer, following a suggestion by Brian Kernighan, to call this the Single Point Of Truth or SPOT rule.</P>
<P class="docText">Repetition leads to inconsistency and code that is subtly broken, because you changed only some repetitions when you needed to change <span class="docEmphasis">all</span> of them. Often, it also means that you haven't properly thought through the organization of your code.</P>
<P class="docText">Constants, tables, and metadata should be declared and initialized <span class="docEmphasis">once</span> and imported elsewhere. Any time you see duplicate code, that's a danger sign. Complexity is a cost; don't pay it twice.</P>
<P class="docText">Often it's possible to remove code duplication by <span class="docEmphasis">refactoring</span><A NAME="idd1e10231"></A>; that is, changing the organization of your code without changing the core algorithms. Data duplication sometimes appears to be forced on you. But when you see it, here are some valuable questions to ask:</P>
<UL><LI><P class="docList">If you have duplicated data in your code because it has to have two different representations in two different places, can you write a function, tool or code generator to make one representation from the other, or both from a common source?</P></LI><LI><P class="docList">If your documentation duplicates knowledge in your code, can you generate parts of the documentation from parts of the code, or vice-versa, or both from a common higher-level representation?</P></LI><LI><P class="docList">If your header files and interface declarations duplicate knowledge in your implementation code, is there a way you can generate the header files and interface declarations from the code?</P></LI></UL>
<P class="docText">There is an analog of the SPOT rule for data structures: "No junk, no confusion". "No junk" says that the data structure (the model) should be minimal, e.g., not made so general that it can represent situations which cannot exist. "No confusion" says that states which must be kept distinct in the real-world problem must be kept distinct in the model. In short, the SPOT rule advocates seeking a data structure whose states have a one-to-one correspondence with the states of the real-world system to be modeled.</P>
<P class="docText">From deeper within the Unix tradition, we can add some of our own corollaries of the SPOT rule:</P>
<UL><LI><P class="docList">Are you duplicating data because you're caching intermediate results of some computation or lookup? Consider carefully whether this is premature optimization<A NAME="idd1e10262"></A>; stale caches (and the layers of code needed to keep caches synchronized) are a fertile source of bugs,<sup class="docFootnote"><A class="docLink" HREF="#ch04en04">[4]</A></sup> and can even slow down overall performance if (as often happens) the cache-management overhead is higher than you expected.</P><blockquote><p class="docFootnote"><sup><A NAME="ch04en04">[4]</A></sup> An archetypal example of bad caching is the <span class="docEmphStrong"><TT>rehash</TT></span><A NAME="idd1e10274"></A> directive in <span class="docEmphasis">csh</span>(1)<A NAME="idd1e10281"></A>; type <span class="docEmphStrong"><TT>man 1 csh</TT></span> for details. See <A class="docLink" HREF="0131429019_ch12lev1sec4.html#ch12lev2sec3">Section 12.4.3</A> for another example.</p></blockquote></LI><LI><P class="docList">If you see lots of duplicative boilerplate code, can you generate all of it from a single higher-level representation, twiddling a few knobs to generate the different cases?</P></LI></UL>
<P class="docText">The reader should begin to see a pattern emerging here.</P>
<P class="docText">In the Unix world, the SPOT Rule as a unifying idea has seldom been explicit—but heavy use of code generators to implement particular <span class="docEmphasis">kinds</span> of SPOT are very much part of the tradition. We'll survey these techniques in <A class="docLink" HREF="0131429019_ch09.html#ch09">Chapter 9</A>.</P>

<A NAME="ch04lev2sec4"></A>
<H4 class="docSection2Title">4.2.4 Compactness and the Strong Single Center</H4>
<P class="docText"><A NAME="idd1e10320"></A><A NAME="idd1e10325"></A>One subtle but powerful way to promote compactness in a design is to organize it around a strong core algorithm addressing a clear formal definition of the problem, avoiding heuristics and fudging.</P>
<blockquote>

<p class="docText"><A NAME="idd1e10340"></A>Formalization often clarifies a task spectacularly. It is not enough for a programmer to recognize that bits of his task fall within standard computer-science categories—a little depth-first search here and a quicksort there. The best results occur when the nub of the task can be formalized, and a clear model of the job at hand can be constructed. It is not necessary that ultimate users comprehend the model. The very existence of a unifying core will provide a comfortable feel, unencumbered with the why-in-hell-did-they-do-that moments that are so prevalent in using Swiss-army-knife programs.</p>
<p class="docText">—Doug McIlroy</p></blockquote>
<P class="docText">This is an often-overlooked strength of the Unix tradition. Many of its most effective tools are thin wrappers around a direct translation of some single powerful algorithm.</P>
<P class="docText">Perhaps the clearest example of this is <span class="docEmphasis">diff</span>(1)<A NAME="idd1e10354"></A>, the Unix tool for reporting differences between related files. This tool and its dual, <span class="docEmphasis">patch</span>(1)<A NAME="idd1e10361"></A>, have become central to the network-distributed development style of modern Unix. A valuable property of diff is that it seldom surprises anyone. It doesn't have special cases or painful edge conditions, because it uses a simple, mathematically sound method of sequence comparison. This has consequences:</P>
<blockquote>

<p class="docText"><A NAME="idd1e10372"></A>By virtue of a mathematical model and a solid algorithm, Unix diff contrasts markedly with its imitators. First, the central engine is solid, small, and has never needed one line of maintenance. Second, the results are clear and consistent, unmarred by surprises where heuristics<A NAME="idd1e10376"></A> fail.</p>
<p class="docText">—Doug McIlroy</p></blockquote>
<P class="docText">Thus, people who use diff can develop an intuitive feel for what it will do in any given situation without necessarily understanding the central algorithm perfectly. Other well-known examples of this special kind of clarity achieved through a strong central algorithm abound in Unix:</P>
<UL><LI><P class="docList">The <span class="docEmphasis">grep</span>(1)<A NAME="idd1e10393"></A> utility for selecting lines out of files by pattern matching is a simple wrapper around a formal algebra of regular-expression patterns (see <A class="docLink" HREF="0131429019_ch08lev1sec2.html#ch08lev2sec2">Section 8.2.2</A> for discussion). If it had lacked this consistent mathematical model, it would probably look like the design of the original <span class="docEmphasis">glob</span>(1)<A NAME="idd1e10404"></A> facility in the oldest Unixes, a handful of ad-hoc wildcards that can't be combined.</P></LI><LI><P class="docList">The <span class="docEmphasis">yacc</span>(1)<A NAME="idd1e10417"></A> utility for generating language parsers is a thin wrapper around the formal theory of LR(1) grammars. Its partner, the lexical analyzer generator <span class="docEmphasis">lex</span>(1)<A NAME="idd1e10424"></A>, is a similarly thin wrapper around the theory of nondeterministic finite-state automata.</P></LI></UL>
<P class="docText">All three of these programs are so bug-free that their correct functioning is taken utterly for granted, and compact enough to fit easily in a programmer's hand. Only a part of these good qualities are due to the polishing that comes with a long service life and frequent use; most of it is that, having been constructed around a strong and provably correct algorithmic core, they never needed much polishing in the first place.</P>
<P class="docText">The opposite of a formal approach is using <span class="docEmphasis">heuristics</span>—rules of thumb<A NAME="idd1e10438"></A> leading toward a solution that is probabilistically, but not certainly, correct. Sometimes we use heuristics because a deterministically correct solution is impossible. Think of spam filtering, for example; an algorithmically perfect spam filter would need a full solution to the problem of understanding natural language as a module. Other times, we use heuristics because known formally correct methods are impossibly expensive. Virtual-memory management is an example of this; there are near-perfect solutions, but they require so much runtime instrumentation that their overhead would swamp any theoretical gain over heuristics.</P>
<P class="docText">The trouble with heuristics is that they proliferate special cases and edge cases. If nothing else, you usually have to backstop a heuristic with some sort of recovery mechanism when it fails. All the usual problems with escalating complexity follow. To manage the resulting tradeoffs, you have to start by being aware of them. Always ask if a heuristic actually pays off in performance what it costs in code complexity—and don't guess at the performance difference, actually measure it before making a decision.</P>

<A NAME="ch04lev2sec5"></A>
<H4 class="docSection2Title">4.2.5 The Value of Detachment</H4>
<P class="docText"><A NAME="idd1e10453"></A><A NAME="idd1e10456"></A>We began this book with a reference to Zen: "a special transmission, outside the scriptures". This was not mere exoticism for stylistic effect; the core concepts of Unix have always had a spare, Zen-like simplicity that continues to shine through the layers of historical accidents that have accreted around them<A NAME="idd1e10462"></A>. This quality is reflected in the cornerstone documents of Unix, like <span class="docEmphasis">The C Programming Language</span><A NAME="idd1e10468"></A> [Kernighan-Ritchie] and the 1974 CACM paper that introduced Unix to the world; one of the famous quotes from that paper observes "...constraint has encouraged not only economy, but also a certain elegance of design". That simplicity came from trying to think not about how much a language or operating system could do, but of how <span class="docEmphasis">little</span> it could do—not by carrying assumptions but by starting from zero (what in Zen is called "beginner's mind" or "empty mind").</P>
<P class="docText">To design for compactness<A NAME="idd1e10478"></A><A NAME="idd1e10481"></A> and orthogonality<A NAME="idd1e10485"></A><A NAME="idd1e10488"></A>, start from zero. Zen teaches that attachment leads to suffering; experience with software design teaches that attachment to unnoticed assumptions leads to non-orthogonality, noncompact designs, and projects that fail or become maintenance nightmares.</P>
<P class="docText">To achieve enlightenment and surcease from suffering, Zen teaches detachment. The Unix tradition teaches the value of detachment from the particular, accidental conditions under which a design problem was posed. Abstract. Simplify. Generalize. Because we write software to solve problems, we cannot completely detach from the problems—but it is well worth the mental effort to see how many preconceptions you can throw away, and whether the design becomes more compact<A NAME="idd1e10495"></A> and orthogonal as you do that. Possibilities for code reuse often result.</P>
<P class="docText">Jokes about the relationship between Unix and Zen are a live part of the Unix tradition as well.<sup class="docFootnote"><A class="docLink" HREF="#ch04en05">[5]</A></sup> This is not an accident.</P><blockquote><p class="docFootnote"><sup><A NAME="ch04en05">[5]</A></sup> For a recent example of Unix/Zen crossover, see <A class="docLink" HREF="0131429019_app04.html#app04">Appendix D</A>.</p></blockquote>


<a href="0131429019_18071533.html"><img src="FILES/pixel.gif" width="1" height="1" border="0"></a><ul></ul></td></tr></table>
<td></td>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
          <a href="0131429019_ch04lev1sec1.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
          <a href="0131429019_ch04lev1sec3.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
</body></html>
