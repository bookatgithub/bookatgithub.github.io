<html><head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<!--SafClassName="docSection1Title"--><!--SafTocEntry="7.3 Problems and Methods to Avoid"-->
<link rel="STYLESHEET" type="text/css" href="FILES/style.css">
<link rel="STYLESHEET" type="text/css" href="FILES/docsafari.css">
<style type="text/css">	.tt1    {font-size: 10pt;}</style>
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
	<a href="0131429019_ch07lev1sec2.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
	<a href="0131429019_ch07lev1sec4.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch07lev1sec3"></A>
<H3 class="docSection1Title" id="162666-939">7.3 Problems and Methods to Avoid</H3>
<P class="docText"><A NAME="idd1e17163"></A>While BSD-style sockets<A NAME="idd1e17169"></A> over TCP/IP<A NAME="idd1e17173"></A> have become the dominant IPC method under Unix, there are still live controversies over the right way to partition by multiprogramming. Some obsolete methods have not yet completely died, and some techniques of questionable utility have been imported from other operating systems (often in association with graphics or GUI programming). We'll be touring some dangerous swamps here; beware the crocodiles.</P>
<A NAME="ch07lev2sec7"></A>
<H4 class="docSection2Title">7.3.1 Obsolescent Unix IPC Methods</H4>
<P class="docText"><A NAME="idd1e17187"></A><A NAME="idd1e17190"></A>Unix (born 1969) long predates TCP/IP<A NAME="idd1e17198"></A> (born 1980) and the ubiquitous networking of the 1990s and later. Anonymous pipes, redirection, and shellout have been in Unix since very early days, but the history of Unix is littered with the corpses of APIs tied to obsolescent IPC and networking models, beginning with the <TT>mx()</TT> facility that appeared in Version 6 (1976) and was dropped before Version 7 (1979).</P>
<P class="docText">Eventually BSD sockets<A NAME="idd1e17214"></A> won out as IPC was unified with networking. But this didn't happen until after fifteen years of experimentation that left a number of relics behind. It's useful to know about these because there are likely to be references to them in your Unix documentation that might give the misleading impression that they're still in use. These obsolete methods are described in more detail in <span class="docEmphasis">Unix Network Programming</span> <A class="docLink" HREF="0131429019_app02.html#biblio80">[Stevens90]</A>.</P>
<blockquote>

<p class="docText"><A NAME="idd1e17234"></A>The real explanation for all the dead IPC facilities in old AT&amp;T Unixes was politics. The Unix Support Group was headed by a low-level manager, while some projects that used Unix were headed by vice presidents. They had ways to make irresistible requests, and would not brook the objection that most IPC mechanisms are interchangeable.</p>
<p class="docText">—Doug McIlroy</p></blockquote>
<A NAME="ch07lev3sec15"></A>
<H5 class="docSection3Title">7.3.1.1 System V IPC</H5>
<P class="docText"><A NAME="idd1e17252"></A><A NAME="idd1e17257"></A>The System V IPC facilities are message-passing facilities based on the System V shared memory facility we described earlier.</P>
<P class="docText">Programs that cooperate using System V IPC usually define shared protocols based on exchanging short (up to 8K) binary messages. The relevant manual pages are <span class="docEmphasis">msgctl</span>(2) and friends. As this style has been largely superseded by text protocols passed between sockets, we do not give an example here.</P>
<P class="docText">The System V IPC facilities are present in Linux<A NAME="idd1e17279"></A> and other modern Unixes. However, as they are a legacy feature, they are not exercised very often. The Linux version is still known to have bugs as of mid-2003. Nobody seems to care enough to fix them.</P>

<A NAME="ch07lev3sec16"></A>
<H5 class="docSection3Title">7.3.1.2 Streams</H5>
<P class="docText"><A NAME="idd1e17291"></A><A NAME="idd1e17296"></A>Streams networking was invented for Unix Version 8 (1985) by Dennis Ritchie<A NAME="idd1e17300"></A>. A re-implementation called STREAMS (yes, it is all-capitals in the documentation) first became available in the 3.0 release of System V Unix (1986)<A NAME="idd1e17304"></A>. The STREAMS facility provided a full-duplex interface (functionally not unlike a BSD socket<A NAME="idd1e17308"></A>, and like sockets, accessible through normal <span class="docEmphasis">read</span>(2)<A NAME="idd1e17315"></A> and <span class="docEmphasis">write</span>(2)<A NAME="idd1e17322"></A> operations after initial setup) between a user process and a specified device driver in the kernel. The device driver might be hardware such as a serial or network card, or it might be a software-only pseudodevice set up to pass data between user processes.</P>
<P class="docText">An interesting feature of both streams and STREAMS<sup class="docFootnote"><A class="docLink" HREF="#ch07en12">[12]</A></sup> is that it is possible to push protocol-translation modules into the kernel's processing path, so that the device the user process 'sees' through the full-duplex channel is actually filtered. This capability could be used, for example, to implement a line-editing protocol for a terminal device. Or one could implement protocols such as IP or TCP without wiring them directly into the kernel.</P><blockquote><p class="docFootnote"><sup><A NAME="ch07en12">[12]</A></sup> STREAMS was much more complex. Dennis Ritchie is reputed to have said "Streams means something different when shouted".</p></blockquote>
<P class="docText">Streams originated as an attempt to clean up a messy feature of the kernel called 'line disciplines'—alternative modes of processing character streams coming from serial terminals and early local-area networks. But as serial terminals faded from view, Ethernet LANs became ubiquitous, and TCP/IP<A NAME="idd1e17336"></A> drove out other protocol stacks and migrated into Unix kernels, the extra flexibility provided by STREAMS had less and less utility. In 2003, System V Unix<A NAME="idd1e17340"></A> still supports STREAMS, as do some System V/BSD<A NAME="idd1e17344"></A> hybrids such as Digital Unix and Sun Microsystems' Solaris.<A NAME="idd1e17348"></A></P>
<P class="docText">Linux<A NAME="idd1e17354"></A> and other open-source Unixes<A NAME="idd1e17358"></A> have effectively discarded STREAMS. Linux kernel modules and libraries are available from the LiS &lt;<A class="docLink" target="_blank" HREF="http://www.gcom.com/home/linux/lis/default.htm">http://www.gcom.com/home/linux/lis/</A>&gt; project, but (as of mid-2003) are not integrated into the stock Linux kernel. They will not be supported under non-Unix operating systems.</P>


<A NAME="ch07lev2sec8"></A>
<H4 class="docSection2Title">7.3.2 Remote Procedure Calls</H4>
<P class="docText"><A NAME="idd1e17374"></A><A NAME="idd1e17377"></A>Despite occasional exceptions such as NFS (Network File System)<A NAME="idd1e17388"></A> and the GNOME project<A NAME="idd1e17392"></A>, attempts to import CORBA, ASN.1, and other forms of remote-procedure-call interface have largely failed—these technologies have not been naturalized into the Unix culture.</P>
<P class="docText">There seem to be several underlying reasons for this. One is that RPC interfaces are not readily discoverable<A NAME="idd1e17402"></A>; that is, it is difficult to query these interfaces for their capabilities, and difficult to monitor them in action without building single-use tools as complex as the programs being monitored (we examined some of the reasons for this in <A class="docLink" HREF="0131429019_ch06.html#ch06">Chapter 6</A>). They have the same version skew problems as libraries, but those problems are harder to track because they're distributed and not generally obvious at link time.</P>
<P class="docText">As a related issue, interfaces that have richer type signatures also tend to be more complex, therefore more brittle. Over time, they tend to succumb to ontology creep as the inventory of types that get passed across interfaces grows steadily larger and the individual types more elaborate. Ontology creep is a problem because structs are more likely to mismatch than strings; if the ontologies of the programs on each side don't exactly match, it can be very hard to teach them to communicate at all, and fiendishly difficult to resolve bugs. The most successful RPC applications, such as the Network File System, are those in which the application domain naturally has only a few simple data types.</P>
<P class="docText">The usual argument for RPC is that it permits "richer" interfaces than methods like text streams—that is, interfaces with a more elaborate and application-specific ontology of data types. But the Rule of Simplicity<A NAME="idd1e17422"></A><A NAME="idd1e17425"></A> applies! We observed in <A class="docLink" HREF="0131429019_ch04.html#ch04">Chapter 4</A> that one of the functions of interfaces is as choke points that prevent the implementation details of modules from leaking into each other. Therefore, the main argument in favor of RPC is also an argument that it increases global complexity rather than minimizing it.</P>
<P class="docText">With classical RPC, it's too easy to do things in a complicated and obscure way instead of keeping them simple. RPC seems to encourage the production of large, baroque, over-engineered systems with obfuscated interfaces, high global complexity, and serious version-skew and reliability problems—a perfect example of thick glue layers run amok.</P>
<P class="docText">Windows<A NAME="idd1e17448"></A> COM and DCOM are perhaps the archetypal examples of how bad this can get, but there are plenty of others. Apple abandoned OpenDoc, and both CORBA and the once wildly hyped Java RMI<A NAME="idd1e17452"></A> have receded from view in the Unix world as people have gained field experience with them. This may well be because these methods don't actually solve more problems than they cause.</P>
<P class="docText">Andrew S. Tanenbaum and Robbert van Renesse have given us a detailed analysis of the general problem in <span class="docEmphasis">A Critique of the Remote Procedure Call Paradigm</span> [Tanenbaum-VanRenesse], a paper which should serve as a strong cautionary note to anyone considering an architecture based on RPC.</P>
<P class="docText">All these problems may predict long-term difficulties for the relatively few Unix projects that use RPC. Of these projects, perhaps the best known is the GNOME desktop effort.<sup class="docFootnote"><A class="docLink" HREF="#ch07en13">[13]</A></sup> These problems also contribute to the notorious security vulnerabilities of exposing NFS servers.</P><blockquote><p class="docFootnote"><sup><A NAME="ch07en13">[13]</A></sup> GNOME's main competitor, KDE<A NAME="idd1e17474"></A>, started with CORBA but abandoned it in their 2.0 release. They have been on a quest for lighter-weight IPC methods ever since.</p></blockquote>
<P class="docText">Unix tradition, on the other hand, strongly favors transparent<A NAME="idd1e17488"></A> and discoverable<A NAME="idd1e17492"></A> interfaces. This is one of the forces behind the Unix culture's continuing attachment to IPC through textual protocols. It is often argued that the parsing overhead of textual protocols is a performance problem relative to binary RPCs—but RPC interfaces tend to have latency problems that are far worse, because (a) you can't readily anticipate how much data marshaling and unmarshaling a given call will involve, and (b) the RPC model tends to encourage programmers to treat network transactions as cost-free. Adding even one additional round trip to a transaction interface tends to add enough network latency to swamp any overhead from parsing or marshaling.</P>
<P class="docText">Even if text streams were less efficient than RPC, the performance loss would be marginal and linear, the kind better addressed by upgrading your hardware than by expending development time or adding architectural complexity. Anything you might lose in performance by using text streams, you gain back in the ability to design systems that are simpler—easier to monitor, to model, and to understand.</P>
<P class="docText">Today, RPC and the Unix attachment to text streams are converging in an interesting way, through protocols like XML-RPC and SOAP<A NAME="idd1e17523"></A><A NAME="idd1e17530"></A>. These, being textual and transparent, are more palatable to Unix programmers than the ugly and heavyweight binary serialization formats they replace. While they don't solve all the more general problems pointed out by Tanenbaum and van Renesse, they do in some ways combine the advantages of both text-stream and RPC worlds.</P>

<A NAME="ch07lev2sec9"></A>
<H4 class="docSection2Title">7.3.3 Threads—Threat or Menace?</H4>
<P class="docText"><A NAME="idd1e17545"></A><A NAME="idd1e17548"></A>Though Unix developers have long been comfortable with computation by multiple cooperating processes, they do not have a native tradition of using threads (processes that share their entire address spaces). These are a recent import from elsewhere, and the fact that Unix programmers generally dislike them is not merely accident or historical contingency.</P>
<P class="docText">From a complexity-control point of view, threads are a bad substitute for lightweight processes with their own address spaces; the idea of threads is native to operating systems with expensive process-spawning and weak IPC facilities.</P>
<P class="docText">By definition, though daughter threads of a process typically have separate local-variable stacks, they share the same global memory. The task of managing contentions and critical regions in this shared address space is quite difficult and a fertile source of global complexity and bugs. It can be done, but as the complexity of one's locking regime rises, the chance of races and deadlocks due to unanticipated interactions rises correspondingly.</P>
<P class="docText">Threads are a fertile source of bugs because they can too easily know too much about each others' internal states. There is no automatic encapsulation, as there would be between processes with separate address spaces that must do explicit IPC to communicate. Thus, threaded programs suffer from not just ordinary contention problems, but from entire new categories of timing-dependent bugs that are excruciatingly difficult to even reproduce, let alone fix.</P>
<P class="docText">Thread developers have been waking up to this problem. Recent thread implementations and standards show an increasing concern with providing thread-local storage, which is intended to limit problems arising from the shared global address space. As threading APIs move in this direction, thread programming starts to look more and more like a controlled use of shared memory.</P>
<blockquote>

<p class="docText"><A NAME="idd1e17584"></A>Threads often prevent abstraction. In order to prevent deadlock, you often need to know how and if the library you are using uses threads in order to avoid deadlock problems. Similarly, the use of threads in a library could be affected by the use of threads at the application layer.</p>
<p class="docText">—David Korn</p></blockquote>
<P class="docText">To add insult to injury, threading has performance costs that erode its advantages over conventional process partitioning. While threading can get rid of some of the overhead of rapidly switching process contexts, locking shared data structures so threads won't step on each other can be just as expensive.</P>
<blockquote>

<p class="docText"><A NAME="idd1e17599"></A>The X server, able to execute literally millions of ops/second, is <span class="docEmphasis">not</span> threaded; it uses a poll/select loop. Various efforts to make a multithreaded implementation have come to no good result. The costs of locking and unlocking get too high for something as performance-sensitive as graphics servers.</p>
<p class="docText">—Jim Gettys</p></blockquote>
<P class="docText">This problem is fundamental, and has also been a continuing issue in the design of Unix kernels for symmetric multiprocessing. As your resource-locking gets finer-grained, latency due to locking overhead can increase fast enough to swamp the gains from locking less core memory.</P>
<P class="docText">One final difficulty with threads is that threading standards still tend to be weak and underspecified as of mid-2003. Theoretically conforming libraries for Unix standards such as POSIX<A NAME="idd1e17613"></A> threads (1003.1c) can nevertheless exhibit alarming differences in behavior across platforms, especially with respect to signals, interactions with other IPC methods, and resource cleanup times. Windows<A NAME="idd1e17620"></A> and classic MacOS have native threading models and interrupt facilities quite different from those of Unix and will often require considerable porting effort even for simple threading cases. The upshot is that you cannot count on threaded programs to be portable.</P>
<P class="docText">For more discussion and a lucid contrast with event-driven programming, see <span class="docEmphasis">Why Threads Are a Bad Idea</span> <A class="docLink" HREF="0131429019_app02.html#biblio59">[Ousterhout96]</A>.</P>


<ul></ul></td></tr></table>
<td></td>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
          <a href="0131429019_ch07lev1sec2.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
          <a href="0131429019_ch07lev1sec4.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
</body></html>
