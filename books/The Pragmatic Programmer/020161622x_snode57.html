<HTML><HEAD><META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<!--SafClassName="docSection1Title"--><!--SafTocEntry="Temporal Coupling"-->
<LINK REL="stylesheet" href="FILES/proquestM.css">
</HEAD>
<BODY link="#354278" vlink="#000066" alink="#000080" topmargin="0">
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#CCCCCC">
<td><font color="black" size=1>I l<font color="#FF0000">@</font>ve RuBoard</td>
<td valign="top" class="v2" align="right"><a href="020161622x_snode56.html"><img src="FILES/previous.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a> <a href="020161622x_snode58.html"><img src="FILES/next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a></td></table>
<FONT size="-1"><H3>Temporal Coupling</H3>
			<P>What is <I>temporal coupling</i> all about, you may ask. It's about time.</p>

			<p>Time is an often ignored aspect of software architectures. The only time that preoccupies us is the time on the schedule, the time left until we ship—but this is not what we're talking about here. Instead, we are talking about the role of time as a design element of the software itself. There are two aspects of time that are important to us: concurrency (things happening at the same time) and ordering (the relative positions of things in time).</p>

			<P>We don't usually approach programming with either of these aspects in mind. When people first sit down to design an architecture or write a program, things tend to be linear. That's the way most people think—<I>do this</I> and then always <I>do that.</i> But thinking this way leads to <i>temporal coupling:</i> coupling in time. Method A must always be called before method B; only one report can be run at a time; you must wait for the screen to redraw before the button click is received. Tick must happen before tock.</p>

			<P>This approach is not very flexible, and not very realistic.</P>

			<P>We need to allow for concurrency<Font size="1"><sup><a href="#FOOTNOTE-3">[3]</a></sup></fONT>
 and to think about decoupling any time or order dependencies. In doing so, we can gain flexibility and reduce any time-based dependencies in many areas of development: workflow analysis, architecture, design, and deployment.</P>
<blockQuOte><fONT SIze="1">
<p cLASS="footnote">
<sup><a NAME="FOOTNOTE-3">[3]</a></sup>
We won't go into the details of concurrent or parallel programming here; a good computer science textbook should cover the basics, including scheduling, deadlock, star-vation, mutual exclusion/semaphores, and so on.</P>
</FONt></blockquote>

				
			<h4>Workflow</h4>
				<p>On many projects, we need to model and analyze the users' workflows as part of requirements analysis. We'd like to find out what <i>can</i> happen at the same time, and what must happen in a strict order. One way to do this is to capture their description of workflow using a notation such as the <i>UML activity diagram.</i><foNT SIze="1"><sup><A hRef="#FOOTNOTE-4">[4]</a></SUP></FOnt>
</p>
<bLOCKquotE><FONt sizE="1">
<P CLass="footnote">
<sup><a name="FOOTNOTE-4">[4]</a></sup>
For more information on all of the UML diagram types, see [<a href="020161622x_snode87.html#14">FS97</A>].</P>
</FOnt></bloCkQuotE>

					
				<P>An activity diagram consists of a set of actions drawn as rounded boxes. The arrow leaving an action leads to either another action (which can start once the first action completes) or to a thick line called a <I>synchronization bar.</I> Once <I>all</i> the actions leading into a synchronization bar are complete, you can then proceed along any arrows leaving the bar. An action with no arrows leading into it can be started at any time.</p>

				<p>You can use activity diagrams to maximize parallelism by identifying activities that <i>could be</I> performed in parallel, but aren't.</P>

				<DIv claSS="note"><P Class="notetitle"><B>Tip 39</B></P><P>

					<p>Analyze Workflow to Improve Concurrency</p>

				</p></div>
<br>
<br>

				<p>For instance, in our blender project (Exercise 17, page 119), users may initially describe their current workflow as follows.</p>

				<ol type="1">
<li>
<P>Open blender</P>
</LI>
<li>
<p>Open piña colada mix</p>
</lI>
<lI>
<p>Put mix in blender</p>
</lI>
<LI>
<P>Measure 1/2 cup white rum</P>
</li>
<li>
<P>Pour in rum</P>
</LI>
<li>
<p>Add 2 cups of ice</p>
</LI>
<LI>
<p>Close blender</p>
</li>
<LI>
<P>Liquefy for 2 minutes</P>
</li>
<li>
<p>Open blender</p>
</li>
<li>
<p>Get glasses</p>
</li>
<li>
<p>Get pink umbrellas</p>
</li>
<LI>
<P>Serve</P>

					</li>
</ol>

				<p>Even though they describe these actions serially, and may even perform them serially, we notice that many of them could be performed in parallel, as we show in the activity diagram in <A href="020161622x_snode57.html#4">Figure 5.2</a> on the next page.</P>

				<CENTer>
					<h5>
<a NAME="4"></a>Figure 5.2. UML activity diagram: making a piña colada</h5><imG BORder="0" wIDTH="407" height="407" src="FILES/05fig02.gif" alt="graphics/05fig02.gif"></center>

				<p>It can be eye-opening to see where the dependencies really exist. In this instance, the top-level tasks (1, 2, 4, 10, and 11) can all happen concurrently, up front. Tasks 3, 5, and 6 can happen in parallel later.</p>

				<P>If you were in a piña colada-making contest, these optimizations may make all the difference.</P>

			
			<H4>Architecture</H4>
				<p>We wrote an On-Line Transaction Processing (OLTP) system a few years ago. At its simplest, all the system had to do was read a request and process the transaction against the database. But we wrote a three-tier, multiprocessing distributed application: each component was an independent entity that ran concurrently with all other components. While this sounds like more work, it wasn't: taking advantage of temporal decoupling made it <i>easier</i> to write. Let's take a closer look at this project.</p>

				<p>The system takes in requests from a large number of data communication lines and processes transactions against a back-end database.</P>

				<p>The design addresses the following constraints:</P>

				<ul>
<lI><P>Database operations take a relatively long time to complete.</P>
</LI>
<li><p>For each transaction, we must not block communication services while a database transaction is being processed.</p>
</LI>
<LI><p>Database performance suffers with too many concurrent sessions.</p>
</li>
<LI><P>Multiple transactions are in progress concurrently on each data line.</P>

					</li>
</ul>
				<P>The solution that gave us the best performance and cleanest architecture looked something like <A href="020161622x_snode57.html#6">Figure 5.3</a>.</p>

				<center>
					<h5>
<a name="6"></a>Figure 5.3. OLTP architecture overview</h5><imG BORder="0" wiDtH="438" heiGHT="175" src="FILES/05fig03.gif" alt="graphics/05fig03.gif"></CENTer>

				<p>Each box represents a separate process; processes communicate via work queues. Each input process monitors one incoming communication line, and makes requests to the application server. All requests are asynchronous: as soon as the input process makes its current request, it goes back to monitoring the line for more traffic. Similarly, the application server makes requests of the database process,<fONT Size="1"><sUP><A Href="#FOOTNOTE-5">[5]</a></sup></font>
 and is notified when the individual transaction is complete.</p>
<blockquoTE><FOnt sizE="1">
<p ClasS="footnote">
<SUP><A name="FOOTNOTE-5">[5]</A></SUP>
Even though we show the database as a single, monolithic entity, it is not. The database software is partitioned into several processes and client threads, but this is handled internally by the database software and isn't part of our example.</p>
</fonT></BLOckquOTE>

					
				<P>This example also shows a way to get quick and dirty load balancing among multiple consumer processes: the <i>hungry consumer</i> model.</p>

				<p>In a hungry consumer model, you replace the central scheduler with a number of independent consumer tasks and a centralized work queue. Each consumer task grabs a piece from the work queue and goes on about the business of processing it. As each task finishes its work, it goes back to the queue for some more. This way, if any particular task gets bogged down, the others can pick up the slack, and each individual component can proceed at its own pace. Each component is temporally decoupled from the others.</p>

				<div class="note"><p class="notetitle"><b>Tip 40</B></P><P>

					<P>Design Using Services</p>

				</p></div>
<Br>
<Br>

				<p>Instead of components, we have really created <i>services—</I>independent, concurrent objects behind well-defined, consistent interfaces.</P>

			
			<H4>Design for Concurrency</H4>
				<P>The rising acceptance of Java as a platform has exposed more developers to multithreaded programming. But programming with threads imposes some design constraints—and that's a good thing. Those constraints are actually so helpful that we want to abide by them whenever we program. It will help us decouple our code and fight <a href="020161622x_snode62.html">programming by coincidence</A>.</P>

				<P>With linear code, it's easy to make assumptions that lead to sloppy programming. But concurrency forces you to think through things a bit more carefully—you're not alone at the party anymore. Because things can now happen at the "same time," you may suddenly see some time-based dependencies.</p>

				<p>To begin with, any global or static variables must be protected from concurrent access. Now may be a good time to ask yourself <i>why</i> you need a global variable in the first place. In addition, you need to make sure that you present consistent state information, regardless of the order of calls. For example, when is it valid to query the state of your object? If your object is in an invalid state between certain calls, you may be relying on a coincidence that no one can call your object at that point in time.</P>

				<P>Suppose you have a windowing subsystem where the widgets are first created and then shown on the display in two separate steps. You aren't allowed to set state in the widget until it is shown. Depending on how the code is set up, you may be relying on the fact that no other object can use the created widget until you've shown it on the screen.</P>

				<P>But this may not be true in a concurrent system. Objects must always be in a valid state when called, and they can be called at the most awkward times. You must ensure that an object is in a valid state <i>any time</i> it could possibly be called. Often this problem shows up with classes that define separate constructor and initialization routines (where the constructor doesn't leave the object in an initialized state). Using class invariants, discussed in <a href="020161622x_snode43.html">Design by Contract</A>, will help you avoid this trap.</p>

				<h5>Cleaner Interfaces</h5>
					<p>Thinking about concurrency and time-ordered dependencies can lead you to design cleaner interfaces as well. Consider the C library routine <tt class="monofont">strtok,</tt> which breaks a string into tokens.</p>

					<p>The design of <tt claSS="monofont">strtok</TT> isn't thread safe,<font sIzE="1"><sup><A HREF="#FOOTNOTE-6">[6]</a></sup></FONT>
 but that isn't the worst part: look at the time dependency. You must make the first call to <tt clASS="monofont">strtok</Tt> with the variable you want to parse, and all successive calls with a <tt cLASS="monofont">NULL</tt> instead. If you pass in a non-<tt class="monofont">NULL</tt> value, it restarts the parse on that buffer instead. Without even considering threads, suppose you wanted to use <tt class="monofont">strtok</tt> to parse two separate strings at the same time:</P>
<BLOckquoTe><Font SIZE="1">
<P clasS="footnote">
<SUP><a namE="FOOTNOTE-6">[6]</A></SUp>
It uses static data to maintain the current position in the buffer. The static data isn't protected against concurrent access, so it isn't thread safe. In addition, it clobbers the first argument you pass in, which can lead to some nasty surprises.</p>
</foNT></BLockquote>

						
					<pre>
						
<b>    char</b> buf1[BUFSIZ];
<b>    char</b> buf2[BUFSIZ];
<b>    char</b> *p, *q;

    strcpy(buf1, "<i>this is a test</i>");
    strcpy(buf2, "<i>this ain't gonna work</I>");

    p = strtok(buf1, " ");
    q = strtok(buf2, " ");
<B>    while</B> (p &amp;&amp; q) {
      printf(<I>"%s %s</i>\<i>n",</i> p, q);
      p = strtok(NULL, " ");
      q = strtok(NULL, " ");
    }
</prE>

					<p>The code as shown will not work: there is implicit state retained in <Tt clASS="monofont">strtok</TT> between calls. You have to use <tt clASS="monofont">strtok</Tt> on just one buffer at a time.</p>

					<p>Now in Java, the design of a string parser has to be different. It must be thread safe and present a consistent state.</p>

					<PRE>
						
     StringTokenizer st1 = <B>new</b> StringTokenizer("<i>this is a test</i>");
     StringTokenizer st2 = <b>new</B> StringTokenizer("<I>this test will work</I>");

     <B>while</b> (st1.hasMoreTokens() &amp;&amp; st2 hasMoreTokens()) {
       System.out.println(st1.nextToken());
       System.out.println(st2.nextToken());
     }
</pre>

					<p><tt class="monofont">StringTokenizer</tt> is a much cleaner, more maintainable, interface. It contains no surprises, and won't cause mysterious bugs in the future, as <tt clasS="monofont">strtok</TT> might.</P>

					<div clAsS="note"><p clASS="notetitle"><B>Tip 41</B></p><p>

						<p>Always Design for Concurrency</p>

					</P></DIV>
<br>
<br>

				
			
			<H4>Deployment</H4>
				<P>Once you've designed an architecture with an element of concurrency, it becomes easier to think about handling <I>many</i> concurrent services: the model becomes pervasive.</p>

				<p>Now you can be flexible as to how the application is deployed: standalone, client-server, or <i>n</I>-tier. By architecting your system as independent services, you can make the configuration dynamic as well. By planning for concurrency, and decoupling operations in time, you have all these options—including the stand-alone option, where you can choose <I>not</I> to be concurrent.</P>

				<p>Going the other way (trying to add concurrency to a nonconcurrent application) is <i>much</i> harder. If we design to allow for concurrency, we can more easily meet scalability or performance requirements when the time comes—and if the time never comes, we still have the benefit of a cleaner design.</p>

				<p>Isn't it about time?</p>

				<h5>Related sections include:</h5>
					<ul>
<li><p><a href="020161622x_snode43.html">Design by Contract</a></p>
</LI>
<LI><p><a href="020161622x_snode62.html">Programming by Coincidence</a></P>

						</li>
</uL>
				
				<H5>Challenges</H5>
					<UL>
<li><p>How many tasks do you perform in parallel when you get ready for work in the morning? Could you express this in a UML activity diagram? Can you find some way to get ready more quickly by increasing concurrency?</p>

						</LI>
</UL>
				
			
		</font>
 
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#CCCCCC">
<td><font color="black" size=1>I l<font color="#FF0000">@</font>ve RuBoard</td>
<td valign="top" class="v2" align="right"><a href="020161622x_snode56.html"><img src="FILES/previous.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a> <a href="020161622x_snode58.html"><img src="FILES/next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a></td></table>
</BODY></HTML>