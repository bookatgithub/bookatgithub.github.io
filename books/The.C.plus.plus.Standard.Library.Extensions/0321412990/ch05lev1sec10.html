<html>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<head>
<title>Section 5.10.&nbsp; Load Factors and Rehashing</title>
<link rel="STYLESHEET" type="text/css" href="images/style.css">
<link rel="STYLESHEET" type="text/css" href="images/docsafari.css">
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr><td><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch05lev1sec9.html><img src="images/prev.gif" width="60" height="17" border="0" align="absmiddle" alt="Previous Page"></a>
<td align="right"><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch05lev1sec11.html><img src="images/next.gif" width="60" height="17" border="0" align="absmiddle" alt="Next Page"></a>
</div></td></tr></table>
<br><table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><a name="ch05lev1sec10"></a>

<h3 id="669163-931" class="docSection1Title">5.10. Load Factors and Rehashing</H3>
<p class="docText"><a name="iddle1434"></a><a name="iddle1768"></a><a name="iddle1856"></a>We saw earlier that it's important to keep the average number of objects per bucket down if we want fast searches. In fact, there are some formalisms for talking about that. A hash table's <span class="docEmphasis">load factor</span> is the average number of objects per bucket. When a hash table's load factor is less than its <span class="docEmphasis">target load factor</span>, inserting another object won't trigger a rehash. You can get the hash table's current load factor by calling the member function <tt>load_factor()</tt>. You can get the table's target load factor by calling the member function <tt>max_load_factor()</tt>, and you can set the table's target load factor by calling <tt>max_load_factor(z)</tt>, where <tt>z</tt> is the new value for the load factor.</P>
<p class="docText">The member function <tt>rehash(n)</tt> sets the number of buckets to at least <tt>n</tt> but large enough so that the load factor is less than the target load factor and then redistributes the hash table's objects into the new set of buckets. This usually reduces the number of objects in each bucket, which, in turn, improves search performance.</p>
<p class="docText">You won't ordinarily have to call <tt>rehash</tt>, though, because the container does it for you when the load factor gets too high. Technically, the requirement goes the other way around: as long as the load factor is less than the maximum load factor, insertions don't invalidate iterators. This means that objects can't be moved to other buckets, which in turn means that the table can't be rehashed. There is no requirement to rehash when the load factor gets too large, just a caution that rehashing might happen. That's a careful way of allowing incremental rehashing, which gradually increases the number of buckets in the table and moves some elements into new buckets on each insertion, rather than doing everything at once. That distributes the rehashing work over several insertions, which can improve responsiveness in real-time systems. If you've done a bunch of insertions and you're not going to do any <a name="iddle1857"></a>more, it's a good idea to call <tt>rehash</tt> to make sure that rehashing has been completed.</P>
<a name="ch05ex04"></a><h5 id="title-IDA0COWG" class="docExampleTitle">Example 5.4. Load Factors and Rehashing (<tt>contunord/rehash.cpp</tt>)</H5><P><table cellspacing="0" width="90%" border="1" cellpadding="5"><TR><TD>



<pre>
#include &lt;unordered_set&gt;
#include &lt;iostream&gt;
using std::tr1::unordered_set;
using std::cout;

typedef unordered_set &lt;int&gt; iset;

static void show_details (const iset&amp; set)
  { <span class="docEmphasis">// show container properties</span>
  cout &lt;&lt; "load factor: " &lt;&lt; set.load_factor ()
    &lt;&lt; " target load factor: " &lt;&lt; set.max_load_factor()
    &lt;&lt; " buckets: " &lt;&lt; set.bucket_count() &lt;&lt; '\n';
  }

int main ()
  { <span class="docEmphasis">// show growth pattern</span>
  iset  set;
  show_details (set);
  int i;
  for (i = 0; i &lt; 20; ++ i)
    set.insert (i);
  show_details (set);
  for (; i &lt; 40; ++ i)
    set.insert (i);
  show_details (set);
  for (; i &lt; 60; ++ i)
    set.insert (i);
  show_details (set);
  set.max_load_factor (2.0);
  show_details (set);
  set.rehash (10);
  show_details (set);
  set.rehash (30);
  show_details (set);
  return  0;
  }
</pre><br>

</TD></tr></table></P>

</TD></TR></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr><td><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch05lev1sec9.html><img src="images/prev.gif" width="60" height="17" border="0" align="absmiddle" alt="Previous Page"></a>
<td align="right"><div STYLE="MARGIN-LEFT: 0.15in;">
<a href=ch05lev1sec11.html><img src="images/next.gif" width="60" height="17" border="0" align="absmiddle" alt="Next Page"></a>
</div></td></tr></table>
</body></html>